[Sigmoid_function_01.png](https://zh.wikipedia.org/wiki/File:Sigmoid_function_01.png "fig:Sigmoid_function_01.png") [Sigmoid_function_02.png](https://zh.wikipedia.org/wiki/File:Sigmoid_function_02.png "fig:Sigmoid_function_02.png") **S函数**得名因其形状像**S**字母。一种常见的S函数是[逻辑函数](https://zh.wikipedia.org/wiki/逻辑函数 "wikilink"):

\[S(t) = \frac{1}{1 + e^{-t}}.\]

其级数展开为：

\(s := 1/2+\frac{1}{4}t-\frac{1}{48}t^3+\frac{1}{480}t^5-\frac{17}{80640}t^7+\frac{31}{1451520}t^9-\frac{691}{319334400}t^{11}+O(t^{12})\)

## 参考资料

  - {{ cite book | first1=Tom M. |last1= Mitchell | title=Machine Learning | publisher=WCB–McGraw–Hill |year=1997

|isbn=0-07-042807-7}}. In particular see "Chapter 4: Artificial Neural Networks" (in particular pp. 96–97) where Mitchell uses the word "logistic function" and the "sigmoid function" synonymously – this function he also calls the "squashing function" – and the sigmoid (aka logistic) function is used to compress the outputs of the "neurons" in multi-layer neural nets.

  - Properties of the sigmoid, including how it can shift along axes and how its domain may be transformed.

## 参见

  - [函数](../Page/函数.md "wikilink")

[Category:特殊函数](https://zh.wikipedia.org/wiki/Category:特殊函数 "wikilink")
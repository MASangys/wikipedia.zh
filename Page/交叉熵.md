在[信息论](../Page/信息论.md "wikilink")中，基于相同事件测度的两个[概率分布](../Page/概率分布.md "wikilink")\(p\)和\(q\)的**交叉熵**是指，当基于一个“非自然”（相对于“真实”分布\(p\)而言）的概率分布\(q\)进行编码时，在事件集合中唯一标识一个事件所需要的平均比特数（[bit](https://zh.wikipedia.org/wiki/bit "wikilink")）。

基于[概率分布](../Page/概率分布.md "wikilink")\(p\)和\(q\)的交叉熵定义为：

\[H(p, q) = \operatorname{E}_p[-\log q] = H(p) + D_{\mathrm{KL}}(p \| q),\!\]

其中\(H(p)\)是\(p\)的[熵](https://zh.wikipedia.org/wiki/信息熵 "wikilink")，\(D_{\mathrm{KL}}(p \| q)\)是从\(p\)到\(q\)的[KL散度](https://zh.wikipedia.org/wiki/KL散度 "wikilink")(也被称为*p*相对于*q*的*相对熵*)。

对于[离散分布](https://zh.wikipedia.org/wiki/离散随机变量 "wikilink")\(p\)和\(q\)，这意味着：

\[H(p, q) = -\sum_x p(x)\, \log q(x). \!\]

对于[连续分布也是类似的](https://zh.wikipedia.org/wiki/连续随机变量 "wikilink")。我们假设\(p\)和\(q\)在[测度](../Page/测度.md "wikilink") \(r\)上是[绝对连续](../Page/绝对连续.md "wikilink")的(通常 \(r\)是[Lebesgue measure](https://zh.wikipedia.org/wiki/Lebesgue_measure "wikilink") on a [Borel](https://zh.wikipedia.org/wiki/Borel_set "wikilink") [σ-algebra](https://zh.wikipedia.org/wiki/Sigma-algebra "wikilink"))。设\(P\)和\(Q\)分别为\(p\)的\(q\)在[测度](../Page/测度.md "wikilink") \(r\)上概率密度函数。则

\[-\int_X P(x)\, \log Q(x)\, dr(x) = \operatorname{E}_p[-\log Q]. \!\]

## 源起

在[信息论](../Page/信息论.md "wikilink")中, 以**直接可解编码**模式通过值\(x_i\)编码一个信息片段，使其能在所有可能的\(X\)集合中唯一标识该信息片段，[Kraft–McMillan theorem确保这一过程可以被看作一种](https://zh.wikipedia.org/wiki/Kraft's_inequality "wikilink")\(X\)上的隐式概率分布\(q(x_i) = 2^{-l_i}\)，从而使得\(l_i\)是\(x_i\)的编码位长度。 因此, 交叉熵可以看作每个信息片段在错误分布\(Q\)下的期望编码位长度，而信息实际分布为\(P\)。这就是期望\({E}_p\)是基于\(P\)而不是\(Q\)的原因。

\[H(p, q) = \operatorname{E}_p[l_i] = \operatorname{E}_p\left[\log \frac{1}{q(x_i)}\right]\]

\[H(p, q) = \sum_{x_i} p(x_i)\, \log \frac{1}{q(x_i)} \!\]

\[H(p, q) = -\sum_x p(x)\, \log q(x). \!\]

## 估计

在大多数情况下，我们需要在不知道分布\(p\)的情况下计算其交叉熵。例如在[语言模型中](https://zh.wikipedia.org/wiki/语言模型 "wikilink"), 我们基于训练集\(T\)创建了一个语言模型, 而在测试集合上通过其交叉熵来评估该模型的准确率。\(p\)是语料中词汇的真实分布，而\(q\)是我们获得的语言模型预测的词汇分布。由于真实分布是未知的，我们不能直接计算交叉熵。在这种情况下，我们可以通过下式来估计交叉熵:

\[H(T,q) = -\sum_{i=1}^N \frac{1}{N} \log_2 q(x_i)\]

\(N\)是测试集大小，\(q(x)\)是在训练集上估计的事件\(x\)发生的概率。我们假设训练集是从\(p(x)\)的真实采样，则此方法获得的是真实交叉熵的蒙特卡洛估计。

  -
[Category:信息學熵](https://zh.wikipedia.org/wiki/Category:信息學熵 "wikilink")
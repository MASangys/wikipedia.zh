在[数理统计学中](https://zh.wikipedia.org/wiki/数理统计学 "wikilink")，**似然函数**是一种关于[统计模型中的](https://zh.wikipedia.org/wiki/统计模型 "wikilink")[参数的](https://zh.wikipedia.org/wiki/参数 "wikilink")[函数](../Page/函数.md "wikilink")，表示模型参数中的**似然性**。似然函数在[统计推断中有重大作用](https://zh.wikipedia.org/wiki/统计推断 "wikilink")，如在[最大似然估计和](../Page/最大似然估计.md "wikilink")[费雪信息之中的应用等等](https://zh.wikipedia.org/wiki/费雪信息 "wikilink")。“似然性”与“或然性”或“[概率](../Page/概率.md "wikilink")”意思相近，都是指某种事件发生的可能性，但是在[统计学中](../Page/统计学.md "wikilink")，“似然性”和“概率”（或然性）又有明确的区分：概率，用于在已知一些参数的情況下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值。

在这种意义上，似然函数可以理解为[条件概率的逆反](../Page/条件概率.md "wikilink")。在已知某个参数**B**时，事件**A**会发生的概率写作：

\[P(A \mid B) = \frac{P(A , B)}{P(B)} \!\]

利用[-{zh-hk:貝葉斯定理;zh-hans:贝叶斯定理;zh-tw:貝氏定理;}-](https://zh.wikipedia.org/wiki/貝氏定理 "wikilink")，

\[P(B \mid A) = \frac{P(A \mid B)\;P(B)}{P(A)} \!\]

因此，我们可以反过来构造表示似然性的方法：已知有事件**A**发生，运用似然函数\(\mathbb{L}(B \mid A)\)，我们估计参数**B**的可能性。形式上，似然函数也是一种条件概率函数，但我们关注的[变量改变了](https://zh.wikipedia.org/wiki/变量 "wikilink")：

\[b\mapsto P(A \mid B=b)  \!\]

注意到这里并不要求似然函数满足归一性：\(\sum_{b \in \mathcal{B}}P(A \mid B=b) = 1\)。一个似然函数乘以一个正的常数之后仍然是似然函数。对所有\(\alpha > 0\)，都可以有似然函数：

\[L(b \mid A) = \alpha \; P(A \mid B=b) \!\]

## 例子

[likelihoodFunctionAfterHH.png](https://zh.wikipedia.org/wiki/File:likelihoodFunctionAfterHH.png "fig:likelihoodFunctionAfterHH.png")
考虑投掷一枚硬币的实验。通常来说，已知掷出一枚“公平的硬币”（正面朝上和反面朝上的概率都为0.5）,
即正面(Head)朝上的概率为\(p_H = 0.5\)，便可以知道投掷若干次后出现各种结果的可能性。

比如说，投两次都是正面朝上的概率是0.25。用条件概率表示，就是：

\[P(\mbox{HH} \mid p_H = 0.5) = 0.5^2 = 0.25\]

其中**H**表示正面朝上。

如果一个硬币的质量分布不够均匀, 那么它可能是一枚"非公平的硬币"

在统计学中，我们关心的是在**已知一系列投掷的结果时，关于硬币投掷时正面朝上的可能性的信息**。
我们可以建立一个统计模型：假设硬币投出时会有\(p_H\)的概率正面朝上，而有\(1 - p_H\)的概率反面朝上。
这时，通过**观察已发生的**两次投掷，条件概率可以改写成似然函数：

\[L(p_H \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.5) =0.25\]

也就是说，对于取定的似然函数，在观测到两次投掷都是正面朝上时，\(p_H = 0.5\)的**似然性**是0.25。注意，**反之并不成立，即当似然函数为0.25时不能推论出
\(p_H= 0.5\)**。

如果考虑\(p_H = 0.6\)，那么似然函数的值也会改变。

\[L(p_H \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.6) =0.36\]

[likelihoodFunctionAfterHHT.png](https://zh.wikipedia.org/wiki/File:likelihoodFunctionAfterHHT.png "fig:likelihoodFunctionAfterHHT.png")
如圖1所示，注意到似然函数的值变大了。
这说明，如果参数\(p_H\)的取值变成0.6的话，结果观测到连续两次正面朝上的概率要比假设\(p_H = 0.5\)时更大。也就是说，参数\(p_H\)取成0.6要比取成0.5更有说服力，更为“**合理**”。
总之，**似然函数的重要性不是它的具体取值，而是当参数变化时函数到底变小还是变大。**

`      `**`对同一个似然函数，其所代表的模型中，某项参数值具有多种可能，但如果存在一个参数值，使得它的函数值达到最大的话，那么这个值就是该项参数最为“合理”的参数值。`**

在这个例子中，如圖1所示，似然函数实际上等于：

\[L( \theta  \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = \theta) =\theta^2\]，其中\(0 \le p_H  \le 1\)。

如果取\(p_H = 1\)，那么**似然函数达到最大值1**。也就是说，当连续观测到两次正面朝上时，假设硬币投掷时正面朝上的概率为1是最合理的。

类似地，如果观测到的是三次投掷硬币，头两次正面朝上，第三次反面朝上，如圖2所示，那么似然函数将会是：

\[L(\theta  \mid \mbox{HHT}) = P(\mbox{HHT}\mid p_H = \theta) =\theta^2(1 - \theta)\]，其中**T**表示反面朝上，\(0 \le p_H  \le 1\)。

这时候，似然函数的最大值将会在\(p_H = \frac{2}{3}\)的时候取到。也就是说，当观测到三次投掷中前两次正面朝上而后一次反面朝上时，估计硬币投掷时正面朝上的概率\(p_H = \frac{2}{3}\)是最合理的。

## 应用

### 最大似然估计

最大似然估计是似然函数最初也是最自然的应用。上文已经提到，似然函数取得最大值表示相应的参数能够使得统计模型最为合理。从这样一个想法出发，最大似然估计的做法是：首先选取似然函数（一般是[概率密度函数或](https://zh.wikipedia.org/wiki/概率密度函数 "wikilink")[概率质量函数](../Page/概率质量函数.md "wikilink")），整理之后求最大值。实际应用中一般会取**似然函数的对数作为求最大值的函数**，这样求出的最大值和直接求最大值得到的结果是相同的。**似然函数的最大值不一定唯一，也不一定存在**。与矩法估计比较，最大似然估计的精确度较高，信息损失较少，但计算量较大。

### 似然比检验

似然比检验是利用似然函数来检测某个假设（或限制）是否有效的一种检验。一般情况下，要检测某个附加的参数限制是否是正确的，可以将加入附加限制条件的较复杂模型的似然函数最大值与之前的较简单模型的似然函数最大值进行比较。如果参数限制是正确的，那么加入这样一个参数应当不会造成似然函数最大值的大幅变动。一般使用两者的比例来进行比较，這個比值是[卡方分配](https://zh.wikipedia.org/wiki/卡方分配 "wikilink")。

[尼曼-皮尔森引理说明](https://zh.wikipedia.org/wiki/尼曼-皮尔森引理 "wikilink")，似然比检验是所有具有同等[显著性差异的检验中最有](../Page/显著性差异.md "wikilink")[统计效力的检验](https://zh.wikipedia.org/wiki/统计效力 "wikilink")。

## 参考来源

  - Stable URL: <http://www.jstor.org/stable/2344804>

  -
  -
  - Stable URL: <http://www.jstor.org/stable/2676741>

  -
[Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink")
[Category:贝叶斯统计](https://zh.wikipedia.org/wiki/Category:贝叶斯统计 "wikilink")
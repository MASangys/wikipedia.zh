在[统计学中](../Page/统计学.md "wikilink")，**典型相关分析**(**Canonical Correlation
Analysis**)是对[互协方差矩阵的一种理解](../Page/互协方差.md "wikilink")。如果我们有两个[随机变量向量](../Page/随机变量.md "wikilink")
*X* = (*X*<sub>1</sub>, ..., *X*<sub>*n*</sub>) 和 *Y* =
(*Y*<sub>1</sub>, ..., *Y*<sub>*m*</sub>)
并且它们是[相关的](../Page/相关.md "wikilink")，那么典型相关分析会找出
*X*<sub>*i*</sub> 和 *Y*<sub>*j*</sub>
的相互相关最大的线性组合。\[1\]T·R·Knapp指出“几乎所有常见的[参数测试的意义可视为特殊情况的典型相关分析](../Page/参数测试.md "wikilink")，这是研究两组变量之间关系的一般步骤。”\[2\]
这个方法在1936年由[哈罗德·霍特林首次引入](../Page/哈罗德·霍特林.md "wikilink")。\[3\]

## 定义

给定两个带[有限](../Page/有限.md "wikilink")[矩的随机变量的](../Page/矩.md "wikilink")[列向量](../Page/列向量.md "wikilink")
\(X = (x_1, \dots, x_n)'\) 和
\(Y = (y_1, \dots, y_m)'\)，我们可以定义[互协方差矩阵](../Page/互协方差.md "wikilink")
\(\Sigma _{XY} = \operatorname{cov}(X, Y)\) 为 \(n \times m\)
的[矩阵](../Page/矩阵.md "wikilink")，其中 \((i, j)\)
是[协方差](../Page/协方差.md "wikilink")
\(\operatorname{cov}(x_i, y_j)\)。实际上，我们可以基于 \(X\) 和 \(Y\)
的采样数据来估计协方差矩阵。(如从一对数据矩阵)。

典型相关分析求出向量 \(a\) 和 \(b\) 使得随机变量 \(a' X\) 和 \(b' Y\)
的[相关性](../Page/相关.md "wikilink")
\(\rho = \operatorname{corr}(a' X, b' Y)\) 最大。随机变量 \(U = a' X\) 和
\(V = b' Y\) 是 ***第一对典型变量***。然后寻求一个依然最大化相关但与第一对典型变量不相关的向量；这样就得到了
***第二对典型变量***。 这个步骤会进行 \(\min\{m,n\}\) 次。

## 计算

### 推导

设 \(\Sigma _{XX} = \operatorname{cov}(X, X)\) 和
\(\Sigma _{YY} = \operatorname{cov}(Y, Y)\)。需要最大化的参数为

\[\rho = \frac{a' \Sigma _{XY} b}{\sqrt{a' \Sigma _{XX} a} \sqrt{b' \Sigma _{YY} b}}.\]

第一步是定义一个[基变更以及](../Page/基变更.md "wikilink")

\[c = \Sigma _{XX} ^{1/2} a,\]

\[d = \Sigma _{YY} ^{1/2} b.\]

因此我们有

\[\rho = \frac{c' \Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1/2} d}{\sqrt{c' c} \sqrt{d' d}}.\]

根据[柯西-施瓦茨不等式](../Page/柯西-施瓦茨不等式.md "wikilink")，我们有

\[\left(c' \Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1/2} \right) d \leq \left(c' \Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1/2} \Sigma _{YY} ^{-1/2} \Sigma _{YX} \Sigma _{XX} ^{-1/2} c \right)^{1/2} \left(d' d \right)^{1/2},\]

\[\rho \leq \frac{\left(c' \Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1} \Sigma _{YX} \Sigma _{XX} ^{-1/2} c \right)^{1/2}}{\left(c' c \right)^{1/2}}.\]

如果向量 \(d\) 和
\(\Sigma _{YY} ^{-1/2} \Sigma _{YX} \Sigma _{XX} ^{-1/2} c\)
共线，那么上式相等。此外，如果 \(c\) 是矩阵
\(\Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1} \Sigma _{YX} \Sigma _{XX} ^{-1/2}\)
(见[Rayleigh quotient](../Page/Rayleigh_quotient.md "wikilink"))
最大特征值对应的[特征向量](../Page/特征向量.md "wikilink")，那么就可以得到相关的最大值。随后的典型变量对可以通过减少[特征值的量级来得到](../Page/特征值.md "wikilink")。正交性保证了相关矩阵的对称性。

### 解法

因此解法是：

  - \(c\) 是
    \(\Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1} \Sigma _{YX} \Sigma _{XX} ^{-1/2}\)
    的一个特征向量。
  - \(d\) 是 \(\Sigma _{YY} ^{-1/2} \Sigma _{YX} \Sigma _{XX} ^{-1/2} c\)
    的比例项。

相反地，也有：

  - \(d\) 是
    \(\Sigma _{YY} ^{-1/2} \Sigma _{YX} \Sigma _{XX} ^{-1} \Sigma _{XY} \Sigma _{YY} ^{-1/2}\)
    的一个特征向量。
  - \(c\) 是 \(\Sigma _{XX} ^{-1/2} \Sigma _{XY} \Sigma _{YY} ^{-1/2} d\)
    的比例项。

把坐标反过来，我们有

  - \(a\) 是
    \(\Sigma _{XX} ^{-1} \Sigma _{XY} \Sigma _{YY} ^{-1} \Sigma _{YX}\)
    的一个特征向量。
  - \(b\) 是
    \(\Sigma _{YY} ^{-1} \Sigma _{YX} \Sigma _{XX} ^{-1} \Sigma _{XY}\)
    的一个特征向量。
  - \(a\) 是 \(\Sigma _{XX} ^{-1} \Sigma _{XY} b\) 的比例项。
  - \(b\) 是 \(\Sigma _{YY} ^{-1} \Sigma _{YX} a\) 的比例项。

那么相关变量定义为：

\[U = c' \Sigma _{XX} ^{-1/2} X = a' X\]

\[V = d' \Sigma _{YY} ^{-1/2} Y = b' Y\]

### 实现

典型相关分析可以用一个相关矩阵的[奇异值分解来解决](../Page/奇异值分解.md "wikilink")。\[4\]
以下是它在一些语言中的函数 \[5\]

  - [MATLAB](../Page/MATLAB.md "wikilink") as
    [canoncorr](http://www.mathworks.co.uk/help/stats/canoncorr.html)
  - [R](../Page/R_\(programming_language\).md "wikilink") as
    [cancor](http://stat.ethz.ch/R-manual/R-devel/library/stats/html/cancor.html)
    or in [FactoMineR](http://factominer.free.fr/)
  - [SAS](../Page/SAS_language.md "wikilink") as [proc
    cancorr](http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_cancorr_sect005.htm)
  - [Scikit-Learn](../Page/Scikit-Learn.md "wikilink"),
    [Python](../Page/Python.md "wikilink") as [Cross
    decomposition](http://scikit-learn.org/stable/modules/cross_decomposition.html)

## 假设检验

每一行可以用下面的方法检测其重要性。由于相关是排好序的，也就是说行 \(i\) 为 0 意味着所有后续的相关都为 0。如果我们在一个样本中有
\(p\) 个独立观测，对 \(i = 1,\dots, \min\{m,n\}\)，\(\widehat{\rho}_i\)
是其估计相关。对第 \(i\) 行，测试统计为：

\[\chi ^2 = - \left( p - 1 - \frac{1}{2}(m + n + 1)\right) \ln \prod _ {j = i} ^{\min\{m,n\}} (1 - \widehat{\rho}_j^2),\]

上面渐近为一个对大 \(p\) 有 \((m - i + 1)(n - i + 1)\)
个[自由度的](../Page/自由度.md "wikilink")[卡方分布](../Page/卡方分布.md "wikilink")。\[6\]
由于所有从 \(\min\{m,n\}\) 到 \(p\) 的相关从逻辑上来说都是 0，所以在这一点之后的乘积都是不相关的。

## 实际运用

## 例子

## 与principal angles的连接

## 参见

  - [Generalized Canonical
    Correlation](../Page/Generalized_Canonical_Correlation.md "wikilink")
  - [Multilinear subspace
    learning](../Page/Multilinear_subspace_learning.md "wikilink")
  - [RV coefficient](../Page/RV_coefficient.md "wikilink")
  - [Principal angles](../Page/Principal_angles.md "wikilink")
  - [主成分分析](../Page/主成分分析.md "wikilink")
  - [Regularized canonical correlation
    analysis](../Page/Regularized_canonical_correlation_analysis.md "wikilink")
  - [奇异值分解](../Page/奇异值分解.md "wikilink")
  - [Partial least squares
    regression](../Page/Partial_least_squares_regression.md "wikilink")

## 参考文献

## 外部链接

  -
  - [A note on the ordinal canonical-correlation analysis of two sets of
    ranking scores](http://mpra.ub.uni-muenchen.de/12796/) (Also
    provides a FORTRAN program)- in J. of Quantitative Economics 7(2),
    2009, pp. 173-199

  - [Representation-Constrained Canonical Correlation Analysis: A
    Hybridization of Canonical Correlation and Principal Component
    Analyses](http://ssrn.com/abstract=1331886) (Also provides a FORTRAN
    program)- in J. of Applied Economic Sciences 4(1), 2009, pp. 115-124

[Category:协方差与相关性](https://zh.wikipedia.org/wiki/Category:协方差与相关性 "wikilink")
[Category:多重变量分析](https://zh.wikipedia.org/wiki/Category:多重变量分析 "wikilink")

1.
2.
3.
4.
5.
6.
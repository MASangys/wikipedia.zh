> 本文内容由[基音檢測算法](https://zh.wikipedia.org/wiki/基音檢測算法)转换而来。


**基音檢測演算法**（英語：**pitch detection algorithm**，縮寫：**PDA**）是估計[周期性或](https://zh.wikipedia.org/wiki/週期性 "wikilink")[訊號的](https://zh.wikipedia.org/wiki/訊號 "wikilink")[音高](../Page/音高.md "wikilink")或[基本頻率](../Page/基本頻率.md "wikilink")的算法。該算法主要用於[語音或樂音的信號處理中](https://zh.wikipedia.org/wiki/語音處理 "wikilink")。基音檢測算法既可以單獨從[時域或](https://zh.wikipedia.org/wiki/時域 "wikilink")[頻域](../Page/頻域.md "wikilink")的角度實現，也可以同時利用時域和頻域。

基音檢測算法的用途廣泛，在[語音學](https://zh.wikipedia.org/wiki/語音學 "wikilink")、、[語音編碼](../Page/語音編碼.md "wikilink")和[電子音樂](../Page/電子音樂.md "wikilink")表演中均有重要位置。這些不同的需求使得通用算法的產生更為困難，故目前尚不存在完美的基音檢測算法，實際使用中有一系列算法共存。多數基音檢測算法大致可歸類為下述分類中的一種\[1\]。

通常情況下，基音檢測算法會估計準周期性信號的周期。周期的倒數即為頻率。

<div>

## 常見的算法

最簡單的方法之一是算出信號[零點間的間隔](https://zh.wikipedia.org/wiki/零點 "wikilink")（[過零率](https://zh.wikipedia.org/wiki/過零率 "wikilink")）。這種方法的缺點在於它無法應對諸如多個周期不同的正弦波或[噪音](../Page/噪音.md "wikilink")這樣的覆雜[波形](https://zh.wikipedia.org/wiki/波形 "wikilink")。不過這並不意味著這種方法一無是處，在只有單一聲源的情景中過零率是個不錯的基音檢測指標。這種算法相當易於實現。

更複雜的方法會將原訊號平移一些時間，去跟原本訊號內積比對相似度，若平移若幹時間後的訊號與原訊號很相似，則平移時間非常可能是該訊號之週期，透過嘗試不同的平移時間，可把平移時間對相似度作圖，找出相似度最大的週期， 像是AMDF演算法 ([平均幅度差函數](https://zh.wikipedia.org/wiki/平均幅度差函數 "wikilink")), ASMDF演算法 ([平均方均差函數](https://zh.wikipedia.org/wiki/平均方均差函數 "wikilink"))和其他類似的[自相關函數法](https://zh.wikipedia.org/wiki/自相關函數 "wikilink")，可以精確的找出基音。但是自相關函數法有時會因為[雜訊](../Page/雜訊.md "wikilink")太多、[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")、[泛音](../Page/泛音.md "wikilink")等因素（通常是“八度音程錯誤”），導致判斷錯誤。他們可以很好地應對噪聲信號（取決於實際狀況），但不能很好地處理[複音音樂](../Page/複音音樂.md "wikilink")（涉及多個音符)。

目前最精確的基音檢測算法會先結合各種找相似度的方法（內積、差值），並透過人類的經驗法則去修正去設門檻值，像是若訊號為音訊，可確定頻率範圍在20赫茲到20000赫茲間，可先鎖定平移時間在0.00005秒到0.05秒的範圍間，最後透過[機率模型或](https://zh.wikipedia.org/wiki/機率模型 "wikilink")[機器學習的方法來判斷音高](https://zh.wikipedia.org/wiki/機器學習 "wikilink")。像是廣泛被採用的[YIN演算法](https://zh.wikipedia.org/wiki/YIN演算法 "wikilink")\[2\]與[MPM演算法](https://zh.wikipedia.org/wiki/MPM演算法 "wikilink")\[3\]，皆為自相關函數法的進階版，但仍侷限在單音的音頻偵測，若訊號為[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")，同時有兩個音源，往往會採用頻域的方法。

## 基于頻域的算法

若訊號為[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")，要同時偵測兩個以上的音源之頻率，在頻域中是可行的，首先會先將訊號轉為[頻譜](https://zh.wikipedia.org/wiki/頻譜 "wikilink")\[4\] ，常見的方法是透過[快速傅立葉變換](https://zh.wikipedia.org/wiki/快速傅立葉變換 "wikilink")，可在有限運算資源下，得到非常有效的準確度。

常見的頻域方法包含[泛音內積頻譜法](https://zh.wikipedia.org/wiki/泛音內積頻譜法 "wikilink")\[5\]\[6\]、[倒頻譜分析](https://zh.wikipedia.org/wiki/倒頻譜分析 "wikilink")\[7\]，[最大似然估計法](https://zh.wikipedia.org/wiki/最大似然估計法 "wikilink")，他們都是由預設的頻率對照表，試圖從訊號頻譜特徵中，找到對應之頻率\[8\]。

為了改進從離散傅立葉頻譜得到的基音估計，可以使用[重新分佈法](https://zh.wikipedia.org/wiki/頻譜重新分佈法 "wikilink") (基於相位) or [格蘭徳克插值](https://zh.wikipedia.org/wiki/格蘭徳克插值 "wikilink") (基於幅度) 的技術超出離散傅立葉頻段提供的精度。 布朗和普克特提供了另一種基於階段的方法 \[9\]

## 基于频域和时域的算法

頻譜/動態的基音檢測法，像是YAAPT\[10\]\[11\]，結合了時域和頻域，時域方面，透過[自相關函數法](https://zh.wikipedia.org/wiki/自相關函數 "wikilink")，頻域則是透過頻譜資訊來辨識出音高，並從較為可能的音高種類中，利用[動態規劃找出最佳的音高選擇](https://zh.wikipedia.org/wiki/動態規劃 "wikilink")，這種結合時域和頻域的演算法，可以結合更多資訊，降低時域或頻域所獨立造成的誤差。

## 語音訊號的基本頻率

語音訊號的基本頻率範圍大約為40赫茲到600赫茲。\[12\]

自相關函數法需要至少兩個周期才能偵測頻率，假如音訊的基本頻率為40赫茲，至少需要0.05秒的語音訊號才能分析。然而在0.05秒內，具有較高基頻的語音不一定在整個窗口中具有相同的基頻。\[13\]

## 參考資料

## 另请参阅

  -
  -
  - [线性预测编码](../Page/线性预测编码.md "wikilink")

  - [MUSIC演算法](../Page/MUSIC演算法.md "wikilink")

[Category:数字信号处理](https://zh.wikipedia.org/wiki/Category:数字信号处理 "wikilink")

1.  D. Gerhard. [Pitch Extraction and Fundamental Frequency: History and Current Techniques](http://www.cs.uregina.ca/Research/Techreports/2003-06.pdf), technical report, Dept. of Computer Science, University of Regina, 2003.
2.  A. de Cheveigné and H. Kawahara. [YIN, a fundamental frequency estimator for speech and music.](http://www.ircam.fr/pcm/cheveign/pss/2002_JASA_YIN.pdf) The Journal of the Acoustical Society of America, 111:1917, 2002.
3.  P. McLeod and G. Wyvill. [A smarter way to find pitch.](http://www.cs.otago.ac.nz/tartini/papers/A_Smarter_Way_to_Find_Pitch.pdf) In Proceedings of the International Computer Music Conference (ICMC’05), 2005.
4.
5.  [Pitch Detection Algorithms](http://cnx.org/content/m11714/latest/), online resource from [Connexions](https://zh.wikipedia.org/wiki/Connexions "wikilink")
6.  A. Michael Noll, “Pitch Determination of Human Speech by the Harmonic Product Spectrum, the Harmonic Sum Spectrum and a Maximum Likelihood Estimate,” Proceedings of the Symposium on Computer Processing in Communications, Vol. XIX, Polytechnic Press: Brooklyn, New York, (1970), pp. 779-797.
7.  A. Michael Noll, “Cepstrum Pitch Determination,” Journal of the Acoustical Society of America, Vol. 41, No. 2, (February 1967), pp. 293-309.
8.  Mitre, Adriano; Queiroz, Marcelo; Faria, Régis. [Accurate and Efficient Fundamental Frequency Determination from Precise Partial Estimates.](http://www.ime.usp.br/~mqz/Mitre_AESBR2006.pdf) Proceedings of the 4th AES Brazil Conference. 113-118, 2006.
9.  Brown JC and Puckette MS (1993). A high resolution fundamental frequency determination based on phase changes of the Fourier transform. J. Acoust. Soc. Am. Volume 94, Issue 2, pp. 662-667 [](https://archive.is/20130414073448/http://asadl.org/jasa/resource/1/jasman/v94/i2/p662_s1?isAuthorized=no)
10. Stephen A. Zahorian and Hongbing Hu. [A Spectral/temporal method for Robust Fundamental Frequency Tracking.](http://bingweb.binghamton.edu/~hhu1/paper/Zahorian2008spectral.pdf) The Journal of the Acoustical Society of America, 123 (6), 2008.
11. Stephen A. Zahorian and Hongbing Hu. [YAAPT Pitch Tracking MATLAB Function](http://ws2.binghamton.edu/zahorian/yaapt.htm)
12.
13.
**基音檢測算法**（英语：**pitch detection
algorithm**，缩写：**PDA**）是估计[周期性或](https://zh.wikipedia.org/wiki/週期性 "wikilink")[訊號的](https://zh.wikipedia.org/wiki/訊號 "wikilink")[音高或](../Page/音高.md "wikilink")[基本頻率的算法](../Page/基本頻率.md "wikilink")。该算法主要用于[語音或乐音的信号处理中](../Page/语音处理.md "wikilink")。基音检测算法既可以单独从[時域或](https://zh.wikipedia.org/wiki/時域 "wikilink")[頻域的角度实现](../Page/頻域.md "wikilink")，也可以同时利用时域和频域。

基音檢測算法的用途广泛，在[语音学](../Page/语音学.md "wikilink")、、[語音編碼和](../Page/語音編碼.md "wikilink")[电子音乐表演中均有重要位置](https://zh.wikipedia.org/wiki/电子音乐 "wikilink")。这些不同的需求使得通用算法的产生更为困难，故目前尚不存在完美的基音检测算法，实际使用中有一系列算法共存。多数基音检测算法大致可归类为下述分类中的一种\[1\]。

通常情况下，基音检测算法会估计准周期性信号的周期。周期的倒数即为频率。

最简单的方法之一是算出信号[零点间的间隔](../Page/零点.md "wikilink")（[过零率](https://zh.wikipedia.org/wiki/过零率 "wikilink")）。这种方法的缺点在于它无法应对诸如多个周期不同的正弦波或[噪音这样的复杂](../Page/噪音.md "wikilink")[波形](https://zh.wikipedia.org/wiki/波形 "wikilink")。不过这并不意味着这种方法一无是处，在只有单一声源的情景中过零率是个不错的基音检测指标。这种算法相当易于实现。

更複雜的方法會將原訊號平移一些時間，去跟原本訊號內積比對相似度，若平移若干時間後的訊號與原訊號很相似，則平移時間非常可能是該訊號之週期，透過嘗試不同的平移時間，可把平移時間對相似度作圖，找出相似度最大的週期，這類的方法稱為[自相關函數法](https://zh.wikipedia.org/wiki/自相關函數 "wikilink")，可以精確的找出基音。但是自相關函數法有時會因為[雜訊太多](../Page/雜訊.md "wikilink")、[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")、[泛音等因素](../Page/泛音.md "wikilink")，導致判斷錯誤。

目前最精確的基音檢測算法會先結合各種找相似度的方法（內積、差值），並透過人類的經驗法則去修正去設門檻值，像是若訊號為音訊，可確定頻率範圍在20赫茲到20000赫茲間，可先鎖定平移時間在0.00005秒到0.05秒的範圍間，最後透過[機率模型或](https://zh.wikipedia.org/wiki/機率模型 "wikilink")[機器學習的方法來判斷音高](https://zh.wikipedia.org/wiki/機器學習 "wikilink")。像是廣泛被採用的[YIN演算法](https://zh.wikipedia.org/wiki/YIN演算法 "wikilink")\[2\]與[MPM演算法](https://zh.wikipedia.org/wiki/MPM演算法 "wikilink")\[3\]，皆為自相關函數法的進階版，但仍侷限在單音的音頻偵測，若訊號為[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")，同時有兩個音源，往往會採用頻域的方法。

<div>

## 基于頻域的算法

若訊號為[複音](https://zh.wikipedia.org/wiki/複音 "wikilink")，要同時偵測兩個以上的音源之頻率，在頻域中是可行的，首先會先將訊號轉為[頻譜](https://zh.wikipedia.org/wiki/頻譜 "wikilink")\[4\]
，常見的方法是透過[快速傅立葉變換](https://zh.wikipedia.org/wiki/快速傅立葉變換 "wikilink")，可在有限運算資源下，得到非常有效的準確度。

常見的頻域方法包含[泛音內積頻譜法](https://zh.wikipedia.org/wiki/泛音內積頻譜法 "wikilink")\[5\]\[6\]、[倒頻譜分析](../Page/倒頻譜.md "wikilink")\[7\]，[最大似然估計法](https://zh.wikipedia.org/wiki/最大似然 "wikilink")，他們都是由預設的頻率對照表，試圖從訊號頻譜特徵中，找到對應之頻率\[8\]。

## 基于频域和时域的算法

頻譜/動態的基音檢測法，像是YAAPT\[9\]\[10\]，結合了時域和頻域，時域方面，透過自相關函數法，頻域則是透過頻譜資訊來辨識出音高，並從較為可能的音高種類中，利用動態規劃找出最佳的音高選擇，這種結合時域和頻域的演算法，可以結合更多資訊，降低時域或頻域所獨立造成的誤差。

## 語音訊號的基本頻率

語音訊號的基本頻率範圍大約為40赫茲到600赫茲。

自相關函數法需要至少兩個周期才能偵測頻率，假如音訊的基本頻率為40赫茲，至少需要0.05秒的語音訊號才能分析。

## 參考資料

## 另请参阅

  -
  -
  - [线性预测编码](../Page/线性预测编码.md "wikilink")

[Category:数字信号处理](https://zh.wikipedia.org/wiki/Category:数字信号处理 "wikilink")

1.  D. Gerhard. [Pitch Extraction and Fundamental Frequency: History and
    Current
    Techniques](http://www.cs.uregina.ca/Research/Techreports/2003-06.pdf),
    technical report, Dept. of Computer Science, University of Regina,
    2003.
2.  A. de Cheveigné and H. Kawahara. [YIN, a fundamental frequency
    estimator for speech and
    music.](http://www.ircam.fr/pcm/cheveign/pss/2002_JASA_YIN.pdf) The
    Journal of the Acoustical Society of America, 111:1917, 2002.
3.  P. McLeod and G. Wyvill. [A smarter way to find
    pitch.](http://www.cs.otago.ac.nz/tartini/papers/A_Smarter_Way_to_Find_Pitch.pdf)
    In Proceedings of the International Computer Music Conference
    (ICMC’05), 2005.
4.
5.  [Pitch Detection Algorithms](http://cnx.org/content/m11714/latest/),
    online resource from
    [Connexions](https://zh.wikipedia.org/wiki/Connexions "wikilink")
6.  A. Michael Noll, “Pitch Determination of Human Speech by the
    Harmonic Product Spectrum, the Harmonic Sum Spectrum and a Maximum
    Likelihood Estimate,” Proceedings of the Symposium on Computer
    Processing in Communications, Vol. XIX, Polytechnic Press: Brooklyn,
    New York, (1970), pp. 779-797.
7.  A. Michael Noll, “Cepstrum Pitch Determination,” Journal of the
    Acoustical Society of America, Vol. 41, No. 2, (February 1967), pp.
    293-309.
8.  Mitre, Adriano; Queiroz, Marcelo; Faria, Régis. [Accurate and
    Efficient Fundamental Frequency Determination from Precise Partial
    Estimates.](http://www.ime.usp.br/~mqz/Mitre_AESBR2006.pdf)
    Proceedings of the 4th AES Brazil Conference. 113-118, 2006.
9.  Stephen A. Zahorian and Hongbing Hu. [A Spectral/temporal method for
    Robust Fundamental Frequency
    Tracking.](http://bingweb.binghamton.edu/~hhu1/paper/Zahorian2008spectral.pdf)
    The Journal of the Acoustical Society of America, 123 (6), 2008.
10. Stephen A. Zahorian and Hongbing Hu. [YAAPT Pitch Tracking MATLAB
    Function](http://ws2.binghamton.edu/zahorian/yaapt.htm)
> 本文内容由[多元分类](https://zh.wikipedia.org/wiki/多元分类)转换而来。


在[机器学习](../Page/机器学习.md "wikilink")中，**多元分类**是将实例[分配到多个](https://zh.wikipedia.org/wiki/分类问题 "wikilink")（多于两个）类别中的其中一个（将实例分配到两个类别中的其中一个被称为[二分类](https://zh.wikipedia.org/wiki/二分类 "wikilink")）。

显然，分类算法可以分为二分类和多分类两种，而多分类算法可以通过将其转化为多个二分类来实现。

需要注意的是，多分类不应和[多标签分类相混淆](https://zh.wikipedia.org/wiki/多标签分类 "wikilink")：多标签分类可以为每个实例预测多个标签，即同一个实例可以同时被分配到多个类别。

## 一般策略

这部分讨论将多分类问题转化为多个二分类问题的策略。

### One-vs.-rest

*one-vs.-rest*\[1\] （或*one-vs.-all*，OvA或OvR）策略需要为每一个类别分别建立一个唯一的二分类基分类器，属于此类的所有样本均为正例，其余的全部为负例。这一策略需要基分类器去产生一个实值置信度以供决策，而不仅仅是预测出一个类标签：只是预测出类标签可能会导致归类的不明确（可能有多个基分类器都预测为正例），以致于一个样本会被预测属于多个类别。\[2\]\[3\]

通过OvR方法使用二分类算法建立多分类学习器，其伪代码表示如下：

  -
    输入：
      - 二分类训练算法
      - 样本集合
      - 标签集合 使 ∈ {1, … } 是样本的类标签
    输出：
      - 一个二分类分类器序列， ∈ {1, …, }
    执行过程：
      - 对于{1, …, }中的每个元素：
          - 构建一个新标签向量，其中 *k*}}时 1}}，否则  0（或-1）}}
          - 将 应用于、 以获得

当进行多分类时，需要将所有的二分类分类器应用于一个未知样本，的最终分类类别即为产生最大置信度的分类器所对应的标签：

\[\hat{y} = \arg\max_{k \in 1 \ldots K} f_k(x)\]

尽管这一策略很流行，但它是一个受到些许问题困扰的[启发式算法](../Page/启发法.md "wikilink")。首先，不同分类器之间置信度分布可能不同，这些分类器各自输出的置信度之间不一定具有可比性。其次，即使一个多分类训练集的类别是均衡分布的，其所对应的二分类所看到的类别分布也是不均衡的，因为它们所看到的负例个数通常远多于正例个数（即类别不平衡问题）。\[4\]

### One-vs.-one

*在one-vs.-one* （OvO） 的转化中，对于一个K类多分类问题，训练  个二分类分类器；每一个二分类分类器从初始多分类训练集中收集其中两个类别的所有样本，并学习去区分这两个类别。在预测时，会有一个投票：所有  个二分类分类器被应用于一个未知样本，并且那个得到最多“+1”预测的类别会成为最终的多分类预测结果。\[5\]

像OvR一样, OvO也受些许问题困扰：在它输入空间的一些区域会收到相同数目的投票。\[6\]

## 另见

  - [二分类](https://zh.wikipedia.org/wiki/二分类 "wikilink")
  - [一分类](https://zh.wikipedia.org/wiki/一分类 "wikilink")
  - [多标签分类](https://zh.wikipedia.org/wiki/多标签分类 "wikilink")

## 注释

## 参考资料

[Category:分類演算法](https://zh.wikipedia.org/wiki/Category:分類演算法 "wikilink") [Category:统计分类](https://zh.wikipedia.org/wiki/Category:统计分类 "wikilink")

1.
2.
3.  在多标签分类中，OvR被认为是“二元相关性”（binary relevance），并且被预测到多个类别被认为是多标签分类的自身特色，而非问题
4.
5.
6.
  -
    *请不要和[多标签分类相混淆](https://zh.wikipedia.org/wiki/多标签分类 "wikilink")*

在[机器学习中](../Page/机器学习.md "wikilink")，**多元分类**
是将示例[归类为多个](https://zh.wikipedia.org/wiki/分类问题 "wikilink")（大于两个）类别中的一类（将示例归为两类中的一类被称为二元分类）。

一些分类算法自然地允许使用超过两类，另一些自然是二元分类算法；然而，它们可以通过多种策略转化为多元分类。

多元分类不应该和[多标签分类相混淆](https://zh.wikipedia.org/wiki/多标签分类 "wikilink")，多标签分类要为每个示例预测多个标签，即一个示例可以同时被归为多个类别。

## 一般策略

这部分讨论将多元分类问题化简为多个二元分类问题的策略。

### One-vs.-rest

*one-vs.-rest*\[1\]
（或*one-vs.-all*，OvA或OvR）策略需要为每一个类建立一个唯一的分类器，属于此类的所有样例均为正例，其余的全部为负例。这一策略需要基础分类器去产生一个实值置信度以供决策，而不仅仅是一个类标签；单独产生的类标签可能会导致归类的不明确，以致于一个样例会被预测属于多个类。\[2\]\[3\]

用伪代码表示，一个OvA学习者的训练算法从一个二元分类学习者中建立，具体如下：

  -
    输入：
      - ，一个学习者（二元分类器的训练策略）

      - 样例集

      - 标签集 使 ∈ {1, … } 是样例的标签
    输出：
      - 一个分类器的序列 ，  ∈ {1, …, }
    程序：
      - For each  in {1, …, }:
          - 构建一个新标签向量  1}} where  *k*}}, 0 (or −1) elsewhere
          - 将 应用于， 以获得

做出决策意味着要将所有的分类器应用于一个未知样例 ，并且预测出产生最大置信度的分类器所对应的标签：

\[\hat{y} = \arg\max_{k \in 1 \ldots K} f_k(x)\]

尽管这一策略很流行，但它是一个受些许问题困扰的[启发法](../Page/启发法.md "wikilink")。首先，分类器之间置信值的范围可能不同。其次，即使一个训练集的类是均衡分布的，二元分类器学习者所看到的类分布也是不均衡的，因为它们所看到的负例集通常比正例集来的大。\[4\]

### One-vs.-one

*在one-vs.-one* （OvO） 化简中，对于一个K类多元问题，训练
个二元分类器；每一个从初始训练集中收到一对类样例，并且必须学习去区分这两个类。在预测时间内，会有一个投票：所有
 个解释器被应用于一个未知样例，并且那个得到最多"+1" 预测的类会成为组合分类器的预测结果。\[5\]

像OvR一样, OvO也受些许问题困扰：在它输入空间的一些区域会收到相同数目的投票。\[6\]

## 另见

  - [二元分类](https://zh.wikipedia.org/wiki/二元分类 "wikilink")
  - [一元分类](https://zh.wikipedia.org/wiki/一元分类 "wikilink")
  - [多标签分类](https://zh.wikipedia.org/wiki/多标签分类 "wikilink")
  - [多元感知器](../Page/感知器.md "wikilink") 在
    [感知器](../Page/感知器.md "wikilink")

## 注释

## 参考资料

[Category:分類演算法](https://zh.wikipedia.org/wiki/Category:分類演算法 "wikilink")
[Category:统计分类](https://zh.wikipedia.org/wiki/Category:统计分类 "wikilink")

1.
2.
3.  在多标签分类中，OvR被认为是“二元相关性”，并且被预测成多个类别被认为是一项特色，而非问题
4.
5.
6.
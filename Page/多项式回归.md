在[统计学中](../Page/统计学.md "wikilink")，
**多项式回归**是[回归分析的一种形式](../Page/迴歸分析.md "wikilink")，其中[自变量](../Page/自变量和因变量.md "wikilink")
x 和[因变量](../Page/自变量和因变量.md "wikilink") y 之间的关系被建模为关于 x 的 n
次[多项式](https://zh.wikipedia.org/wiki/多项式 "wikilink")。多项式回归拟合x的值与
y 的相应条件均值之间的非线性关系，表示为
E(y|x)，并且已被用于描述非线性现象，例如组织的生长速率\[1\]、湖中碳同位素的分布\[2\]以及沉积物和流行病的发展\[3\]。虽然多项式回归是拟合数据的非线性模型，但作为[统计估计问题](../Page/估计理论.md "wikilink")，它是线性的。在某种意义上，回归函数
E(y|x)
在从数据估计到的未知参数中是线性的。因此，多项式回归被认为是多元[线性回归的特例](../Page/線性回歸.md "wikilink")。

由“基线”变量的多项式展开得到的解释性（独立）变量称为高次项，这些变量也用于分类场景。\[4\]

## 历史

多项式回归模型通常使用[最小二乘法来拟合](../Page/最小二乘法.md "wikilink")。在[高斯-马尔可夫定理的条件下](../Page/高斯-马尔可夫定理.md "wikilink")，最小二乘法最小化系数的无偏估计的[方差](../Page/方差.md "wikilink")。最小二乘法由[勒让德于](../Page/阿德里安-马里·勒让德.md "wikilink")1805年发表，1809年由[高斯发表](../Page/卡爾·弗里德里希·高斯.md "wikilink")。多项式回归实验的第一个设计出现在1815年的
Gergonne 的论文中。\[5\]\[6\]
在二十世纪，多项式回归在[回归分析的发展中起着重要作用](https://zh.wikipedia.org/wiki/回归分析 "wikilink")，更加强调设计和推理的问题。\[7\]

## 定义和实例

[缩略图](https://zh.wikipedia.org/wiki/File:Polyreg_scheffe.svg "fig:缩略图")是使用Scheffé方法构建的95％置信区间。\]\]
回归分析的目标是根据自变量（或自变量向量）x 的值来模拟因变量 y 的期望值。在简单的线性回归中，使用模型

  -
    <math>

y = \\beta_0 + \\beta_1 x + \\varepsilon, \\, </math>

其中ε是未观察到的随机[误差](../Page/误差.md "wikilink")，其以[标量](../Page/标量.md "wikilink")
x 为条件，均值为零。在该模型中，对于 x 值的每个单位增加，y 的条件期望增加 \(\beta_{1}\)个单位。

在许多情况下，这种线性关系可能不成立。例如，如果我们根据合成发生的温度对化学合成的产率进行建模，我们可以发现通过增加每单位温度增加的量来提高产率。在这种情况下，我们可能会提出如下所示的二次模型：

  -
    \(y = \beta_0 + \beta_1x + \beta_2 x^2 + \varepsilon\)。

在该模型中，当温度从x增加到x+1单位时，预期产量会变化\(\beta_1+\beta_2(2x+ 1).\)\(\beta_{1}+\beta_{2}(2x+1)\)。对于
x 的[无穷小变化](../Page/無窮小量.md "wikilink")，对 y 的影响由关于 x
的[导数给出](../Page/导数.md "wikilink")：\(\beta_1+\beta_2(2x+ 1)\),
即使模型在待估计的参数中是线性的，但是产量的变化取决于 x 的事实使得 x 和 y 之间的关系为非线性关系。

通常，我们可以将 y 的期望值建模为 n 次多项式，得到一般多项式回归模型：

  -
    \(y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \cdots + \beta_n x^n + \varepsilon\)<math>

y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\cdots +
\\beta_n x^n + \\varepsilon. \\, </math>。

为了方便，这些模型从[估计的角度来看都是线性的](../Page/估计理论.md "wikilink")，因为回归函数就未知参数β<sub>0</sub>、β<sub>1</sub>等而言是线性的。因此，对于[最小二乘分析](../Page/最小二乘法.md "wikilink")，多项式回归的计算和推理问题可以使用多元回归技术完全解决，这是通过将
x、x<sup>2</sup> 等视为多元回归模型中的独特自变量来完成的。

## 矩阵形式和估计计算

多项式回归模型

  -
    \(y_i \,=\, \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_m x_i^m + \varepsilon_i\  (i = 1, 2, \dots , n)\)

可以由设计矩阵 \(\mathbf{X}\)、响应矢量 \(\vec y\)、矢量参数 \(\vec \beta\)和随机误差向量
\(\vec\varepsilon\)来表示。在第 i 行的 \(\mathbf{X}\)和 \(\vec y\)为第 i 个数据样本的 x 和
y 值。然后该模型可以写成线性方程组：

  -
    \(\begin{bmatrix} y_1\\ y_2\\ y_3 \\ \vdots \\ y_n \end{bmatrix}= \begin{bmatrix} 1 & x_1 & x_1^2 & \dots & x_1^m \\ 1 & x_2 & x_2^2 & \dots & x_2^m \\ 1 & x_3 & x_3^2 & \dots & x_3^m \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & x_n & x_n^2 & \dots & x_n^m \end{bmatrix} \begin{bmatrix} \beta_0\\ \beta_1\\ \beta_2\\ \vdots \\ \beta_m \end{bmatrix} + \begin{bmatrix} \varepsilon_1\\ \varepsilon_2\\ \varepsilon_3 \\ \vdots \\ \varepsilon_n \end{bmatrix},\)

当使用纯矩阵表示法时，将其写为

  -
    \(\vec y = \mathbf{X} \vec \beta + \vec\varepsilon\)\(\vec y = \mathbf{X} \vec \beta + \vec\varepsilon. \,\)。

估计多项式回归系数的向量（使用[最小二乘估计](https://zh.wikipedia.org/wiki/最小二乘 "wikilink")）为

  -
    \(\widehat{\vec \beta} = (\mathbf{X}^\mathsf{T} \mathbf{X})^{-1}\; \mathbf{X}^\mathsf{T} \vec y, \,\)

假设 m\<n 是矩阵可逆的必要条件，那么由于 \(\mathbf{X}\)是
[范德蒙矩阵](../Page/范德蒙矩陣.md "wikilink")，如果所有
\(x_i\)值都不同，则保证可逆性条件成立，这是唯一的最小二乘法的解。

## 解释

虽然多项式回归在技术上是多元线性回归的一个特例，但拟合多项式回归模型的解释需要一个不同的视角。通常难以在多项式回归拟合中解释各个系数，因为基础单项式可以高度相关。例如，当
x 具有在区间 (0,1) 上的[均匀分布时](https://zh.wikipedia.org/wiki/均勻分佈 "wikilink")，x
和 x<sup>2</sup>
具有大约0.97的相关性。尽管可以通过使用[正交多项式来减少相关性](../Page/正交多項式.md "wikilink")，但是通常将拟合的回归函数视为整体来提供更多信息，然后可以使用逐点或同时[置信区间来提供回归函数估计的不确定性](../Page/置信区间.md "wikilink")。

## 替代方法

多项式回归是使用[基函数来模拟两个变量之间的函数关系的回归分析的一个实例](../Page/基函數.md "wikilink")。更具体地说，它用多项式基
\(\varphi (x) \in \mathbb R^{d_\varphi}\)替换线性回归中的
\(x \in \mathbb R^{d_x}\)，如
\([1,x] \mathbin{\stackrel{\varphi}{\rightarrow}} [1,x,x^2,\ldots,x^d]\)。多项式基的一个缺点在于基函数是“非局部的”，这意味在给定值x = x<sub>0</sub>
处 y 的拟合值很大程度依赖于 x 远离 x<sub>0</sub>的数据值<ref> Such "non-local" behavior is
a property of [analytic
functions](https://zh.wikipedia.org/wiki/Analytic_function#Properties_of_analytic_functions "wikilink")
that are not constant (everywhere). Such "non-local" behavior has been
widely discussed in statistics:

  - </ref>。在现代统计中，多项式基函数与新的基函数一起使用，如[样条函数](../Page/样条函数.md "wikilink")、[径向基函数和](../Page/径向基函数.md "wikilink")[小波](https://zh.wikipedia.org/wiki/小波 "wikilink")。这些基函数族为许多类型的数据提供了更简约的拟合。

多项式回归的目标是模拟独立变量和因变量之间的非线性关系（在自变量和因变量的条件均值之间）。这与非参数回归的目标类似，非参数回归旨在捕获非线性回归关系。因此，诸如平滑的非参数回归方法可以是多项式回归的有效替代方案。这些方法中的一些利用了经典多项式回归的局部形式。\[8\]
传统多项式回归的一个优点是可以使用多元回归的推理框架（当使用其他基函数族，如样条函数时也是如此）。

另外一种方法是使用核方法模型，如[支持向量回归和多项式核](../Page/支持向量机.md "wikilink")。

## 参见

  - [曲线拟合](../Page/曲線擬合.md "wikilink")

  - [线性回归](../Page/線性回歸.md "wikilink")

  -
  -
  - [多项式差值](../Page/多项式插值.md "wikilink")

  - [反应曲面法](../Page/反應曲面法.md "wikilink")

  -
## 参考文献

<references group="">

</references>

[Category:回归分析](https://zh.wikipedia.org/wiki/Category:回归分析 "wikilink")
[Category:有未审阅翻译的页面](https://zh.wikipedia.org/wiki/Category:有未审阅翻译的页面 "wikilink")

1.
2.
3.
4.
5.
6.
7.
8.
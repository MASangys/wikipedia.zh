在[计算机科学](../Page/计算机科学.md "wikilink")中，**并行编程模型**是[并行计算](../Page/并行计算.md "wikilink")机架构的[抽象化](https://zh.wikipedia.org/wiki/抽象化_\(计算机科学\) "wikilink")，通过它可方便的表达[算法](../Page/算法.md "wikilink")和它们在[程序中的合成](https://zh.wikipedia.org/wiki/程序 "wikilink")。判别编程模型的价值可以通过它的通用性：在各种不同架构上能表达多大的范围的不同问题，和它的性能：编译的程序在执行时有多高的效率\[1\]。并行编程模型的实现形式可以是从“顺序编程”语言中调用的[函式库](https://zh.wikipedia.org/wiki/函式库 "wikilink")，作为现存语言的扩展，或作为全新的语言。

围绕特定编程模型的共识是很重要的，这可导致建造不同的并行计算机来支持这个模型，从而促进软件的[可移植性](https://zh.wikipedia.org/wiki/软件可移植性 "wikilink")。在这个意义上，编程模型被称为在硬件和软件之间的\[2\]。

## 并行编程模型的分类

并行编程模型的分类可以宽泛的分成两个领域：进程交互和问题分解\[3\]\[4\]\[5\]。

### 进程交互

进程交互有关于并行进程能够籍此相互通信的机制。最常见的交互形式是共享内存和消息传递，但是交互也可以是隐式的（对编程者不可见）。

#### 共享内存

共享内存是在进程间传递数据的高效方式。在共享内存模型中，并行进程共享它们可以异步读与写的全局地址空间。异步并发访问可能导致[竞争条件](https://zh.wikipedia.org/wiki/竞争条件 "wikilink")，和用来避免它们的机制如：[锁](https://zh.wikipedia.org/wiki/锁_\(计算机科学\) "wikilink")、[信号量](../Page/信号量.md "wikilink")和[监视器](https://zh.wikipedia.org/wiki/监视器_\(程序同步化\) "wikilink")。常规的[多核处理器直接支持共享内存](https://zh.wikipedia.org/wiki/多核处理器 "wikilink")，很多并行编程语言和库在设计上利用了它，比如：[Cilk](../Page/Cilk.md "wikilink")、[OpenMP](../Page/OpenMP.md "wikilink")和。

#### 消息传递

在消息传递模型中，并行进程通过消息传递相互交换数据。这种通信可以时异步的，就是说消息可以在接收者准备好之前发出，或时同步的，就是说消息发出前接收者必须准备好。[通信顺序进程](https://zh.wikipedia.org/wiki/通信顺序进程 "wikilink")（CSP）形式化了使用同步通信信道来连接进程的消息传递，并引出了重要的语言如：[Occam](https://zh.wikipedia.org/wiki/Occam "wikilink")、[Limbo和](https://zh.wikipedia.org/wiki/Limbo_\(程式语言\) "wikilink")[Go](../Page/Go.md "wikilink")。与之相对，[演员模型使用异步消息传递](https://zh.wikipedia.org/wiki/演员模型 "wikilink")，并被采用于如下语言的设计中：[D](https://zh.wikipedia.org/wiki/D语言 "wikilink")、[Scala](../Page/Scala.md "wikilink")和SALSA。

#### 隐式交互

在隐式模型中，进程交互对编程者均不可见，转而由编译器和/或运行时系统负责进行交互。隐式并行的两个例子是[领域特定语言](../Page/领域特定语言.md "wikilink")，这里在高级运算内的[并发性](../Page/并发性.md "wikilink")是规定好了的，并且是[函数式编程](../Page/函数式编程.md "wikilink")语言，因为不存在[副作用从而允许无依赖的函数并行执行](../Page/函数副作用.md "wikilink")\[6\]。但是，这类并行难于管理\[7\]，并且函数式语言如和显式的提供了管理并行的特征。

### 问题分解

并行程序由同时执行的进程构成。问题分解有关于规划（formulate）成员进程的方式\[8\]\[9\]。

#### 任务并行

任务并行模型关注[进程或](https://zh.wikipedia.org/wiki/进程 "wikilink")[线程](../Page/线程.md "wikilink")的执行。这些进程通常表现出独特性，并强调对通信的需求。任务并行是表达消息传递通信的自然方式。在[费林分类法中](https://zh.wikipedia.org/wiki/费林分类法 "wikilink")，任务并行通常分类为[MIMD](https://zh.wikipedia.org/wiki/MIMD "wikilink")/[MPMD或](https://zh.wikipedia.org/wiki/MPMD "wikilink")[MISD](https://zh.wikipedia.org/wiki/MISD "wikilink")。

#### 数据并行

数据并行模型关注进行运算所在的数据集，典型的是正规结构的数组。一组任务将在这些数据上运算，但是单独的处于在不相交的分区中。在[费林分类法中](https://zh.wikipedia.org/wiki/费林分类法 "wikilink")，数据并行通常分类为[MIMD](https://zh.wikipedia.org/wiki/MIMD "wikilink")/[SPMD或](https://zh.wikipedia.org/wiki/SPMD "wikilink")[SIMD](https://zh.wikipedia.org/wiki/SIMD "wikilink")。

#### 隐式并行

就像隐式进程交互一样，隐式并行模型不向编程者透露任何编译器、运行时系统或硬件负责的事情。例如，在编译器中[自动并行是把顺序代码转变程并行代码的过程](https://zh.wikipedia.org/wiki/自动并行 "wikilink")，而在计算机架构中，[超标量执行是采用](https://zh.wikipedia.org/wiki/超标量 "wikilink")[指令级并行来进行并行运算的机制](https://zh.wikipedia.org/wiki/指令级并行 "wikilink")。

## 术语

并行计算模型密切关联于[计算模型](../Page/计算模型_\(数学\).md "wikilink")，包括：[细胞自动机](https://zh.wikipedia.org/wiki/细胞自动机 "wikilink")、、[佩特里网](https://zh.wikipedia.org/wiki/佩特里网 "wikilink")、和[演员模型等](https://zh.wikipedia.org/wiki/演员模型 "wikilink")。并行计算模型是用来分析计算进程代价的一种[抽象化](../Page/抽象化.md "wikilink")，但是其自身不必然需要付诸实际，因为它可以被有效的用硬件和/或软件实现。相反的，编程模型特别暗含着对硬件或软件实现的实际考虑\[10\]。

并行编程语言可以基于一种或一个组合的编程模型。例如，[高性能Fortran基于共享内存交互和数据并行问题分解](https://zh.wikipedia.org/wiki/HPF "wikilink")，而[Go](../Page/Go.md "wikilink")提供共享内存交互和消息传递交互。

## 并行编程模型

<table>
<thead>
<tr class="header">
<th><p>名称</p></th>
<th><p>交互类别</p></th>
<th><p>分解类别</p></th>
<th><p>样例实现</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/演员模型" title="wikilink">演员模型</a></p></td>
<td><p>异步消息传递</p></td>
<td><p>任务</p></td>
<td><p><a href="../Page/Erlang.md" title="wikilink">Erlang</a>，<a href="https://zh.wikipedia.org/wiki/D语言" title="wikilink">D</a>，<a href="../Page/Scala.md" title="wikilink">Scala</a>，SALSA</p></td>
</tr>
<tr class="even">
<td><p><a href="https://zh.wikipedia.org/wiki/通信顺序进程" title="wikilink">通信顺序进程</a></p></td>
<td><p>同步消息传递</p></td>
<td><p>任务</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/Occam" title="wikilink">Occam</a>，<a href="../Page/Ada.md" title="wikilink">Ada</a>，<a href="../Page/Go.md" title="wikilink">Go</a>，<a href="https://zh.wikipedia.org/wiki/VerilogCSP" title="wikilink">VerilogCSP</a></p></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/PRAM模型" title="wikilink">并行随机访问机</a></p></td>
<td><p>共享内存</p></td>
<td><p>数据</p></td>
<td><p><a href="../Page/Cilk.md" title="wikilink">Cilk</a>，<a href="../Page/OpenMP.md" title="wikilink">OpenMP</a>，<a href="../Page/CUDA.md" title="wikilink">CUDA</a>，，<a href="https://zh.wikipedia.org/wiki/XMTC" title="wikilink">XMTC</a></p></td>
</tr>
<tr class="even">
<td><p><a href="../Page/整体同步并行计算模型.md" title="wikilink">整体同步并行</a></p></td>
<td><p>共享内存</p></td>
<td><p>任务</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/BSPlib" title="wikilink">BSPlib</a>[11]，<a href="../Page/Giraph.md" title="wikilink">Apache Giraph</a>，</p></td>
</tr>
<tr class="odd">
<td></td>
<td><p>消息传递</p></td>
<td><p>任务</p></td>
<td><p>，<a href="../Page/TensorFlow.md" title="wikilink">TensorFlow</a>，<a href="../Page/Apache_Flink.md" title="wikilink">Apache Flink</a></p></td>
</tr>
<tr class="even">
<td></td>
<td><p>消息传递</p></td>
<td><p>任务</p></td>
<td><p><a href="../Page/Verilog.md" title="wikilink">Verilog</a>，<a href="../Page/VHDL.md" title="wikilink">VHDL</a></p></td>
</tr>
<tr class="odd">
<td><p><a href="../Page/函数式编程.md" title="wikilink">函数式</a></p></td>
<td><p>消息传递</p></td>
<td><p>任务</p></td>
<td><p>，</p></td>
</tr>
<tr class="even">
<td><p><a href="https://zh.wikipedia.org/wiki/LogP模型" title="wikilink">LogP机</a></p></td>
<td><p>同步消息传递</p></td>
<td><p>未指定</p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>

## 参见

  - [自动并行](https://zh.wikipedia.org/wiki/自动并行 "wikilink")
  - [桥接模型](https://zh.wikipedia.org/wiki/桥接模型 "wikilink")
  - [并发计算](../Page/并发计算.md "wikilink")
  - [并行程度](https://zh.wikipedia.org/wiki/并行程度 "wikilink")
  - [显式并行](https://zh.wikipedia.org/wiki/显式并行 "wikilink")
  - [并发及并行编程语言列表](https://zh.wikipedia.org/wiki/并发及并行编程语言列表 "wikilink")
  - [并行外部内存](https://zh.wikipedia.org/wiki/并行外部内存 "wikilink")

## 引用

## 进一步阅读

  -
  -
  -
  -
[Category:并行计算](https://zh.wikipedia.org/wiki/Category:并行计算 "wikilink") [Category:编程典范](https://zh.wikipedia.org/wiki/Category:编程典范 "wikilink")

1.  Skillicorn, David B., "Models for practical parallel computation", International Journal of Parallel Programming, 20.2 133–158 (1991), <https://www.ida.liu.se/~chrke55/papers/modelsurvey.pdf>
2.  Leslie G. Valiant, "A bridging model for parallel computation", Communications of the ACM, Volume 33, Issue 8, August, 1990, pages 103–111.
3.  John E. Savage, Models of Computation: Exploring the Power of Computing, 2008, Chapter 7 (Parallel Computation), <http://cs.brown.edu/~jes/book/>
4.  Ian Foster, Designing and Building Parallel Programs, 1995, Section 1.3, "A Parallel Programming Model", <http://www.mcs.anl.gov/~itf/dbpp/text/node9.html>
5.  Blaise Barney, Introduction to Parallel Computing, "Models", 2015, Lawrence Livermore National Laboratory, <https://computing.llnl.gov/tutorials/parallel_comp/#Models>
6.  Hammond, Kevin. Parallel functional programming: An introduction. In International Symposium on Parallel Symbolic Computation, p. 46. 1994.
7.  McBurney, D. L., and M. Ronan Sleep. "Transputer-based experiments with the ZAPP architecture." PARLE Parallel Architectures and Languages Europe. Springer Berlin Heidelberg, 1987.
8.  Ian Foster, Designing and Building Parallel Programs, 1995, Section 2.2, "Partitioning", <http://www.mcs.anl.gov/~itf/dbpp/text/node16.html>
9.  Blaise Barney, Introduction to Parallel Computing, "Partitioning", 2015, Lawrence Livermore National Laboratory, <https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning>
10. Skillicorn, David B., and Domenico Talia, Models and languages for parallel computation, ACM Computing Surveys, 30.2 123–169 (1998), <https://www.cs.utexas.edu/users/browne/CS392Cf2000/papers/ModelsOfParallelComputation-Skillicorn.pdf>
11. [BSPlib](http://www.bsp-worldwide.org/)
    [BSPonMPI](https://github.com/wijnand-suijlen/bsponmpi)
    [MulticoreBSP](http://www.multicorebsp.com/)
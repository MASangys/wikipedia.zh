> 本文内容由[并行编程模型](https://zh.wikipedia.org/wiki/并行编程模型)转换而来。


在[计算机科学](../Page/计算机科学.md "wikilink")中，**并行编程模型**是[并行计算](../Page/并行计算.md "wikilink")机架构的[抽象化](https://zh.wikipedia.org/wiki/抽象化_\(计算机科学\) "wikilink")，通过它可方便的表达[算法](../Page/算法.md "wikilink")和它们在[程序中的合成](https://zh.wikipedia.org/wiki/程序 "wikilink")。判别编程模型的价值可以通过它的通用性：在各种不同架构上能表达多大范围的不同问题，和它的性能：编译的程序在执行时有多高的效率\[1\]。并行编程模型的实现形式可以是从“顺序编程”语言中调用的[函式库](https://zh.wikipedia.org/wiki/函式库 "wikilink")，作为现存语言的扩展，或作为全新的语言。

围绕特定编程模型的共识是很重要的，这可导致建造不同的并行计算机来支持这个模型，从而促进软件的[可移植性](https://zh.wikipedia.org/wiki/软件可移植性 "wikilink")。在这个意义上，编程模型被称为在硬件和软件之间的\[2\]。

## 并行编程模型的分类

并行编程模型的分类可以宽泛的在两个领域主题下进行：进程交互和问题分解\[3\]\[4\]\[5\]。

### 进程交互

进程交互有关于并行进程能够籍此相互通信的机制。最常见的交互形式是共享内存和消息传递。

#### 共享内存

[共享内存是在进程间传递数据的高效方式](https://zh.wikipedia.org/wiki/共享内存 "wikilink")。在共享内存模型中，并行进程共享它们可以异步读与写的全局地址空间。异步并发访问可能导致[竞争条件](https://zh.wikipedia.org/wiki/竞争条件 "wikilink")，和用来避免它们的机制如：[锁](https://zh.wikipedia.org/wiki/锁_\(计算机科学\) "wikilink")、[信号量](../Page/信号量.md "wikilink")和[监视器](https://zh.wikipedia.org/wiki/监视器_\(程序同步化\) "wikilink")。常规的[多核处理器直接支持共享内存](https://zh.wikipedia.org/wiki/多核处理器 "wikilink")，很多并行编程语言和库在设计上利用了它，比如采用[Fork-join模型](../Page/Fork-join模型.md "wikilink")的：[Cilk](../Page/Cilk.md "wikilink")、[OpenMP](../Page/OpenMP.md "wikilink")和\[6\]。

#### 消息传递

在[消息传递模型中](https://zh.wikipedia.org/wiki/消息传递 "wikilink")，并行进程通过消息传递相互交换数据。这种通信可以时异步的，就是说消息可以在接收者准备好之前发出，或时同步的，就是说消息发出前接收者必须准备好。[通信顺序进程](https://zh.wikipedia.org/wiki/通信顺序进程 "wikilink")（CSP）形式化了使用同步通信通道来连接进程的消息传递，并引出了重要的语言如：[Occam](https://zh.wikipedia.org/wiki/Occam "wikilink")、[Limbo和](https://zh.wikipedia.org/wiki/Limbo_\(程式语言\) "wikilink")[Go](../Page/Go.md "wikilink")。与之相对，[演员模型使用异步消息传递](https://zh.wikipedia.org/wiki/演员模型 "wikilink")，并被采用于如下语言的设计中：[D](https://zh.wikipedia.org/wiki/D语言 "wikilink")、[Scala](../Page/Scala.md "wikilink")和[SALSA](https://wcl.cs.rpi.edu/salsa/)。

#### 分布式内存

指称一类[多处理器计算机系统](https://zh.wikipedia.org/wiki/多处理器 "wikilink")，其中每个[处理器都有自己私有的](https://zh.wikipedia.org/wiki/CPU "wikilink")[内存](https://zh.wikipedia.org/wiki/内存 "wikilink")，计算任务只能在本地数据上运算，如果需要远程数据，计算任务必须与一个或多个远程处理器通信。在分布式内存系统编程中的关键要点是如何把数据分布到各个内存上；依赖于所解决的问题，数据可以静态分布，也可以在节点间移动；数据可以在需要时移动，也可以事先推入新的节点。

[MPI规定了用于分布式内存系统的](https://zh.wikipedia.org/wiki/MPI "wikilink")[通信协议](https://zh.wikipedia.org/wiki/通信协议 "wikilink")，支持点到点通信和集体通信（collective communication）二者。MPI还是[消息传递](https://zh.wikipedia.org/wiki/消息传递 "wikilink")[API](../Page/应用程序接口.md "wikilink")，带有对其特征在任何实现中必须如何表现的协议和语义规定\[7\]。MPI的目标是高性能、可伸缩性和可移植性，目前仍是[高性能计算领域中统治性的模型](https://zh.wikipedia.org/wiki/高性能计算 "wikilink")\[8\]。此外还有支持单边通信（one-sided communication）的[分区全局地址空间](../Page/分区全局地址空间.md "wikilink")模型。

### 问题分解

并行程序由同时执行的进程构成。问题分解有关于规划（formulate）成员进程的方式\[9\]\[10\]。

#### 数据并行

[数据并行模型关注进行运算所在的数据集](https://zh.wikipedia.org/wiki/数据并行 "wikilink")，典型的是正规结构的数组。一组任务将在这些数据上运算，但是单独的处于在不相交的分区中。数据并行通常对应[SPMD编程模型](https://zh.wikipedia.org/wiki/SPMD "wikilink")\[11\]，相应执行模型对应[费林分类法中的](https://zh.wikipedia.org/wiki/费林分类法 "wikilink")[SIMD](https://zh.wikipedia.org/wiki/SIMD "wikilink")（例如[AVX](https://zh.wikipedia.org/wiki/AVX "wikilink")）或[MIMD](https://zh.wikipedia.org/wiki/MIMD "wikilink")（例如[Xeon Phi](https://zh.wikipedia.org/wiki/Xeon_Phi "wikilink")）\[12\]，还有[GPGPU采用的](https://zh.wikipedia.org/wiki/GPGPU "wikilink")\[13\] （例如[NVIDIA Tesla](../Page/NVIDIA_Tesla.md "wikilink")）。

#### 任务并行

[任务并行](../Page/任务并行.md "wikilink")模型关注[进程或](https://zh.wikipedia.org/wiki/进程 "wikilink")[线程](../Page/线程.md "wikilink")的执行。这些进程通常表现出独特性，并强调对通信的需求。任务并行是表达消息传递通信的自然方式。任务并行通常对应[MPMD编程模型](https://zh.wikipedia.org/wiki/MPMD "wikilink")，与[SPMD的区别在于适合解决的问题而非执行模型](https://zh.wikipedia.org/wiki/SPMD "wikilink")\[14\]。

### 隐式并行

与上述相反，不向编程者透露任何编译器、运行时系统或硬件负责的事情。例如，在编译器中是把顺序代码转变程并行代码的过程；而在计算机架构中，[超标量执行是采用](https://zh.wikipedia.org/wiki/超标量 "wikilink")[指令级并行来进行并行运算的机制](https://zh.wikipedia.org/wiki/指令级并行 "wikilink")，因自身限制而被实际利用为[同时多线程](../Page/同时多线程.md "wikilink")/[超线程](https://zh.wikipedia.org/wiki/超线程 "wikilink")。

在隐式并行中，进程交互对编程者均不可见，转而由编译器和/或运行时系统负责进行交互。[函数式编程](../Page/函数式编程.md "wikilink")语言不存在[副作用](../Page/函数副作用.md "wikilink")，允许无依赖的函数并行执行，人们已经进行了很多有关的研究实验\[15\]。以和[SAC为代表的一类](https://zh.wikipedia.org/wiki/SAC编程语言 "wikilink")语言，是可以高效隐式并行的函数式编程语言，其关键特征是[单赋值和](https://zh.wikipedia.org/wiki/单赋值 "wikilink")。

## 术语

并行计算模型是[计算模型的一大范畴](../Page/计算模型_\(数学\).md "wikilink")，包括：[细胞自动机](https://zh.wikipedia.org/wiki/细胞自动机 "wikilink")、[PRAM机](https://zh.wikipedia.org/wiki/PRAM模型 "wikilink")、[LogP机](https://zh.wikipedia.org/wiki/LogP模型 "wikilink")、[佩特里网](https://zh.wikipedia.org/wiki/佩特里网 "wikilink")、和等。计算模型是用来分析计算进程代价的一种[抽象化](../Page/抽象化.md "wikilink")，利用它性能，可以不取决于特定实现和技术所特有的各种变化，[并行算法一般而言是针对特定计算模型而编写的](https://zh.wikipedia.org/wiki/并行算法 "wikilink")，为[PRAM机编写的伪码通常会采用某种](https://zh.wikipedia.org/wiki/PRAM模型 "wikilink")[For循环形式的并发编程构造](https://zh.wikipedia.org/wiki/For循环 "wikilink")\[16\]。

指称一种编程样式，即通过看起来像[库调用的方式引发执行](https://zh.wikipedia.org/wiki/函式库 "wikilink")。例子包括[POSIX的](https://zh.wikipedia.org/wiki/POSIX "wikilink")[Pthreads库和](../Page/POSIX线程.md "wikilink")[Apache Hadoop中的](../Page/Apache_Hadoop.md "wikilink")[MapReduce](../Page/MapReduce.md "wikilink")。在这二者情况下，都符合这个库所用语言的语法却不能按照其语义来理解。不同于计算模型，编程模型特别暗含着对硬件或软件实现的实际考虑\[17\]。

在[并行计算](../Page/并行计算.md "wikilink")中，执行模型经常必须暴露硬件特征来达成高性能。并行硬件有大量的变种导致了同时需要类似数量的并行执行模型。对每个执行模型都建立一门新语言是不实际的，因此常见的实践都是通过某个API来引发并行执行模型的行为。并行编程语言可以基于一种或一个组合的编程模型。例如，[高性能Fortran基于共享内存交互和数据并行问题分解](https://zh.wikipedia.org/wiki/HPF "wikilink")，而[Go](../Page/Go.md "wikilink")提供共享内存交互和消息传递交互。

## 并行编程模型

这里列出的编程模型是可称为的[计算机的抽象模型](https://zh.wikipedia.org/wiki/计算机 "wikilink")\[18\]，它提供了在一个机器的物理实现和[编程者可获得的这个机器的抽象概念之间的桥梁](../Page/程序员.md "wikilink")；换句话说，它意图在[硬件和](https://zh.wikipedia.org/wiki/计算机硬件 "wikilink")[软件](../Page/软件.md "wikilink")工程师之间提供共同的理解层面。成功的编程模型可以在现实中有效的实现并被编程者有效的作为目标；特别是应当有可能用典型的高级语言编译器生成良好的代码。从编程者的角度来看，这种并行编程模型典型的位于[OpenMP](../Page/OpenMP.md "wikilink")、[OpenACC](../Page/OpenACC.md "wikilink")等之下而在[Pthreads](../Page/POSIX线程.md "wikilink")、[IPC](https://zh.wikipedia.org/wiki/进程间通信 "wikilink")、[MPI等之上](https://zh.wikipedia.org/wiki/MPI "wikilink")。

<table>
<thead>
<tr class="header">
<th><p>名称</p></th>
<th><p>交互类别</p></th>
<th><p>分解类别</p></th>
<th><p>实现及用例</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><a href="../Page/Fork-join模型.md" title="wikilink">Fork-join模型</a></p></td>
<td><p>共享内存</p></td>
<td><p>数据</p></td>
<td><p><a href="../Page/Cilk.md" title="wikilink">Cilk</a>，<a href="../Page/OpenMP.md" title="wikilink">OpenMP</a>，[19]</p></td>
</tr>
<tr class="even">
<td><p><a href="../Page/整体同步并行计算模型.md" title="wikilink">整体同步并行</a><a href="https://zh.wikipedia.org/wiki/计算模型" title="wikilink">模型</a></p></td>
<td><p>共享内存</p></td>
<td><p>数据[20]</p></td>
<td><p><a href="http://www.bsp-worldwide.org/">BSPlib</a>：<a href="http://www.multicorebsp.com">MulticoreBSP</a>、<a href="https://github.com/wijnand-suijlen/bsponmpi/releases">BSPonMPI</a>，<a href="../Page/Giraph.md" title="wikilink">Apache Giraph</a>[21]，[22]</p></td>
</tr>
<tr class="odd">
<td><p><a href="../Page/分区全局地址空间.md" title="wikilink">分区全局地址空间</a>模型</p></td>
<td></td>
<td><p>数据</p></td>
<td><p>[23]，，，</p></td>
</tr>
<tr class="even">
<td><p><a href="https://zh.wikipedia.org/wiki/演员模型" title="wikilink">演员模型</a></p></td>
<td><p>异步消息传递</p></td>
<td><p>任务</p></td>
<td><p><a href="../Page/Erlang.md" title="wikilink">Erlang</a>，<a href="https://zh.wikipedia.org/wiki/D语言" title="wikilink">D</a>，<a href="../Page/Scala.md" title="wikilink">Scala</a>，很多的<a href="https://zh.wikipedia.org/wiki/軟體框架" title="wikilink">框架和</a><a href="https://zh.wikipedia.org/wiki/函式库" title="wikilink">库实现</a></p></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/通信顺序进程" title="wikilink">通信顺序进程</a><a href="https://zh.wikipedia.org/wiki/模式" title="wikilink">模式</a></p></td>
<td><p>同步消息传递</p></td>
<td><p>任务</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/Occam" title="wikilink">Occam</a>，<a href="../Page/Ada.md" title="wikilink">Ada</a>，<a href="../Page/Go.md" title="wikilink">Go</a></p></td>
</tr>
<tr class="even">
<td><p><a href="../Page/OpenCL.md" title="wikilink">OpenCL</a><a href="https://zh.wikipedia.org/wiki/軟體框架" title="wikilink">框架</a></p></td>
<td><p>共享内存</p></td>
<td><p>数据</p></td>
<td><p><a href="../Page/CUDA.md" title="wikilink">CUDA</a>[24]，<a href="../Page/SYCL.md" title="wikilink">SYCL</a>，<a href="http://portablecl.org/">Pocl</a></p></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/串流处理" title="wikilink">串流处理</a>/<a href="../Page/编程范型.md" title="wikilink">范型</a></p></td>
<td><p><a href="../Page/流水线_(计算机).md" title="wikilink">流水线</a></p></td>
<td><p>数据[25]</p></td>
<td><p>[26]，<a href="../Page/Apache_Flink.md" title="wikilink">Apache Flink</a>，，<a href="../Page/TensorFlow.md" title="wikilink">TensorFlow</a></p></td>
</tr>
<tr class="even">
<td><p><a href="../Page/高级综合.md" title="wikilink">高级综合</a><a href="https://zh.wikipedia.org/wiki/电子设计自动化" title="wikilink">电子设计自动化</a></p></td>
<td></td>
<td><p>任务</p></td>
<td><p>：<a href="../Page/Handel-C.md" title="wikilink">Handel-C</a>、<a href="../Page/SystemC.md" title="wikilink">SystemC</a>，</p></td>
</tr>
</tbody>
</table>

[OpenCL](../Page/OpenCL.md "wikilink")将计算系统视为组成自一组“计算设备”，它们可以是[CPU或是附加的](https://zh.wikipedia.org/wiki/中央处理单元 "wikilink")“[加速器](../Page/硬件加速.md "wikilink")”比如[GPU](https://zh.wikipedia.org/wiki/图形处理单元 "wikilink")。它定义了一种用来写程序。在OpenCL设备上执行的函数叫做“[内核](https://zh.wikipedia.org/wiki/内核函数 "wikilink")”\[27\]。一个单一的计算设备典型的组成自一些“计算单元”，它们依次又包含很多“处理元素”（PE）。一个单一的内核执行可以在所有或多个PE上并行运行。OpenCL定义了[API](https://zh.wikipedia.org/wiki/应用程序编程接口 "wikilink")，允许运行于主机上的程序，启动在计算设备上的内核，并管理设备内存，它至少在概念上分离于主机内存。用OpenCL语言写的程序预期会被[即时编译](https://zh.wikipedia.org/wiki/即时编译 "wikilink")，所以使用OpenCL的应用程序在针对各种设备的实现之间是可移植的\[28\]。

[FPGA可以被用来解决任何](https://zh.wikipedia.org/wiki/FPGA "wikilink")[可计算的问题](https://zh.wikipedia.org/wiki/可计算性 "wikilink")，这通过用FPGA能实现的事实就可轻易的证明。它们的好处在于对某些应用它们明显的要更快速，因为它们有着[并行本质和在对用在特定处理上的](../Page/并行计算.md "wikilink")[逻辑门的数目方面的](https://zh.wikipedia.org/wiki/逻辑门 "wikilink")\[29\]。近年来开始兴起使用[OpenCL](../Page/OpenCL.md "wikilink")编程来利用FPGA提供的性能和能耗效率。OpenCL允许编程者用C语言编码并把FPGA[组合函数作为使用OpenCL构造的OpenCL](../Page/组合逻辑电路.md "wikilink")[计算内核的目标](https://zh.wikipedia.org/wiki/内核函数 "wikilink")\[30\]。

[MapReduce](../Page/MapReduce.md "wikilink")是通过并行、分布式算法在[集群上处理和生成](../Page/计算机集群.md "wikilink")[键/值对形式的](../Page/键-值存储.md "wikilink")[大数据集的编程模型和有关实现](https://zh.wikipedia.org/wiki/大数据 "wikilink")\[31\] ，[Apache Hadoop中将它与HDFS分立实现](../Page/Apache_Hadoop.md "wikilink")\[32\]。[MapReduce](../Page/MapReduce.md "wikilink")受到了在[函数式编程](../Page/函数式编程.md "wikilink")[范型中常用的](../Page/编程范型.md "wikilink")和函数的启发\[33\]，但是它们在MapReduce框架中的用途不同于它们在起初形式中那样\[34\]。

并行编程模型还有很多，比如：[马里兰大学学院市分校依据](https://zh.wikipedia.org/wiki/马里兰大学学院市分校 "wikilink")[PRAM](https://zh.wikipedia.org/wiki/PRAM模型 "wikilink")[计算模型](../Page/计算模型_\(数学\).md "wikilink")，建立了[指令级并行](https://zh.wikipedia.org/wiki/指令级并行 "wikilink")的多处理器计算机和编程语言\[35\]，实现了Spawn-Join[范型](../Page/编程范型.md "wikilink")\[36\]。

## 参见

  - [并发计算](../Page/并发计算.md "wikilink")

  - [异构计算](https://zh.wikipedia.org/wiki/异构计算 "wikilink")

  - [高性能计算](https://zh.wikipedia.org/wiki/高性能计算 "wikilink")

  - [集群计算](https://zh.wikipedia.org/wiki/集群计算 "wikilink")

  - [分布式计算](../Page/分布式计算.md "wikilink")

  -
  - [远程直接内存访问](../Page/远程直接内存访问.md "wikilink")

  -
## 引用

## 进一步阅读

  -
  -
  -
  -
[Category:并行计算](https://zh.wikipedia.org/wiki/Category:并行计算 "wikilink") [Category:编程典范](https://zh.wikipedia.org/wiki/Category:编程典范 "wikilink")

1.  Skillicorn, David B., "Models for practical parallel computation", International Journal of Parallel Programming, 20.2 133–158 (1991), <https://www.ida.liu.se/~chrke55/papers/modelsurvey.pdf>
2.
3.  John E. Savage, Models of Computation: Exploring the Power of Computing, 2008, Chapter 7 (Parallel Computation), <http://cs.brown.edu/~jes/book/>
4.  Ian Foster, Designing and Building Parallel Programs, 1995, Section 1.3, "A Parallel Programming Model", <http://www.mcs.anl.gov/~itf/dbpp/text/node9.html>
5.  Blaise Barney, Introduction to Parallel Computing, "Models", 2015, Lawrence Livermore National Laboratory, <https://computing.llnl.gov/tutorials/parallel_comp/#Models>
6.
7.
8.
9.  Ian Foster, Designing and Building Parallel Programs, 1995, Section 2.2, "Partitioning", <http://www.mcs.anl.gov/~itf/dbpp/text/node16.html>
10. Blaise Barney, Introduction to Parallel Computing, "Partitioning", 2015, Lawrence Livermore National Laboratory, <https://computing.llnl.gov/tutorials/parallel_comp/#DesignPartitioning>
11.
12.
13.
14.
15. McBurney, D. L., and M. Ronan Sleep. "Transputer-based experiments with the ZAPP architecture." PARLE Parallel Architectures and Languages Europe. Springer Berlin Heidelberg, 1987.
    Hammond, Kevin. Parallel functional programming: An introduction. In International Symposium on Parallel Symbolic Computation, p. 46. 1994. “The Alfalfa project implemented serial combinators for the Intel iPSC\[44\]. …… Buckwheat re-implemented this model for the Encore Multimax, a shared-memory multiprocessor. ……\[45\].”
16.

17. Skillicorn, David B., and Domenico Talia, Models and languages for parallel computation, ACM Computing Surveys, 30.2 123–169 (1998), <https://www.cs.utexas.edu/users/browne/CS392Cf2000/papers/ModelsOfParallelComputation-Skillicorn.pdf>
18.
19.
20.
21.
22.
23.
24.



25.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
36.
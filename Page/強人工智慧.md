**強人工智慧**（）或**通用人工智慧**（）是具備與[人類同等](../Page/人類.md "wikilink")[智慧](../Page/智慧.md "wikilink")、或超越人類的[人工智慧](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")，能表現正常人類所具有的所有[智能行為](https://zh.wikipedia.org/wiki/智能 "wikilink")。\[1\]

## 概述

強人工智慧是[人工智慧研究的主要目標之一](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")，同時也是[科幻小說和](https://zh.wikipedia.org/wiki/科幻小說 "wikilink")[未來學家所討論的主要議題](https://zh.wikipedia.org/wiki/未來學 "wikilink")。相對的，弱人工智慧（applied
AI，narrow AI，weak AI\[2\], artificial narrow intelligence,
ANI\[3\]）只處理特定的[問題](https://zh.wikipedia.org/wiki/解决問題 "wikilink")。\[4\]弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了。由於過去的智能程式多是弱人工智慧，發現這個具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指**通用人工智能**（artificial
general
intelligence，AGI），或具備執行一般智慧行為的能力。\[5\]強人工智慧通常把人工智慧和[意識](https://zh.wikipedia.org/wiki/意識 "wikilink")、感性、知識和自覺等人類的特徵互相連結。

因而，這樣的具備意識的強[人工智慧是否存在](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")？目前[模擬出簡單的一個生物頭](https://zh.wikipedia.org/wiki/模擬 "wikilink")[腦已經不是不可能的事](https://zh.wikipedia.org/wiki/腦 "wikilink")，一如[化學技術累積發展下](../Page/化學.md "wikilink")，現在許多研發[藥品已經使用計算機模型來推演藥物效果](../Page/藥品.md "wikilink")，以減少[受試動物的痛苦等](https://zh.wikipedia.org/wiki/受試動物 "wikilink")。從前在使用[電腦語言的時代](https://zh.wikipedia.org/wiki/電腦語言 "wikilink")，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤，而近年來從電腦在[摩爾定律與](https://zh.wikipedia.org/wiki/摩爾定律 "wikilink")[神經科學研究的協助下](https://zh.wikipedia.org/wiki/神經科學 "wikilink")，透過在電腦上對[生物](../Page/生物.md "wikilink")[神經元系統複雜的電位衝動模擬上取得了明顯的突破](../Page/神經元.md "wikilink")，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯[學習經驗並總結](https://zh.wikipedia.org/wiki/學習 "wikilink")，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進[思考結構](https://zh.wikipedia.org/wiki/思考 "wikilink")，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「[思想](../Page/思想.md "wikilink")」上的議題，將還會一直是人們爭辯的對象，特別是在智能[理性與心理](https://zh.wikipedia.org/wiki/理性 "wikilink")[感性部分要如何區別](https://zh.wikipedia.org/wiki/感性 "wikilink")、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。在一些能夠自動推理出最佳解的工具已經出現，如[Google旗下的深思公司](../Page/Google.md "wikilink")（DeepMind）在此領域進展最多，成功開發出了能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表者這是一個可以透過自主「進化發展」的通用智慧。\[6\]

## 标准

人们提出过很多[人工智能的定义](../Page/人工智能.md "wikilink")（例如能够通过[图灵测试](../Page/图灵测试.md "wikilink")），但是没有一个定义能够得到所有人的认同\[7\]
然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\[8\]

  - [自动推理](https://zh.wikipedia.org/wiki/自动推理 "wikilink")，使用一些策略来解决问题，在[不确定性的环境中作出决策](https://zh.wikipedia.org/wiki/不确定性 "wikilink")；
  - [知识表示](https://zh.wikipedia.org/wiki/知识表示 "wikilink")，包括[常识知识库](../Page/常识知识库.md "wikilink")；
  - 自动[规划](https://zh.wikipedia.org/wiki/规划 "wikilink")；
  - 自主学习、创新；
  - 使用[自然语言进行沟通](https://zh.wikipedia.org/wiki/自然语言 "wikilink")；
  - 以及，整合以上这些手段来达到同一个的目标；

还有一些重要的能力，包括机器[知觉](https://zh.wikipedia.org/wiki/知觉 "wikilink")（例如[计算机视觉](../Page/计算机视觉.md "wikilink")），以及在智能行为的世界中行动的能力（例如[机器人移动自身和其他物体的能力](../Page/机器人.md "wikilink")）。\[9\]
它可能包括探知与回避危险的能力。\[10\]
许多研究智能的交叉领域（例如[认知科学](../Page/认知科学.md "wikilink")、[机器智能和](https://zh.wikipedia.org/wiki/机器智能 "wikilink")[决策](../Page/决策.md "wikilink")）试图强调一些额外的特征，例如[想象力](https://zh.wikipedia.org/wiki/想象力 "wikilink")（不依靠预设而建构精神影像与概念的能力）\[11\]
以及[自主性](https://zh.wikipedia.org/wiki/自我决定论 "wikilink")。\[12\]
基于计算机的系统中的确已经存在许多这样的能力，例如、[自动推理](https://zh.wikipedia.org/wiki/自动推理 "wikilink")、[决策支持系统](../Page/决策支持系统.md "wikilink")、[机器人](../Page/机器人.md "wikilink")、[进化计算](https://zh.wikipedia.org/wiki/进化计算 "wikilink")、[智能代理](https://zh.wikipedia.org/wiki/智能代理 "wikilink")，然而并未达到人类的水平。

### 检验强人工智能的操作性手段

一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括[阿兰·图灵](https://zh.wikipedia.org/wiki/阿兰·图灵 "wikilink")、、，他们提出的测试包括：

1\. 图灵测试（*图灵*）

  -
    同人類交流的試驗。参见 [图灵测试](../Page/图灵测试.md "wikilink")。

2\. 咖啡测试 (*格策尔*)

  -
    生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。

3\. 机器人学生测试 (*格策尔*)

  -
    透過機器學習，分析和回答單一問題的測試
    。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的[東大AI或是IBM參加搶答節目的](https://zh.wikipedia.org/wiki/東大AI "wikilink")[華生](../Page/沃森_\(人工智能程序\).md "wikilink")。

4\. 雇员测试 (*尼尔森*)

  -
    測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。

这些测试检测了一系列必要的特质，包括推理和学习能力。\[13\]

## 强人工智能需要解决的问题

人们将对于计算机来说最困难的问题，非正式地称为“人工智能完备”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。\[14\]
将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。

人们假定人工智能完备的问题包括[计算机视觉](../Page/计算机视觉.md "wikilink")、[自然语言理解](../Page/自然语言理解.md "wikilink")，以及处理真实世界中的意外情况。\[15\]目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要。这一点在某些方面很有用，例如通过[验证码来判别人类和机器](../Page/验证码.md "wikilink")，以及在[计算机安全方面用于阻止](../Page/计算机安全.md "wikilink")[暴力破解法](https://zh.wikipedia.org/wiki/暴力破解法 "wikilink")。\[16\]\[17\]

## 人工智能研究的主流

### 强人工智能研究的主流历史

现代人工智能研究开始于1950年代中期。\[18\]
最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱[司马贺在](../Page/司马贺.md "wikilink")1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。”\[19\]
启发这一预言的是[斯坦利·库布里克和](https://zh.wikipedia.org/wiki/斯坦利·库布里克 "wikilink")[亚瑟·查理斯·克拉克创作的角色](https://zh.wikipedia.org/wiki/亚瑟·查理斯·克拉克 "wikilink")，[HAL
9000](../Page/HAL_9000.md "wikilink")。当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱[马文·闵斯基](../Page/马文·闵斯基.md "wikilink")，在创作HAL
9000的工作中， \[20\]
他担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决，”，\[21\]

然而，到了1970年代早期，研究者们意识到他们远远低估了其中的困难。资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。\[22\]
在1980年代初，日本的[第五代电脑开始重新对强人工智能恢复兴趣](https://zh.wikipedia.org/wiki/第五代电脑 "wikilink")，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”。\[23\]
同时，[专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域](../Page/专家系统.md "wikilink")。\[24\]
然而，人工智能的市场在1980年代晚期发生剧烈崩塌，而第五代计算机的目标从未实现。\[25\]
再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言。\[26\]
并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\[27\]

### 今日的人工智能研究主流

在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如[人工神经网络](../Page/人工神经网络.md "wikilink")、[机器视觉以及](../Page/机器视觉.md "wikilink")[数据挖掘](../Page/数据挖掘.md "wikilink")。\[28\]
这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。

大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将、或者整合起来。[汉斯·莫拉维克在](../Page/汉斯·莫拉维克.md "wikilink")1988年写道

> "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的[常识知识库](../Page/常识知识库.md "wikilink")。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。"\[29\]

然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道

> "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章的基础是正确的，那么这个希望不会实现，只有一个可行的路线从感觉到符号，就是自下而上。一个独立的符号层面，类似计算机软件从不需要这样的路径来到达（反之亦然）——我们也不清楚为何要达到这样的层面，因为这个过程反而将其从自身的意义中拔出（仅仅是将我们化简为何计算机程序等价的东西）。"\[30\]

## 理论

“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家希尔勒认为不可能。

关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。他举了著名的[中文房间的例子来说明](../Page/中文房间.md "wikilink")，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。

也有哲学家持不同的观点。[丹尼爾·丹尼特](../Page/丹尼爾·丹尼特.md "wikilink")（Daniel C.
Dennett）在其著作《意识的阐释》（Consciousness
Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。

## 風險

## 參見

  - [人工智能史](../Page/人工智能史.md "wikilink")
  - [人工智能哲學](../Page/人工智能哲學.md "wikilink")
  - [人工智慧](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")
  - [機器學習](https://zh.wikipedia.org/wiki/機器學習 "wikilink")
  - [人工意識](../Page/人工意識.md "wikilink")
  - [技术奇异点](../Page/技术奇异点.md "wikilink")
  - [無條件基本收入](../Page/無條件基本收入.md "wikilink")
  - [意识上传](../Page/意识上传.md "wikilink")（Mind uploading）

## 參考資料

[fr:Intelligence artificielle\#Intelligence artificielle
forte](https://zh.wikipedia.org/wiki/fr:Intelligence_artificielle#Intelligence_artificielle_forte "wikilink")

[Category:機器學習](https://zh.wikipedia.org/wiki/Category:機器學習 "wikilink")
[Category:计算神经科学](https://zh.wikipedia.org/wiki/Category:计算神经科学 "wikilink")

1.   or see [Advanced Human
    Intelligence](http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html)
    where he defines strong AI as "machine intelligence with the full
    range of human intelligence."
2.  [The Open University on Strong and Weak
    AI](http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm)
3.  AI創世紀, pp.68
4.  Encyclopædia Britannica [Strong AI, applied AI, and cognitive
    simulation](http://www.britannica.com/eb/article-219086/artificial-intelligence)
    or Jack Copeland [What is artificial
    intelligence?](http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html)
     on AlanTuring.net
5.  . This the term they use for "human-level" intelligence in the
    physical symbol system hypothesis.
6.  <http://www.inside.com.tw/2016/02/21/the-superhero-of-artificial-intelligence-can-this-genius-keep-it-in-check>
    人工智慧有多恐怖？聽聽「天才」Demis Hassabis 怎麼說！
7.  AI founder [John
    McCarthy](https://zh.wikipedia.org/wiki/John_McCarthy_\(computer_scientist\) "wikilink")
    writes: "we cannot yet characterize in general what kinds of
    computational procedures we want to call intelligent."  (For a
    discussion of some definitions of intelligence used by [artificial
    intelligence](https://zh.wikipedia.org/wiki/artificial_intelligence "wikilink")
    researchers, see [philosophy of artificial
    intelligence](https://zh.wikipedia.org/wiki/philosophy_of_artificial_intelligence "wikilink").)
8.  This list of intelligent traits is based on the topics covered by
    major AI textbooks, including: , ,  and .
9.  Pfeifer, R. and Bongard J. C., How the body shapes the way we think:
    a new view of intelligence (The MIT Press, 2007). ISBN 0-262-16239-3
10. White, R. W. (1959). Motivation reconsidered: The concept of
    competence. Psychological Review, 66, 297-333
11.
12. deCharms, R. (1968). Personal causation. New York: Academic Press.
13.
14. Shapiro, Stuart C. (1992). [Artificial
    Intelligence](http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf) In
    Stuart C. Shapiro (Ed.), *Encyclopedia of Artificial Intelligence*
    (Second Edition, pp. 54–57). New York: John Wiley. (Section 4 is on
    "AI-Complete Tasks".)
15. Roman V. Yampolskiy. Turing Test as a Defining Feature of
    AI-Completeness . In Artificial Intelligence, Evolutionary
    Computation and Metaheuristics (AIECM) --In the footsteps of Alan
    Turing. Xin-She Yang (Ed.). pp. 3-17. (Chapter 1). Springer, London.
    2013.
    <http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf>
16. Luis von Ahn, Manuel Blum, Nicholas Hopper, and John Langford.
    [CAPTCHA: Using Hard AI Problems for
    Security](http://www.captcha.net/captcha_crypt.pdf) . In Proceedings
    of Eurocrypt, Vol. 2656 (2003), pp. 294-311.
17.  (unpublished?)
18.
19.  quoted in
20. [Scientist on the Set: An Interview with Marvin
    Minsky](http://mitpress.mit.edu/e-books/Hal/chap2/two1.html)
21. Marvin Minsky to , quoted in .
22. The [Lighthill
    report](https://zh.wikipedia.org/wiki/Lighthill_report "wikilink")
    specifically criticized AI's "grandiose objectives" and led the
    dismantling of AI research in England. (; ) In the U.S.,
    [DARPA](https://zh.wikipedia.org/wiki/DARPA "wikilink") became
    determined to fund only "mission-oriented direct research, rather
    than basic undirected research". See  under "Shift to Applied
    Research Increases Investment". See also  and
23. ,  and see also
24. ; ;
25.
26. As AI founder [John
    McCarthy](https://zh.wikipedia.org/wiki/John_McCarthy_\(computer_scientist\) "wikilink")
    writes "it would be a great relief to the rest of the workers in AI
    if the inventors of new general formalisms would express their hopes
    in a more guarded form than has sometimes been the case."
27. "At its low point, some computer scientists and software engineers
    avoided the term artificial intelligence for fear of being viewed as
    wild-eyed dreamers."
28.
29.
30. Harnad, S. (1990) The Symbol Grounding Problem. Physica D 42:
    335-346.
> 本文内容由[所罗门诺夫的归纳推理理论](https://zh.wikipedia.org/wiki/所罗门诺夫的归纳推理理论)转换而来。


**所罗门诺夫的归纳推理理论**（Solomonoff's theory of inductive inference）是对[奥卡姆剃刀](../Page/奥卡姆剃刀.md "wikilink")叙述的数学化描述。\[1\]\[2\]\[3\]\[4\]\[5\]该理论指出：在所有能够完全描述的已观测的可计算类中，较短的可计算理论在估计下一次观测结果的概率时具有较大的权重。简而言之，在几组可以给出的答案的假设论述中，假设越少的越被大家选择。引申为“越简单的越易行”。

## 参考资料

[Category:归纳推理](https://zh.wikipedia.org/wiki/Category:归纳推理 "wikilink") [Category:算法信息论](https://zh.wikipedia.org/wiki/Category:算法信息论 "wikilink") [Category:贝叶斯统计](https://zh.wikipedia.org/wiki/Category:贝叶斯统计 "wikilink") [Category:机器学习](https://zh.wikipedia.org/wiki/Category:机器学习 "wikilink")

1.  JJ McCall. Induction: From Kolmogorov and Solomonoff to De Finetti and Back to Kolmogorov – Metroeconomica, 2004 – Wiley Online Library.
2.  D Stork. Foundations of Occam's razor and parsimony in learning from ricoh.com – NIPS 2001 Workshop, 2001
3.  A.N. Soklakov. Occam's razor as a formal basis for a physical theory [from arxiv.org](https://zh.wikipedia.org/wiki/arxiv:math-ph/0009007 "wikilink") – Foundations of Physics Letters, 2002 – Springer
4.
5.  M Hutter. On the existence and convergence of computable universal priors [arxiv.org](https://zh.wikipedia.org/wiki/arxiv:cs/0305052 "wikilink") – Algorithmic Learning Theory, 2003 – Springer
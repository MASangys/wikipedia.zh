> 本文内容由[最优化](https://zh.wikipedia.org/wiki/最优化)转换而来。


**最优化**，是[应用数学的一个分支](https://zh.wikipedia.org/wiki/应用数学 "wikilink")。主要研究在特定情况下最大化或最小化某一特定函数或变量。

## 数学表述

主要研究以下形式的问题：

  -
    给定一个[函数](../Page/函数.md "wikilink")\(f:A\to \mathbb{R}\)，寻找一个元素\(\mathbf{x}^0\in A\)使得对于所有\(A\)中的\(\mathbf{x}\)，\(f(\mathbf{x}^0)\leq f(\mathbf{x})\)（最小化）；或者\(f(\mathbf{x}^0)\geq f(\mathbf{x})\)（最大化）。

这类定式有时还称为“**数学规划**”（譬如，[线性规划](../Page/线性规划.md "wikilink")）。许多现实和理论问题都可以建模成这样的一般性框架。

典型的，\(A\)一般为[欧几里得空间](../Page/欧几里得空间.md "wikilink")\(\mathbb{R}^n\)中的[子集](../Page/子集.md "wikilink")，通常由一个\(A\)必须满足的[约束](https://zh.wikipedia.org/wiki/约束 "wikilink")[等式或者](https://zh.wikipedia.org/wiki/等式 "wikilink")[不等式来规定](https://zh.wikipedia.org/wiki/不等式 "wikilink")。 \(A\)的元素被称为是**可行解**。函数\(f\)被称为**[目标函数](https://zh.wikipedia.org/wiki/目标函数 "wikilink")**，或者**[代价函数](https://zh.wikipedia.org/wiki/代价函数 "wikilink")**。一个最小化（或者最大化）目标函数的可行解被称为**最优解**。

一般情况下，会存在若干个局部的极小值或者极大值。局部极小值\(x^*\)定义为对于一些\(\delta>0\)，以及所有的\(x\) 满足

\[\|\mathbf{x}-\mathbf{x}^*\|\leq\delta\];

公式

\[f(\mathbf{x}^*)\leq f(\mathbf{x})\]

成立。这就是说，在\(\mathbf{x}^*\)周围的一些[闭球上](https://zh.wikipedia.org/wiki/闭球 "wikilink")，所有的[函数值都大于或者等于在该点的函数值](https://zh.wikipedia.org/wiki/函数值 "wikilink")。一般的，求局部极小值是容易的，但是要确保其为全域性的最小值，则需要一些附加性的条件，例如，该函数必须是[凸函数](../Page/凸函数.md "wikilink")。

## 符号表示

最优化问题通常有一些较特别的[符号](../Page/符号.md "wikilink")标示方法。例如：

\[\mathrm{min}_{x\in\mathbb R}\; x^2 + 1\]

这是要求表达式\(x^2 + 1\)的最小值，这里x取值为全体[实数](../Page/实数.md "wikilink")，\(\mathbb{R}\)。这个问题的最小值应该是\(1\)，当\(x=0\)。

\[\mathrm{max}_{x\in\mathbb R}\; 2x\]

这是要求表达式\(2x\)的最大值，同样地，\(x\)在全体实数上取值。对于这个问题，由于该表达式不是有上界的，因此不存在最大值，因此，答案应该是[无限大](https://zh.wikipedia.org/wiki/无限大 "wikilink")，或者是不可定义的。

\[\operatorname{argmin}_{x\in[-\infty;-1]}\; x^2 + 1\,\]

这是求使表达式*x*<sup>2</sup>+1 达到最小值时x的值。在这里x被限定在区间\[-∞ ,-1\]之间，所以上式的值是-1。

## 主要分支

  - [线性规划](../Page/线性规划.md "wikilink")：当目标函数*f*是线性函数而且集合A是由线性等式函数和线性不等式函数来确定的， 我们称这一类问题为线性规划
  - [整数规划](https://zh.wikipedia.org/wiki/整数规划 "wikilink")：当线性规划问题的部分或所有的变量局限于[整数](../Page/整数.md "wikilink")值时， 我们称这一类问题為整数规划问题
  - [二次规划](../Page/二次规划.md "wikilink")：目标函数是二次函数，而且集合A必须是由线性等式函数和线性不等式函数来确定的。
  - [分数规划](https://zh.wikipedia.org/wiki/分数规划 "wikilink")：研究的是如何优化两个非线性函数的比例。
  - [非线性规划](../Page/非线性规划.md "wikilink")：研究的是目标函数或是限制函数中含有非线性函数的问题。
  - [随机规划](https://zh.wikipedia.org/wiki/随机规划 "wikilink")：研究的是某些变量是[随机变量](../Page/随机变量.md "wikilink")的问题。
  - [动态规划](../Page/动态规划.md "wikilink")：研究的是最优策略基于将问题分解成若干个较小的子问题的优化问题。
  - [组合最优化](https://zh.wikipedia.org/wiki/组合最优化 "wikilink")：研究的是可行解是离散或是可转化为[离散的问题](https://zh.wikipedia.org/wiki/离散 "wikilink")。
  - [无限维最优化](https://zh.wikipedia.org/wiki/无限维最优化 "wikilink")：研究的是可行解的集合是无限维空间的子集的问题，一个无限维空间的例子是函数空间。

## 算法

对于无约束的优化问题， 如果-{A|zh-cn:函数; zh-tw:函式; zh-hk:函數;}-是二次可微的话，可以通过找到目标函数[梯度](../Page/梯度.md "wikilink")为0（也就是[拐点](../Page/拐点.md "wikilink")）的那些点来解决此优化问题。我们需要用[黑塞矩阵来确定此点的类型](https://zh.wikipedia.org/wiki/黑塞矩阵 "wikilink")。如果[黑塞矩阵是正定的话](https://zh.wikipedia.org/wiki/黑塞矩阵 "wikilink")，该点是一个局部最小解， 如果是负定的话，该点是一个局部最大解，如果[黑塞矩阵是不定的话](https://zh.wikipedia.org/wiki/黑塞矩阵 "wikilink")，该点是某种[鞍点](https://zh.wikipedia.org/wiki/鞍点 "wikilink")。

要找到那些拐点，我们可以通过猜测一个初始点，然后用比如以下的迭代的方法来找到。

  - [梯度下降法](https://zh.wikipedia.org/wiki/梯度下降法 "wikilink")
  - [牛顿法](../Page/牛顿法.md "wikilink")
  - [共轭梯度法](../Page/共轭梯度法.md "wikilink")
  - [线性搜索](https://zh.wikipedia.org/wiki/线性搜索 "wikilink")
  - [置信域方法](../Page/置信域方法.md "wikilink")

如果目标函数在我们所关心的区域中是凸函数的话，那么任何局部最小解也是全局最优解。现在已经有稳定，快速的数值计算方法来求二次可微地凸函数的最小值。

有[約束條件的约束问题常常可以通过](../Page/約束_\(數學\).md "wikilink")[拉格朗日乘数](../Page/拉格朗日乘数.md "wikilink")转化为非约束问题。

其他一些流行的方法有：

  - [遗传算法](../Page/遗传算法.md "wikilink")
  - [神经网络](../Page/人工神经网络.md "wikilink")
  - [微粒群算法](https://zh.wikipedia.org/wiki/微粒群算法 "wikilink")
  - [模拟退火](../Page/模拟退火.md "wikilink")
  - [支持向量机](../Page/支持向量机.md "wikilink")
  - [蚁群算法](../Page/蚁群算法.md "wikilink")
  - [类免疫演算法](https://zh.wikipedia.org/wiki/类免疫演算法 "wikilink")
  - [演化策略](https://zh.wikipedia.org/wiki/演化策略 "wikilink")
  - [差异演化算法](https://zh.wikipedia.org/wiki/差异演化算法 "wikilink")

## 人工智能和最优化

现代的计算机科学技术和人工智能科学把最优化作为一个重要的领域来研究。我们也可以认为人工智能的一些算法，就是模拟了人类寻求实际问题最优解的过程。例如，利用人工智能方法设计软件，配合外部的电子设备例如摄像头识别人脸；利用数据挖掘和神经网络算法来寻找投资的最佳时机等。

## 参见

  - [最优化问题](https://zh.wikipedia.org/wiki/最优化问题 "wikilink")

  -
  - [博弈论](../Page/博弈论.md "wikilink")

  - [运筹学](https://zh.wikipedia.org/wiki/运筹学 "wikilink")

  - [模糊逻辑](../Page/模糊逻辑.md "wikilink")

  - [随机最优化](https://zh.wikipedia.org/wiki/随机最优化 "wikilink")

  - [变分不等式](https://zh.wikipedia.org/wiki/变分不等式 "wikilink")

  - [单体算法](https://zh.wikipedia.org/wiki/单体算法 "wikilink")

  - [内点法](https://zh.wikipedia.org/wiki/内点法 "wikilink")

## 参考文献

<references/>

  - Stephen Boyd and Lieven Vandenberghe (2004). [Convex Optimization](http://www.stanford.edu/~boyd/cvxbook.html)，Cambridge University Press. ISBN 0-521-83378-7.

## 外部链接

  - [NEOS Guide](https://web.archive.org/web/20020822203831/http://www-fp.mcs.anl.gov/otc/GUIDE/index.html)
  - [Online curve and surface fitting](http://zunzun.com)
  - [Xpress-MP - Optimization software free to students](http://www.dashoptimization.com/)

[Category:最优化](https://zh.wikipedia.org/wiki/Category:最优化 "wikilink") [Category:運籌學](https://zh.wikipedia.org/wiki/Category:運籌學 "wikilink")
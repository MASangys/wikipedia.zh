> 本文内容由[最大期望算法](https://zh.wikipedia.org/wiki/最大期望算法)转换而来。


**最大期望演算法**（**Expectation-maximization algorithm**，又譯**期望最大化算法**）在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中，参数的最大似然估计。

在[统计](https://zh.wikipedia.org/wiki/统计 "wikilink")[计算中](https://zh.wikipedia.org/wiki/计算 "wikilink")，**最大期望（EM）算法**是在[概率模型](../Page/概率模型.md "wikilink")中寻找[参数](https://zh.wikipedia.org/wiki/参数 "wikilink")[最大似然估计](../Page/最大似然估计.md "wikilink")或者[最大后验估计的](../Page/最大后验概率.md "wikilink")[算法](../Page/算法.md "wikilink")，其中概率模型依赖于无法观测的[隐变量](https://zh.wikipedia.org/wiki/隐变量 "wikilink")。最大期望算法经常用在[机器学习](../Page/机器学习.md "wikilink")和[计算机视觉](../Page/计算机视觉.md "wikilink")的[数据聚类](https://zh.wikipedia.org/wiki/数据聚类 "wikilink")（Data Clustering）领域。最大期望算法经过两个步骤交替进行计算，第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；第二步是最大化（M），最大化在E步上求得的[最大似然值来计算参数的值](../Page/最大似然估计.md "wikilink")。M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。

## 历史

最大期望值算法由，和在他们1977年发表的经典论文中提出。他们指出此方法之前其实已经被很多作者「在他们特定的研究领域中多次提出过」。

## 介绍

EM算法用于在方程不能直接求解的情况下寻找统计模型的(局部)最大似然参数。这些模型中较为典型的是含有潜变量，未知参数并且已知观测数据的模型。也就是说，要么数据中存在缺失的值，要么模型可以通过假设存在更多未观测到的数据点来更简单地表示。以混合模型（Mixture Model）为例，通过假设每个观察到的数据点都有一个对应的未观察到的数据点，也可以说是潜在变量，来指定每个数据点所属的混合部分，这样就可以更简单地描述混合模型。

## EM简单教程

EM是一个在已知部分相关变量的情况下，估计未知变量的迭代技术。EM的算法流程如下：

1.  初始化分布参数
2.  重复直到收敛：
    1.  E步骤：根据参数的假设值，给出未知变量的期望估计，应用于缺失值。
    2.  M步骤：根据未知变量的估计值，给出当前的参数的极大似然估计。

## 最大期望过程说明

我们用\(\textbf{y}\)表示能够观察到的不完整的变量值，用\(\textbf{x}\)表示无法观察到的变量值，这样\(\textbf{x}\)和\(\textbf{y}\)一起组成了完整的数据。\(\textbf{x}\)可能是实际测量丢失的数据，也可能是能够简化问题的隐藏变量，如果它的值能够知道的话。例如，在[混合模型中](https://zh.wikipedia.org/wiki/混合模型 "wikilink")，如果“产生”样本的混合元素成分已知的话最大似然公式将变得更加便利（参见下面的例子）。

### 估计无法观测的数据

让\(p\,\)代表矢量\(\theta\): \(p( \mathbf y, \mathbf x | \theta)\)定义的参数的全部数据的[機率密度函數](../Page/機率密度函數.md "wikilink")（连续情况下）或者[機率質量函數](https://zh.wikipedia.org/wiki/機率質量函數 "wikilink")（离散情况下），那么从这个函数就可以得到全部数据的[最大似然值](../Page/最大似然估计.md "wikilink")，另外，在给定的观察到的数据条件下未知数据的[条件分布可以表示为](https://zh.wikipedia.org/wiki/条件分布 "wikilink")：

\[p(\mathbf x |\mathbf y, \theta) = \frac{p(\mathbf y, \mathbf x | \theta)}{p(\mathbf y | \theta)} = \frac{p(\mathbf y|\mathbf x, \theta)p(\mathbf x |\theta)}{\int p(\mathbf y|\mathbf x, \theta) p(\mathbf x |\theta) d\mathbf x}\]

## 参见

  - [估计理论](../Page/估计理论.md "wikilink")
  - [数据聚类](https://zh.wikipedia.org/wiki/数据聚类 "wikilink")

## 参考文献

  - Arthur Dempster, Nan Laird, and Donald Rubin. "Maximum likelihood from incomplete data via the EM algorithm". *Journal of the Royal Statistical Society*, Series B, 39 (1):1–38, 1977 [1](http://links.jstor.org/sici?sici=0035-9246%281977%2939%3A1%3C1%3AMLFIDV%3E2.0.CO%3B2-Z).
  - Robert Hogg, Joseph McKean and Allen Craig. *Introduction to Mathematical Statistics*. pp. 359-364. Upper Saddle River, NJ: Pearson Prentice Hall, 2005.
  - Radford Neal, [Geoffrey Hinton](https://zh.wikipedia.org/wiki/Geoffrey_Hinton "wikilink"). "A view of the EM algorithm that justifies incremental, sparse, and other variants". In Michael I. Jordan (editor), *Learning in Graphical Models* pp 355-368. Cambridge, MA: MIT Press, 1999.
  - [The on-line textbook: Information Theory, Inference, and Learning Algorithms](http://www.inference.phy.cam.ac.uk/mackay/itila/)，by [David J.C. MacKay](https://zh.wikipedia.org/wiki/David_J.C._MacKay "wikilink") includes simple examples of the E-M algorithm such as clustering using the soft K-means algorithm, and emphasizes the variational view of the E-M algorithm.
  - [A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models](http://citeseer.ist.psu.edu/bilmes98gentle.html)，by [J. Bilmes](https://zh.wikipedia.org/wiki/J._Bilmes "wikilink") includes a simplified derivation of the EM equations for Gaussian Mixtures and Gaussian Mixture Hidden Markov Models.
  - [Information Geometry of the EM and em Algorithms for Neural Networks](http://citeseer.ist.psu.edu/amari95information.html)，by [Shun-Ichi Amari](https://zh.wikipedia.org/wiki/Shun-Ichi_Amari "wikilink") give a view of EM algorithm from geometry view point.

[Category:估计理论](https://zh.wikipedia.org/wiki/Category:估计理论 "wikilink") [Category:算法](https://zh.wikipedia.org/wiki/Category:算法 "wikilink") [Category:機器學習演算法](https://zh.wikipedia.org/wiki/Category:機器學習演算法 "wikilink")
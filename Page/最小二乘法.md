[Linear_least_squares2.png](https://zh.wikipedia.org/wiki/File:Linear_least_squares2.png "fig:Linear_least_squares2.png")
[X33-ellips-1.svg](https://zh.wikipedia.org/wiki/File:X33-ellips-1.svg "fig:X33-ellips-1.svg")
**最小二乘法**（又称**-{zh-hans:最小平方法; zh-hk:最小平方法;
zh-tw:最小平方法}-**）是一种[数学](../Page/数学.md "wikilink")[优化技术](https://zh.wikipedia.org/wiki/优化 "wikilink")。它通过最小化[误差的平方和寻找数据的最佳](../Page/误差.md "wikilink")[函数匹配](../Page/函数.md "wikilink")。

利用**最小二乘法**可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。

“**最小平方法**”是對超定方程组，即其中存在比未知數更多的方程組，以[迴歸分析求得近似解的標準方法](../Page/迴歸分析.md "wikilink")。在這整個解決方案中，最小平方法演算為每一方程式的結果中，將殘差平方和的總和最小化。

最重要的應用是在[曲線擬合上](../Page/曲線擬合.md "wikilink")。最小平方所涵義的最佳擬合，即[殘差](../Page/误差.md "wikilink")（殘差為：觀測值與模型提供的擬合值之間的差距）平方總和的最小化。當問題在自變量（*x*變量）有重大不確定性時，那麼使用簡易迴歸和最小平方法會發生問題；在這種情況下，須另外考慮變量-誤差-擬合模型所需的方法，而不是最小平方法。

最小平方問題分為兩種：線性或普通的最小平方法，和非線性的最小平方法，取決於在所有未知數中的殘差是否為線性。線性的最小平方問題發生在統計迴歸分析中；它有一個[封閉形式的解決方案](https://zh.wikipedia.org/wiki/解析解 "wikilink")。非線性的問題通常經由迭代細緻化來解決；在每次迭代中，系統由線性近似，因此在這兩種情況下核心演算是相同的。

最小平方法所得出的多項式，即以擬合曲線的函數來描述自變量與預計應變量的[變異數關係](../Page/方差.md "wikilink")。

當觀測值來自指數族且滿足輕度條件時，最小平方估計和[最大似然估计是相同的](../Page/最大似然估计.md "wikilink")。最小平方法也能從[動差法得出](../Page/矩估计.md "wikilink")。

以下討論大多是以線性函數形式來表示，但對於更廣泛的函數族，最小平方法也是有效和實用的。此外，迭代地將局部的二次近似應用於或然性（藉由[費雪信息](https://zh.wikipedia.org/wiki/费希尔信息 "wikilink")），最小平方法可用於擬合[廣義線性模型](../Page/廣義線性模型.md "wikilink")。

其它依據平方距離的目標加總函數作為逼近函數的主題，請參見最小平方法（函數近似）。

最小平方法通常歸功於[高斯](../Page/卡爾·弗里德里希·高斯.md "wikilink")（Carl Friedrich
Gauss，1795），但最小平方法是由[阿德里安-马里·勒让德](../Page/阿德里安-马里·勒让德.md "wikilink")（Adrien-Marie
Legendre）首先發表的。

## 示例

[Linear_least_squares_example2.svg](https://zh.wikipedia.org/wiki/File:Linear_least_squares_example2.svg "fig:Linear_least_squares_example2.svg")

某次实验得到了四个数据点
\((x, y)\)：\((1, 6)\)、\((2, 5)\)、\((3, 7)\)、\((4, 10)\)（右图中红色的点）。我们希望找出一条和这四个点最匹配的直线
\(y=\beta_1+\beta_2 x\)，即找出在某种「最佳情况」下能够大致符合如下超定线性方程组的 \(\beta_1\) 和
\(\beta_2\)：

\[\begin{alignat}{4}
\beta_1  +  1\beta_2 &&\; = \;&& 6 & \\
\beta_1  +  2\beta_2 &&\; = \;&& 5 & \\
\beta_1  +  3\beta_2 &&\; = \;&& 7 & \\
\beta_1  +  4\beta_2 &&\; = \;&& 10 & \\
\end{alignat}\]

最小二乘法采用的手段是尽量使得等号两边的方差最小，也就是找出这个函数的最小值：

  -
    <math>\\begin{align}

S(\\beta_1, \\beta_2) =

`&\left[6-(\beta_1+1\beta_2)\right]^2+\left[5-(\beta_1+2\beta_2)   \right]^2 \\`

&+\\left\[7-(\\beta_1 + 3\\beta_2)\\right\]^2+\\left\[10-(\\beta_1 +
4\\beta_2)\\right\]^2.\\\\ \\end{align}</math>

最小值可以通过对 \(S(\beta_1, \beta_2)\) 分别求 \(\beta_1\) 和 \(\beta_2\)
的[偏导数](../Page/偏导数.md "wikilink")，然后使它们等于零得到。

\[\frac{\partial S}{\partial \beta_1}=0=8\beta_1 + 20\beta_2 -56\]

\[\frac{\partial S}{\partial \beta_2}=0=20\beta_1 + 60\beta_2 -154.\]

如此就得到了一个只有两个未知数的方程组，很容易就可以解出：

\[\beta_1=3.5\]

\[\beta_2=1.4\]

也就是说直线 \(y=3.5+1.4x\) 是最佳的。

## 简介

### 歷史背景

最小平方法發展於[天文學和](../Page/天文學.md "wikilink")[大地测量学領域](../Page/大地测量学.md "wikilink")，科學家和數學家嘗試為[大航海探索時期的海洋航行挑戰提供解決方案](../Page/地理大发现.md "wikilink")。準確描述天體的行為是船艦在大海洋上航行的關鍵，水手不能再依靠陸上目標導航作航行。

這個方法是在十八世紀期間一些進步的集大成：

  - 不同觀測值的組合是真實值的最佳估計；多次觀測會減少誤差而不是增加，也許在1722年由Roger Cotes首先闡明。

<!-- end list -->

  - 在相同條件下採取的不同觀察結果，與只嘗試記錄一次最精確的觀察結果是對立的。這個方法被稱為平均值方法。托馬斯·馬耶爾（Tobias
    Mayer）在1750年研究月球的[天平動時](../Page/天平動.md "wikilink")，特別使用這種方法，而[拉普拉斯](../Page/皮埃尔-西蒙·拉普拉斯.md "wikilink")（Pierre-Simon
    Laplace）在1788年他的工作成果中以此解釋[木星和](../Page/木星.md "wikilink")[土星的運動差異](../Page/土星.md "wikilink")。

<!-- end list -->

  - 在不同條件下進行的不同觀測值組合。該方法被稱為最小絕對偏差法，出現在Roger Joseph
    Boscovich在1757年他對地球形體的著名作品，而拉普拉斯在1799年也表示了同樣的問題。

<!-- end list -->

  - 評定對誤差達到最小的解決方案標準，拉普拉斯指明了誤差的[概率密度的數學形式](../Page/概率.md "wikilink")，並定義了誤差最小化的估計方法。為此，拉普拉斯使用了一雙邊對稱的指數分佈，現在稱為[拉普拉斯分佈作為誤差分佈的模型](https://zh.wikipedia.org/wiki/拉普拉斯分布 "wikilink")，並將絕對偏差之和作為估計誤差。他認為這是他最簡單的假設，他期待得出算術平均值而成為最佳的估計。可相反地，他的估計是後驗中位數。

### 最小平方法

[Carl_Friedrich_Gauss.jpg](https://zh.wikipedia.org/wiki/File:Carl_Friedrich_Gauss.jpg "fig:Carl_Friedrich_Gauss.jpg")

1801年，意大利天文学家[朱赛普·皮亚齐发现了第一颗小行星](https://zh.wikipedia.org/wiki/朱赛普·皮亚齐 "wikilink")[谷神星](https://zh.wikipedia.org/wiki/谷神星 "wikilink")。经过40天的跟踪观测后，由于谷神星运行至太阳背后，使得皮亚齐失去了谷神星的位置。随后全世界的科学家利用皮亚齐的观测数据开始寻找谷神星，但是根据大多数人计算的结果来寻找谷神星都没有结果。时年24岁的[高斯也计算了谷神星的轨道](https://zh.wikipedia.org/wiki/卡尔·弗里德里希·高斯 "wikilink")。奥地利天文学家[海因里希·奥伯斯根据高斯计算出来的轨道重新发现了谷神星](https://zh.wikipedia.org/wiki/海因里希·奥伯斯 "wikilink")。

[高斯使用的最小二乘法的方法发表于](https://zh.wikipedia.org/wiki/高斯 "wikilink")1809年他的著作《天体运动论》中，而法国科学家[勒让德于](https://zh.wikipedia.org/wiki/勒让德 "wikilink")1806年独立发现“最小二乘法”，但因不为世人所知而默默无闻。兩人曾为谁最早创立最小二乘法原理發生争执。

1829年，[高斯提供了最小二乘法的优化效果强于其他方法的证明](https://zh.wikipedia.org/wiki/高斯 "wikilink")，見[高斯-马尔可夫定理](../Page/高斯-马尔可夫定理.md "wikilink")。

## 方法

人们对由某一变量\(t\) 或多个变量\(t_{1}\)……\(t_{n}\)
构成的相关变量\(y\)感兴趣。如[弹簧的](../Page/弹簧.md "wikilink")[形变与所用的力相关](https://zh.wikipedia.org/wiki/形变 "wikilink")，一个[企业的盈利与其](../Page/企业.md "wikilink")[营业额](https://zh.wikipedia.org/wiki/营业额 "wikilink")，[投资收益和](https://zh.wikipedia.org/wiki/投资收益 "wikilink")[原始资本有关](https://zh.wikipedia.org/wiki/原始资本 "wikilink")。为了得到这些变量同\(y\)之间的关系，便用不相关变量去构建\(y\)，使用如下函数模型

\[y_m = f(t_1,\dots, t_q;b_1,\dots,b_p)\],

\(q\)个獨立变量或\(p\)个係數去拟合。

通常人们将一个可能的、对不相关变量t的构成都无困难的[函数类型称作函数模型](../Page/函数.md "wikilink")（如[抛物线函数或](../Page/抛物线.md "wikilink")[指数函数](https://zh.wikipedia.org/wiki/指數函數 "wikilink")）。参数b是为了使所选择的函数模型同观测值y相匹配。（如在测量弹簧形变时，必须将所用的力与弹簧的膨胀系数联系起来）。其目标是合适地选择参数，使函数模型最好的拟合观测值。**一般情况下，观测值远多於所选择的参数。**

其次的问题是怎样判断不同拟合的质量。[高斯和](https://zh.wikipedia.org/wiki/高斯 "wikilink")[勒让德的方法是](https://zh.wikipedia.org/wiki/勒让德 "wikilink")，**假设测量误差的平均值为0**。令每一个测量误差对应一个变量并与其它**测量误差不相关（随机无关）**。人们假设，在测量误差中绝对不含[系统误差](https://zh.wikipedia.org/wiki/系统误差 "wikilink")，它们应该是**纯[偶然误差](https://zh.wikipedia.org/wiki/偶然误差 "wikilink")(有固定的變異數)，围绕真值波动**。除此之外，**测量误差符合[正态分布](../Page/正态分布.md "wikilink")**，这保证了偏差值在最后的结果y上忽略不计。

确定拟合的标准应该被重视，并小心选择，较大误差的测量值应被赋予较小的[權](https://zh.wikipedia.org/wiki/權重 "wikilink")。并建立如下规则：被选择的参数，应该使算出的**函数曲线与观测值之差的平方和最小**。用[函数表示为](../Page/函数.md "wikilink")：

\(\min_{\vec{b}} { \sum_{i=1}^{n}(y_m - y_i)^2} .\)

用[欧几里得度量表达为](https://zh.wikipedia.org/wiki/欧几里得度量 "wikilink")：

\(\min_{ \vec{b} } \| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|^2_{2} \ .\)

又因为\(\| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|_{2}\) ≥0,

所以也可以表示为\(\min_{ \vec{b} } \| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|_{2} \ .\)

最小化问题的精度，依赖于所选择的函数模型。

## 线性函数模型

典型的一类函数模型是线性函数模型。最简单的线性式是\(y = b_0 + b_1 t\)，写成矩陣式，为

\[\min_{b_0,b_1}\left\|\begin{pmatrix}1 & t_1 \\ \vdots & \vdots \\ 1 & t_n  \end{pmatrix}
\begin{pmatrix} b_0\\ b_1\end{pmatrix} - \begin{pmatrix} y_1 \\ \vdots \\ y_{n}\end{pmatrix}\right\|_{2} = \min_b\|Ab-Y\|_2.\]
直接给出该式的参数解：

\[b_1 = \frac{\sum_{i=1}^n t_iy_i - n \cdot \bar t \bar y}{\sum_{i=1}^n t_i^2- n \cdot (\bar t)^2}\]
和 \(b_0 = \bar y - b_1 \bar t\)

其中\(\bar t = \frac{1}{n} \sum_{i=1}^n t_i\)，为t值的[算术平均值](https://zh.wikipedia.org/wiki/算术平均值 "wikilink")。也可解得如下形式：

\[b_1 = \frac{\sum_{i=1}^n (t_i - \bar t)(y_i - \bar y)}{\sum_{i=1}^n (t_i - \bar t)^2}\]

\===简单线性模型 y = b<sub>0</sub> + b<sub>1</sub>t 的例子===
随机选定10艘战舰，并分析它们的长度与宽度，寻找它们长度与宽度之间的关系。由下面的描点图可以直观地看出，一艘战舰的长度（t）与宽度（y）基本呈线性关系。散点图如下：
[散点图](https://zh.wikipedia.org/wiki/File:散点图.jpg "fig:散点图")

以下图表列出了各战舰的数据，随后步骤是采用最小二乘法确定两变量间的线性关系。

|    编号 | 长度 (m)        | 宽度 (m)        | t<sub>i</sub> - <font style="text-decoration:overline">t</font> | y<sub>i</sub> - <font style="text-decoration:overline">y</font> |                                |                                |                                |
| ----: | ------------- | ------------- | --------------------------------------------------------------- | --------------------------------------------------------------- | ------------------------------ | ------------------------------ | ------------------------------ |
|     i | t<sub>i</sub> | y<sub>i</sub> | t<sub>i</sub>\*                                                 | y<sub>i</sub>\*                                                 | t<sub>i</sub>\*y<sub>i</sub>\* | t<sub>i</sub>\*t<sub>i</sub>\* | y<sub>i</sub>\*y<sub>i</sub>\* |
|     1 | 208           | 21.6          | 40.2                                                            | 3.19                                                            | 128.238                        | 1616.04                        | 10.1761                        |
|     2 | 152           | 15.5          | \-15.8                                                          | \-2.91                                                          | 45.978                         | 249.64                         | 8.4681                         |
|     3 | 113           | 10.4          | \-54.8                                                          | \-8.01                                                          | 438.948                        | 3003.04                        | 64.1601                        |
|     4 | 227           | 31.0          | 59.2                                                            | 12.59                                                           | 745.328                        | 3504.64                        | 158.5081                       |
|     5 | 137           | 13.0          | \-30.8                                                          | \-5.41                                                          | 166.628                        | 948.64                         | 29.2681                        |
|     6 | 238           | 32.4          | 70.2                                                            | 13.99                                                           | 982.098                        | 4928.04                        | 195.7201                       |
|     7 | 178           | 19.0          | 10.2                                                            | 0.59                                                            | 6.018                          | 104.04                         | 0.3481                         |
|     8 | 104           | 10.4          | \-63.8                                                          | \-8.01                                                          | 511.038                        | 4070.44                        | 64.1601                        |
|     9 | 191           | 19.0          | 23.2                                                            | 0.59                                                            | 13.688                         | 538.24                         | 0.3481                         |
|    10 | 130           | 11.8          | \-37.8                                                          | \-6.61                                                          | 249.858                        | 1428.84                        | 43.6921                        |
| 总和（Σ） | 1678          | 184.1         | 0.0                                                             | 0.00                                                            | 3287.820                       | 20391.60                       | 574.8490                       |

仿照上面给出的例子

\(\bar t = \frac {\sum_{i=1}^n t_i}{n} = \frac {1678}{10} = 167{.}8\)
并得到相应的\(\bar y = 18{.}41\).

然后确定b<sub>1</sub>

\[b_1 = \frac{\sum_{i=1}^n (t_i- \bar {t})(y_i - \bar y)}{\sum_{i=1}^n (t_i- \bar t)^2}\]

\[= \frac{3287{.}820} {20391{.}60} = 0{.}1612 \;,\]

可以看出，战舰的长度每变化1m，相对应的宽度便要变化16cm。并由下式得到常数项b<sub>0</sub>：

\[b_0 = \bar y - b_1 \bar t = 18{.}41 - 0{.}1612 \cdot 167{.}8 = -8{.}6394
\;,\]

在这里随机理论不加阐述。可以看出点的拟合非常好，[长度和](../Page/长度.md "wikilink")[宽度的相关性大约为](https://zh.wikipedia.org/wiki/宽度 "wikilink")96.03％。
利用Matlab得到拟合直线：
[最小二乘法Matlab拟合](https://zh.wikipedia.org/wiki/File:最小二乘法拟合.jpg "fig:最小二乘法Matlab拟合")

### 一般线性情况

若含有更多不相关模型变量\(t_1, ..., t_q\)，可如组成线性[函数的形式](../Page/函数.md "wikilink")

\[y(t_1,\dots,t_q;b_0, b_1, \dots, b_q )= b_0 + b_1 t_1 + \cdots + b_q t_q\]

即[线性方程组](../Page/线性方程组.md "wikilink")

\[\begin{matrix}
b_0 + b_1 t_{11} + \cdots + b_j t_{1j}+ \cdots +b_q t_{1q} = y_1\\
b_0 + b_1 t_{21} + \cdots + b_j t_{2j}+ \cdots +b_q t_{2q} = y_2\\
\vdots \\
b_0 + b_1 t_{i1} + \cdots + b_j t_{ij}+ \cdots +b_q t_{iq}= y_i\\
\vdots\\
b_0 + b_1 t_{n1} + \cdots + b_j t_{nj}+ \cdots +b_q t_{nq}= y_n
\end{matrix}\]

通常人们将*t<sub>ij</sub>*记作数据矩阵
*A*，参数*b<sub>j</sub>*记做参数向量*b*，观测值*y<sub>i</sub>*记作*Y*，则线性方程组又可写成：

\[\begin{pmatrix}
1 & t_{11} & \cdots & t_{1j} \cdots & t_{1q}\\
1 & t_{21} & \cdots & t_{2j} \cdots & t_{2q}\\
\vdots \\
1 & t_{i1} & \cdots & t_{ij} \cdots & t_{iq}\\
\vdots\\
1 & t_{n1} & \cdots & t_{nj} \cdots & t_{nq}
\end{pmatrix}
\cdot
\begin{pmatrix}
b_0\\
b_1\\
b_2\\
\vdots \\
b_j\\
\vdots\\
b_q
\end{pmatrix}
=
\begin{pmatrix}
y_1\\
y_2\\
\vdots \\
y_i\\
\vdots\\
y_n
\end{pmatrix}\] 即 \(Ab = Y\)

上述方程运用最小二乘法导出为线性平方差计算的形式为：

\[\min_b\|Ab-Y\|_2\]。

### 最小二乘法的解

\(\min_b \left \|\boldsymbol{Ab}- \boldsymbol{Y} \right \|_2,\boldsymbol{A}\in\mathbf{C}^{n\times m},\boldsymbol{Y}\in\mathbf{C}^{n}\)

的特解为***A***的[广义逆矩阵与](https://zh.wikipedia.org/wiki/广义逆矩阵 "wikilink")***Y***的乘积，这同时也是二[范数极小的解](../Page/范数.md "wikilink")，其通解为特解加上***A***的[零空间](../Page/零空间.md "wikilink")。证明如下：

先将**Y**拆成***A***的值域及其[正交补两部分](../Page/正交补.md "wikilink")

\[\boldsymbol{Y}=\boldsymbol{Y}_{1}+\boldsymbol{Y}_{2}\]

\[\boldsymbol{Y}_{1}=\boldsymbol{A}\boldsymbol{A}^\dagger\boldsymbol{Y}\in R\left(\boldsymbol{A} \right)\]

\[\boldsymbol{Y}_{2}=\left(\boldsymbol{I}- \boldsymbol{A}\boldsymbol{A}^\dagger \right)\boldsymbol{Y}\in R\left(\boldsymbol{A} \right)^{\bot}\]
所以\(\boldsymbol{Ab}-\boldsymbol{Y}_{1}\in R\left(\boldsymbol{A} \right)\)，可得

\[\left \| \boldsymbol{Ab}- \boldsymbol{Y} \right \|^{2}=\left \| \boldsymbol{Ab}- \boldsymbol{Y}_{1} +\left(-\boldsymbol{Y}_{2}\right) \right \|^{2}=\left \| \boldsymbol{Ab}- \boldsymbol{Y}_{1} \right \|^{2}+\left \|\boldsymbol{Y}_{2} \right \|^{2}\]
故当且仅当\(\boldsymbol{b}\)是\(\boldsymbol{Ab}= \boldsymbol{Y}_{1} =\boldsymbol{A}\boldsymbol{A}^\dagger\boldsymbol{Y}\)解时，\(\boldsymbol{b}\)即为最小二乘解，即\(\boldsymbol{b}=\boldsymbol{A}^\dagger \boldsymbol{Y} = {\left( {{{\mathbf{A}}^H}{\mathbf{A}}} \right)^{ - 1}}{{\mathbf{A}}^H}{\mathbf{Y}}\)。

又因为

\[N\left(\boldsymbol{A}\right)=N\left(\boldsymbol{A}^\dagger \boldsymbol{A}\right)=R\left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A}\right)=\left\{ \left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A} \right) \boldsymbol{h}:\boldsymbol{h}\in\mathbf{C}^{n}  \right\}\]
故\(\boldsymbol{Ab}=\boldsymbol{A}\boldsymbol{A}^\dagger\boldsymbol{Y}\)的通解为

\[\boldsymbol{b}=\boldsymbol{A}^\dagger\boldsymbol{Y}+\left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A} \right) \boldsymbol{h}:\boldsymbol{h}\in\mathbf{C}^{n}\]
因为

\[\begin{align}
\left \| \boldsymbol{A}^\dagger\boldsymbol{Y}\right \|^{2} & < \left \| \boldsymbol{A}^\dagger\boldsymbol{Y} \right \|^{2}+ \left \| \left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A} \right) \boldsymbol{h} \right \|^{2} \\
& = \left \| \boldsymbol{A}^\dagger\boldsymbol{Y} + \left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A} \right) \boldsymbol{h} \right \|^{2},\left(\boldsymbol{I}-\boldsymbol{A}^\dagger \boldsymbol{A} \right) \boldsymbol{h}\neq\boldsymbol{0} \\
\end{align}\]
所以\(\boldsymbol{A}^\dagger \boldsymbol{Y}\)又是二[范数极小的最小二乘解](../Page/范数.md "wikilink")。

## 参考文献

### 书籍

  -
## 外部链接

  - [3種統計學點估計的理論推演:動差法,最小平方法,最大概似估計法](http://molecular-service-science.com/2012/06/30/statistical-estimation/)

  - [中央大學數學系教材-最小平方法](http://libai.math.ncu.edu.tw/libai/about.html)

  - <http://www.physics.csbsju.edu/stats/least_squares.html>

  - <http://www.zunzun.com>

  - <http://www.orbitals.com/self/least/least.htm>

  -
[Category:最优化](https://zh.wikipedia.org/wiki/Category:最优化 "wikilink")
[Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink")
[Category:误差理论](https://zh.wikipedia.org/wiki/Category:误差理论 "wikilink")
[Category:回归分析](https://zh.wikipedia.org/wiki/Category:回归分析 "wikilink")
[Category:計量經濟學](https://zh.wikipedia.org/wiki/Category:計量經濟學 "wikilink")
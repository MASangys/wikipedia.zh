> 本文内容由[核回归](https://zh.wikipedia.org/wiki/核回归)转换而来。


**核回归（又称局部加权线性回归）**是统计学中用于估计[随机变量](../Page/随机变量.md "wikilink")的[条件期望](../Page/条件期望.md "wikilink")的[非参数方法](../Page/無母數統計.md "wikilink")。目的是找到一对随机变量***X***和***Y***之间的非线性关系。

在任何非参数回归中 ，变量的[条件期望](../Page/条件期望.md "wikilink") \(Y\)相对于变量\(X\)可以写成：

\(\operatorname{E}(Y | X) = m(X)\)

m为一个未知函数。

## Nadaraya–Watson核回归

1964年， Nadaraya和Watson都提出了估算\(m\)作为局部加权平均值，使用内核作为加权函数的方法。 \[1\] \[2\] \[3\] Nadaraya–Watson估计量为：

\(\widehat{m}_h(x)=\frac{\sum_{i=1}^n K_h(x-x_i) y_i}{\sum_{j=1}^nK_h(x-x_j)}\)

\(K_h\)是一个带宽为 \(h\) 的核。 分母是一个总和为1的加权项。

### 推导

\(\operatorname{E}(Y | X=x) = \int y f(y|x) dy = \int y \frac{f(x,y)}{f(x)} dy\)

将[内核密度估计用于具有内核](https://zh.wikipedia.org/wiki/核密度估计 "wikilink")***K***的联合分布*f（x，y）*和*f（x）* ，

\(\hat{f}(x,y) = \frac{1}{n}\sum_{i=1}^{n} K_h\left(x-x_i\right) K_h\left(y-y_i\right)\), \(\hat{f}(x) = \frac{1}{n} \sum_{i=1}^{n} K_h\left(x-x_i\right)\),

我们得到

\(\begin{align}
\operatorname{\hat E}(Y | X=x) &= \int \frac{y \sum_{i=1}^{n} K_h\left(x-x_i\right) K_h\left(y-y_i\right)}{\sum_{j=1}^{n} K_h\left(x-x_j\right)} dy,\\
&= \frac{\sum_{i=1}^{n} K_h\left(x-x_i\right) \int y \, K_h\left(y-y_i\right) dy}{\sum_{j=1}^{n} K_h\left(x-x_j\right)},\\
&= \frac{\sum_{i=1}^{n} K_h\left(x-x_i\right) y_i}{\sum_{j=1}^{n} K_h\left(x-x_j\right)},
\end{align}\)

这便是Nadaraya–Watson估计量。

## Priestley–Chao核估计函数

\(\widehat{m}_{PC}(x) = h^{-1} \sum_{i=2}^n (x_i - x_{i-1}) K\left(\frac{x-x_i}{h}\right) y_i\)

此处 \(h\) 为带宽（或平滑参数）。

## Gasser–Müller核估计函数

\(\widehat{m}_{GM}(x) = h^{-1} \sum_{i=1}^n \left[\int_{s_{i-1}}^{s_i} K\left(\frac{x-u}{h}\right) du\right] y_i\)

此处 \(s_i = \frac{x_{i-1} + x_i}{2}\)

## 示例

此示例基于加拿大截面工资数据，该数据由1971年加拿大人口普查公用带中的随机样本组成，这些样本适用于受过普通教育的男性（13年级）。共有205个观测值。

右图显示了使用二阶高斯核以及渐近变化范围的估计回归函数

### 程序实例

以下[R语言](../Page/R语言.md "wikilink")命令使用`npreg()`函数提供最佳平滑效果并创建上面给出的图形。 这些命令可以通过剪切和粘贴在命令提示符下输入。

``` rsplus numberLines
 install.packages("np")
 library(np) # non parametric library
 data(cps71)
 attach(cps71)

 m <- npreg(logwage~age)

 plot(m,plot.errors.method="asymptotic",
   plot.errors.style="band",
   ylim=c(11,15.2))

 points(age,logwage,cex=.25)
```

## 相关资料

大卫·萨尔斯堡 （David Salsburg）指出 ，用于内核回归的算法是独立开发的，并且已用于[模糊系统](../Page/模糊控制.md "wikilink") ：“通过几乎完全相同的计算机算法，模糊系统和基于内核密度的回归似乎是完全独立于彼此而开发的。 ” \[4\]

## 统计实现

  - [MATLAB](../Page/MATLAB.md "wikilink") [这些页面](https://www.math.muni.cz/english/science-and-research/developed-software/232-matlab-toolbox.html)上提供了免费的MATLAB工具箱，其中包括内核回归，内核密度估计，危险函数的内核估计以及许多其他工具的实现（此工具箱是本书的一部分\[5\] ）。
  - [Stata](https://zh.wikipedia.org/wiki/Stata "wikilink") [npregress](https://www.stata.com/manuals/rnpregress.pdf) ， [kernreg2](https://ideas.repec.org/c/boc/bocode/s372601.html)
  - [R](../Page/R语言.md "wikilink") ： *np package*的函数`npreg`可以执行内核回归。 \[6\] \[7\]
  - [Python](../Page/Python.md "wikilink") ：所述[`KernelReg`](http://www.statsmodels.org/stable/generated/statsmodels.nonparametric.kernel_regression.KernelReg.html)在混合数据类型类[`statsmodels.nonparametric`](http://www.statsmodels.org/stable/nonparametric.html)子包（包括其他内核密度相关的类），封装[kernel_regression](https://github.com/jmetzen/kernel_regression)作为的延伸sklearn （低效存储器明智的，有用的，只有对于小数据集）
  - [GNU Octave数学程序包](../Page/GNU_Octave.md "wikilink")：

## 相关资料

  - 内核平滑
  - 局部回归

## 参考文献

## 延申阅读

  -
  -
  -
  -
## 外部链接

  - [可缩放比例的内核回归](http://www.cs.tut.fi/~lasip) （使用Matlab软件）。
  - [使用电子表格](https://web.archive.org/web/20070927062200/http://people.revoledu.com/kardi/tutorial/Regression/KernelRegression/index.html) （使用[Microsoft Excel](../Page/Microsoft_Excel.md "wikilink") ） [进行内核回归的教程](https://web.archive.org/web/20070927062200/http://people.revoledu.com/kardi/tutorial/Regression/KernelRegression/index.html) 。
  - [在线内核回归演示](http://pcarvalho.com/things/kernelregressor/) Requires。 NET 3.0或更高版本。
  - [具有自动带宽选择功能的内核回归](https://github.com/jmetzen/kernel_regression) （使用Python）

[Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink")

1.
2.
3.
4.
5.
6.  [*np*: Nonparametric kernel smoothing methods for mixed data types](https://cran.r-project.org/web/packages/np/index.html)
7.
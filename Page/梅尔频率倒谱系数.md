> 本文内容由[梅尔频率倒谱系数](https://zh.wikipedia.org/wiki/梅尔频率倒谱系数)转换而来。


在聲音處理領域中，**梅爾頻率倒譜**(Mel-Frequency Cepstrum)是基於聲音頻率的非線性[梅爾刻度](https://zh.wikipedia.org/wiki/梅爾刻度 "wikilink")(mel scale)的[對數能量頻譜的線性變換](https://zh.wikipedia.org/wiki/對數 "wikilink")。

**梅爾頻率倒譜系數** (**Mel-Frequency Cepstral Coefficients，MFCCs**)就是組成梅爾頻率倒譜的係數。它衍生自音訊片段的[倒頻譜](../Page/倒頻譜.md "wikilink")(cepstrum)。倒譜和梅爾頻率倒譜的區別在於，梅爾頻率倒譜的頻帶劃分是在[梅爾刻度上等距劃分的](https://zh.wikipedia.org/wiki/梅爾刻度 "wikilink")，它比用於正常的對數[倒頻譜](../Page/倒頻譜.md "wikilink")中的線性間隔的頻帶更能近似人類的聽覺系統。 這樣的非線性表示，可以在多個領域中使聲音信號有更好的表示。例如在[音訊壓縮中](https://zh.wikipedia.org/wiki/音訊壓縮 "wikilink")。

梅爾頻率倒譜係數（MFCC）廣泛被應用於[語音識別的功能](https://zh.wikipedia.org/wiki/語音識別 "wikilink")。他們由Davis和Mermelstein在1980年代提出，並在其後持續是最先進的技術之一。在MFCC之前，線性預測係數（LPCS）和線性預測倒譜系數（LPCCs）是自動語音識別的的主流方法。

MFCC通常有以下之過程:\[1\]\[2\]

1.  將一段語音信號分解為多個[訊框](https://zh.wikipedia.org/wiki/訊框 "wikilink")。
2.  將語音信號[預強化](https://zh.wikipedia.org/wiki/預強化 "wikilink")，通過一個[高通](../Page/高通.md "wikilink")[濾波器](https://zh.wikipedia.org/wiki/濾波器 "wikilink")。
3.  進行[傅立叶变换](https://zh.wikipedia.org/wiki/傅立叶变换 "wikilink")，將信號轉換至頻域。
4.  將每個[訊框獲得的频譜通過梅爾濾波器](https://zh.wikipedia.org/wiki/訊框 "wikilink")(三角重叠窗口)，得到[梅爾刻度](https://zh.wikipedia.org/wiki/梅爾刻度 "wikilink")。
5.  在每个梅爾刻度上提取[對數能量](https://zh.wikipedia.org/wiki/對數 "wikilink")。
6.  对上面获得的结果进行[离散傅立葉反变换](https://zh.wikipedia.org/wiki/离散傅立葉反变换 "wikilink")，轉換到[倒頻譜](../Page/倒頻譜.md "wikilink")域。
7.  MFCC就是這個[倒频谱图的幅度](https://zh.wikipedia.org/wiki/倒频谱 "wikilink")(amplitudes)。一般使用12個係數，與訊框能量疊加得13維的係數。

### MFCC的原理

聲音信號是連續變化的，為了將連續變化信號簡化，我們假設在一個短時間尺度內，音頻信號不發生改變。因此將信號以多個取樣點集合成一個單位，稱為[**訊框**](https://zh.wikipedia.org/wiki/'''訊框''' "wikilink")。一個訊框多為20-40毫秒，如果訊框長度更短，那每個訊框內的取樣點將不足以做出可靠的頻譜計算，但若長度太長，則每個訊框信號會變化太大。

**預強化**的目的就是為了消除發聲過程中，聲帶和嘴唇造成的效應，來補償語音信號受到發音系統所壓抑的高頻部分。並且能突顯高頻的共振峰。

由於訊號在時域上的變化通常很難看出訊號的特性，所以通常透過[傅立葉轉換將它轉換成頻域上的能量分佈來觀察](https://zh.wikipedia.org/wiki/傅立葉轉換 "wikilink")，不同的能量分佈，就能代表不同語音的特性。

由於能量頻譜中還存在大量的無用訊息，尤其人耳無法分辨高頻的頻率變化，因此讓頻譜通過梅爾濾波器。 **梅爾濾波器**，也就是一組20個非線性分布的**三角帶通濾波器（Triangular Bandpass Filters）**，能求得每一個濾波器輸出的對數能量。必須注意的是：這 20 個三角帶通濾波器在[**梅爾刻度**的頻率上是平均分佈的](https://zh.wikipedia.org/wiki/'''梅爾刻度''' "wikilink")。 梅爾頻率代表一般人耳對於頻率的感受度，由此也可以看出人耳對於頻率 f 的感受是呈對數變化的。

<http://i.stack.imgur.com/YUH48.gif>

最後的步驟是計算對數濾波器的能量的[離散傅立葉反變換](https://zh.wikipedia.org/wiki/離散傅立葉反變換 "wikilink")，在此相當於離散餘弦反變換(IDCT)。值得注意的是，雖然通常的會有24-26個係數，但我們只保留前12個係數。這是因為丟棄高[倒頻域值的DCT係數](https://zh.wikipedia.org/wiki/倒頻域 "wikilink")，代表一個類似低通濾波器的概念，可以使信號平滑化，能增進語音處理的性能。

\[3\] \[4\] \[5\]

在此过程中可以有很多变化，例如，映射时的窗口的形状和间距。\[6\] The 在2000年初定义了一个可以用在移动电话上的标准MFCC算法.\[7\]

### 參考

## 詳細推導

1.對該信號做[傅立葉變換](https://zh.wikipedia.org/wiki/傅立葉變換 "wikilink")
X\[k\]=FT{x\[n\]}
2.根據下面公式算出Y\[m\]
\(Y[m]=\log \left( \sum_{k=f_{m-1}}^{f_{m+1}} \left| X[k] \right|^2 B_m[k] \right)\)
其中\(B_m[k]\)是梅爾頻率倒頻譜的遮罩
[有框](https://zh.wikipedia.org/wiki/File:B_m-k-.png "fig:有框") \(B_m[k]= \begin{cases} 0 & \mbox{for } k<f_{m-1} \mbox{ and } k>f_{m+1}\\
\cfrac {k-f_{m-1}}{f_m-f_{m-1}} & \mbox{for } f_{m-1} \leq k \leq f_m \\
\cfrac {f_{m+1}-k}{f_{m+1}-f_m} & \mbox{for } f_m \leq k \leq f_{m+1}  \end{cases}\)
3.對Y\[m\]做IDCT得\(c_x[n]\)
因為Y\[m\]是偶函數,故用IDCT(反離散餘弦變換)取代IDFT(反離散傅立葉變換)
\(c_x[n]= \frac{1}{M} \sum_{m=1}^{M} Y[m]cos \left( \cfrac{\pi n(m-1/2)}{M} \right)\)

與原倒頻譜的差異
一.log裡面因為使用了sum,故等於0的機率變小
二.避免了相位的問題
三.使用IDCT取代IDFT,減少了運算量
四.\(B_m[k]\)隨著頻率的增加而增寬,該特性符合人類聽覺,更適合用來描述語音特徵

## 应用

MFCC主要作为[语音识别](../Page/语音识别.md "wikilink")系统中的特征，这样的系统可以自动识别语音中的数字内容。MFCC同样也用于，该技术尝试通过语音该鉴别说话人。\[8\]

MFCC也被用于领域，如流派分类(genre classification)、音频相似性计算等。\[9\]


比起倒頻譜,梅爾倒頻譜更接近人耳對於語音的區別性(因為遮罩\(B[k]\))
用\(c_x[1],c_x[2],...,c_x[13]\),MFCCs的前13項足以描述語音特徵

## 噪声的敏感性

MFCC特征在加性噪声的情况下并不稳定，因此在语音识别系统中通常要对其进行归一化处理(normalise)以降低噪声的影响。一些研究人员对MFCC算法进行修改以提升其強健性，如在进行DCT之前将log-mel-amplitudes提升到一个合适的能量(2到3之间)，以此来降低低能量成分的影响.\[10\]

## 参考文献

## 外部链接

  - [A tutorial on MFCCs for Automatic Speech Recognition](http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)

[Category:信号处理](https://zh.wikipedia.org/wiki/Category:信号处理 "wikilink")

1.
2.
3.  <http://mirlab.org/jang/books/audiosignalprocessing/speechFeatureMfcc_chinese.asp?title=12-2+MFCC>
4.  <http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/>
5.  <http://djj.ee.ntu.edu.tw/ADSP_tutorial_D98921028.pdf>
6.  Fang Zheng, Guoliang Zhang and Zhanjiang Song (2001), "[Comparison of Different Implementations of MFCC](http://link.springer.com/article/10.1007%2FBF02943243?LI=true#page-1)," *J. Computer Science & Technology,* 16(6): 582–589.
7.  European Telecommunications Standards Institute (2003), [Speech Processing, Transmission and Quality Aspects (STQ); Distributed speech recognition; Front-end feature extraction algorithm; Compression algorithms](http://webapp.etsi.org/workprogram/Report_WorkItem.asp?wki_id=18820). Technical standard ES 201 108, v1.1.3.
8.  T. Ganchev, N. Fakotakis, and G. Kokkinakis (2005), "[Comparative evaluation of various MFCC implementations on the speaker verification task](http://www.wcl.ece.upatras.gr/ganchev/Papers/ganchev17.pdf) ," in *10th International Conference on Speech and Computer (SPECOM 2005),* Vol. 1, pp. 191–194.
9.
10. V. Tyagi and C. Wellekens (2005), , in Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP ’05). IEEE International Conference on, vol. 1, pp. 529–532.
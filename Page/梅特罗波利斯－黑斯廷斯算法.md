[Metropolis_hastings_algorithm.png](https://zh.wikipedia.org/wiki/File:Metropolis_hastings_algorithm.png "fig:Metropolis_hastings_algorithm.png")下一状态的可能位置\]\]
**梅特罗波利斯－黑斯廷斯算法**（）是[统计学与](../Page/统计学.md "wikilink")[统计物理中的一种](https://zh.wikipedia.org/wiki/统计物理 "wikilink")[马尔科夫蒙特卡洛](https://zh.wikipedia.org/wiki/马尔科夫蒙特卡洛 "wikilink")（MCMC）方法，用于在难以直接采样时从某一[概率分布中抽取随机](../Page/概率分布.md "wikilink")[样本序列](https://zh.wikipedia.org/wiki/样本 "wikilink")。得到的序列可用于估计该概率分布或计算积分（如[期望值](../Page/期望值.md "wikilink")）等。梅特罗波利斯－黑斯廷斯或其他MCMC算法一般用于从多变量（尤其是高维）分布中采样。对于单变量分布而言，常会使用自适应判别采样（adaptive
rejection
sampling）等其他能抽取独立样本的方法，而不会出现MCMC中样本[自相关的问题](https://zh.wikipedia.org/wiki/自相关 "wikilink")。

该算法的名称源于美国物理学家[尼古拉斯·梅特罗波利斯](../Page/尼古拉斯·梅特罗波利斯.md "wikilink")\[1\]与加拿大统计学家。\[2\]

## 算法

假设\(P(x)\)为目标概率分布。梅特罗波利斯－黑斯廷斯算法的过程为：

1.  初始化
    1.  选定初始状态\(x_0\)；
    2.  令\(t=0\)；
2.  迭代过程
    1.  **生成：** 从某一容易抽样的分布\(Q(x' | x_t)\)中随机生成候选状态\(x'\)；
    2.  **计算：**
        计算是否采纳候选状态的概率\(A(x' | x) = \min\left(1,\frac{P(x')}{P(x)}\frac{Q(x | x')}{Q(x' | x)}\right)\)；
    3.  **接受或拒绝**
        1.  从\([0,1]\)的均匀分布中生成随机数\(u\)；
        2.  如\(u \le A(x' | x)\)，则接受该状态，并令\(x_{t+1} = x'\)；
        3.  如\(u >   A(x' | x)\)，则拒绝该状态，并令\(x_{t+1} = x_{t}\)（复制原状态）；
    4.  **增量：**令\(t=t+1\)；

## 注释

## 参考文献

  - Bernd A. Berg. *Markov Chain Monte Carlo Simulations and Their
    Statistical Analysis*. Singapore, World Scientific, 2004.
  - Siddhartha Chib and Edward Greenberg: "Understanding the
    Metropolis–Hastings Algorithm". *American Statistician*, 49(4),
    327–335, 1995
  - [David D. L. Minh and Do Le Minh. "Understanding the Hastings
    Algorithm." Communications in Statistics - Simulation and
    Computation, 44:2 332-349, 2015](http://www.tandfonline.com/doi/abs/10.1080/03610918.2013.777455#.VOk8J1PF9_c)
  - Bolstad, William M. (2010) *Understanding Computational Bayesian
    Statistics*, John Wiley & Sons

[Category:蒙地卡羅方法](https://zh.wikipedia.org/wiki/Category:蒙地卡羅方法 "wikilink")

1.
2.
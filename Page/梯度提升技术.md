> 本文内容由[梯度提升技术](https://zh.wikipedia.org/wiki/梯度提升技术)转换而来。


**梯度提升（梯度增强）**是一种用于[回归和](../Page/迴歸分析.md "wikilink")[分类问题的](https://zh.wikipedia.org/wiki/统计分类 "wikilink")[机器学习](../Page/机器学习.md "wikilink")技术，其产生的预测模型是弱预测模型的[集成](../Page/集成学习.md "wikilink")，如采用典型的[决策树](../Page/决策树学习.md "wikilink") 作为弱预测模型，这时则为梯度提升树（GBT或GBDT）。像其他[提升方法](../Page/提升方法.md "wikilink")一样，它以分阶段的方式构建模型，但它通过允许对任意可[微分](../Page/可微函数.md "wikilink")[损失函数进行优化作为对一般提升方法的推广](https://zh.wikipedia.org/wiki/损失函数 "wikilink")。

梯度提升的思想源自Leo Breiman的一个观察：即可以将提升方法解释为针对适当成本函数的优化算法。 \[1\]显式回归梯度增强算法随后由Jerome H. Friedman \[2\] \[3\]给出，同时Llew Mason，Jonathan Baxter，Peter Bartlett和Marcus Frean在两篇论文中给出更一般的函数空间上的梯度提升观点。 \[4\] \[5\]这两篇论文介绍了将Boosting算法看作*函数空间上的梯度下降迭代*算法的观点。即，将其视为通过迭代地选择指向负梯度方向的函数（弱预测模型）来优化函数空间上的成本函数的算法。这种将提升视为函数梯度的观点导致了除回归和分类之外的许多机器学习和统计领域中提升算法的发展。

## 非正式介绍

（本节遵循Li \[6\]对梯度增强的说明。）

与其他增强方法一样，梯度增强以迭代方式将弱的“学习器”组合为一个强学习器。最简单的解释是在最小二乘[回归中](../Page/迴歸分析.md "wikilink")，通过最小化[均方误差](../Page/均方误差.md "wikilink") \(\tfrac{1}{n}\sum_i(\hat{y}_i - y_i)^2\) ，“教”模型\(F\)预测实数值\(\hat{y} = F(x)\)。

在梯度提升的每个阶段 \(m\), \(1 \le m \le M\), 假设已经有一个不太完美的模型 \(F_m\) (最开始时只是一个预测输出变量  均值的模型)。 梯度提升算法通过在当前模型 \(F_m\) 增加一个新的估计量  得到一个更好的模型: \(F_{m+1}(x) = F_m(x) + h(x)\). 为了求得 \(h\), 梯度提升基于以下观察：一个完美的  可以完美预测当前不完美模型\(F_m\)的残差，即满足，

  -
    <math>

F_{m+1}(x) = F_m(x) + h(x) = y </math>

或者，等效地有，

  -
    <math>

h(x) = y - F_m(x) </math>.

因此，梯度提升通过拟合*[残差](../Page/误差.md "wikilink")* \(y - F_m(x)\)得到  。和其他提升方法的变体一样, \(F_{m+1}\) 通过纠正 \(F_m\)的误差变得更完美。 这个想法可以扩展到均方误差损失之外的任意损失函数，甚至扩展到分类与排序问题，只要观察到以下一点：模型的*[残差](../Page/误差.md "wikilink")* \(y - F_m(x)\)就是均方损失函数\(\frac{1}{2}(y - F(x))^2\)关于\(F(x)\)的负梯度。因此，梯度提升其实是一种 [梯度下降算法](https://zh.wikipedia.org/wiki/梯度下降法 "wikilink")，可以代入除了均方损失之外的不同的损失函数，得到不同的梯度。

## 算法

在许多有[监督学习问题中](../Page/監督式學習.md "wikilink")，一个输出变量和一个输入变量通过[联合概率分布](../Page/联合分布.md "wikilink")\(P(x,y)\)描述 。给定训练集\(\{ (x_1,y_1), \dots, (x_n,y_n) \}\)，目的是在所有具有给定形式的函数\(F(x)\)中找到一个\(\hat{F}(x)\)使某些指定[损失函数\(L(y, F(x))\)的期望值达到最小](https://zh.wikipedia.org/wiki/损失函数 "wikilink") ：

  -
    \(\hat{F} = \underset{F}{\arg\min} \, \mathbb{E}_{x,y}[L(y, F(x))]\).

梯度提升方法通过某一类\(\mathcal{H}\)中弱学习器（或称[基学习器](../Page/提升方法.md "wikilink")）\(h_i (x)\)带权重和的形式来表示对实值变量做出估计的\(\hat{F}(x)\):

  -
    \(\hat{F}(x) = \sum_{i=1}^M \gamma_i h_i(x) + \mbox{const}\).

根据[经验风险最小化](../Page/经验风险最小化.md "wikilink")原理，该方法试图找到一个近似\(\hat{F}(x)\)可以最大程度地减少训练集上损失函数的平均值，即，最小化经验风险。它是从一个由常数函数组成的模型\(F_0(x)\)开始 ，并以[贪心的方式逐步扩展](../Page/贪心算法.md "wikilink")：

  -
    \(F_0(x) = \underset{\gamma}{\arg\min} {\sum_{i=1}^n {L(y_i, \gamma)}}\),
    \(F_m(x) = F_{m-1}(x) + \underset{h_m \in \mathcal{H}}{\operatorname{arg\,min}} \left[{\sum_{i=1}^n {L(y_i, F_{m-1}(x_i) + h_m(x_i))}}\right]\),

上式\(h_m \in \mathcal{H}\)是基学习器。

不幸的是，通常在每个步骤中为任意损失函数**选择最佳函数**是计算上不可行的优化问题。 因此，我们将方法局限于问题的简化版本。

这个想法是对这个最小化问题（函数梯度下降）应用[梯度下降步骤](https://zh.wikipedia.org/wiki/梯度下降法 "wikilink")。如果我们考虑连续情况，即\(\mathcal{H}\)是上的任意微分函数的集合\(\R\) ，我们将根据以下方程式更新模型

  -
    \(F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^n {\nabla_{F_{m-1}} L(y_i, F_{m-1}(x_i))},\)
    <math>\\gamma_m = \\underset{\\gamma}{\\arg\\min} {\\sum_{i=1}^n {L\\left(y_i, F_{m-1}(x_i) -

`   \gamma \nabla_{F_{m-1}} L(y_i, F_{m-1}(x_i)) \right)}},`</math>

式子中，对于\(i \in \{ 1,..,m \}\)是关于函数\(F_i\)求导，\(\gamma_m\)是步长。 但是在离散情况下，即\(\mathcal{H}\)如果是有限的，我们选择最接近梯度的候选函数 ，然后可以根据上述等式通过[线搜索](../Page/线搜索.md "wikilink")来计算系数 。 请注意，这种方法是一种启发式方法，因此不能给出给定问题的精确解决方案，而是一种近似方法。 在伪代码中，通用梯度增强方法是： \[7\] \[8\]  Input: training set \(\{(x_i, y_i)\}_{i=1}^n,\) a differentiable loss function \(L(y, F(x)),\) number of iterations .

Algorithm:

1.  Initialize model with a constant value:
      -
        \(F_0(x) = \underset{\gamma}{\arg\min} \sum_{i=1}^n L(y_i, \gamma).\)
2.  For  = 1 to :
    1.  Compute so-called *pseudo-residuals*:
          -
            \(r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)} \quad \mbox{for } i=1,\ldots,n.\)
    2.  Fit a base learner (or weak learner, e.g. tree) \(h_m(x)\) to pseudo-residuals, i.e. train it using the training set \(\{(x_i, r_{im})\}_{i=1}^n\).
    3.  Compute multiplier \(\gamma_m\) by solving the following [one-dimensional optimization](../Page/线搜索.md "wikilink") problem:
          -
            \(\gamma_m = \underset{\gamma}{\operatorname{arg\,min}} \sum_{i=1}^n L\left(y_i, F_{m-1}(x_i) + \gamma h_m(x_i)\right).\)
    4.  Update the model:
          -
            \(F_m(x) = F_{m-1}(x) + \gamma_m h_m(x).\)
3.  Output \(F_M(x).\)

## 梯度树增强

梯度提升通常与固定大小的[决策树](../Page/决策树学习.md "wikilink") （尤其是[CART树](../Page/决策树学习.md "wikilink")）一起用作基础学习者。 对于这种特殊情况，Friedman提出了对梯度增强方法的改进，以提高每个基础学习者的适应质量。

第*m*步的通用梯度提升将适合决策树\(h_m(x)\)伪残留物。 让\(J_{m}\)是它的叶子数。 树将输入空间划分为\(J_{m}\)不相交的区域\(R_{1m}, \ldots, R_{J_{m}m}\)并预测每个区域的恒定值。 使用[指标符号](../Page/指示函数.md "wikilink") ，输出\(h_m(x)\)输入*x*可以写为和：

  -
    \(h_m(x) = \sum_{j=1}^{J_{m}} b_{jm} \mathbf {1}_{R_{jm}}(x),\)

这里\(b_{jm}\)是该区域中预测的值\(R_{jm}\) 。 \[9\]

然后系数\(b_{jm}\)乘以一些值\(\gamma_m\) ，使用线搜索进行选择，以最大程度地减少损失函数，并按以下方式更新模型：

  -
    <math>

` F_m(x) = F_{m-1}(x) + \gamma_m h_m(x), \quad`
` \gamma_m = \underset{\gamma}{\operatorname{arg\,min}} \sum_{i=1}^n L(y_i, F_{m-1}(x_i) + \gamma h_m(x_i)).`
</math>

弗里德曼（Friedman）建议修改此算法，以便选择一个单独的最佳值\(\gamma_{jm}\)每个树的区域，而不是单个\(\gamma_m\)为整棵树。 他称修改后的算法为“ TreeBoost”。 系数\(b_{jm}\)然后可以简单地丢弃树拟合过程中的数据，模型更新规则变为：

  -
    <math>

` F_m(x) = F_{m-1}(x) + \sum_{j=1}^{J_{m}} \gamma_{jm} \mathbf {1}_{R_{jm}}(x), \quad`
` \gamma_{jm} = \underset{\gamma}{\operatorname{arg\,min}} \sum_{x_i \in R_{jm}} L(y_i, F_{m-1}(x_i) + \gamma).`
</math>

### 树木大小

\(J\) （树中终端节点的数量）是该方法的参数，可以针对手头的数据集进行调整。 它控制模型中变量之间允许的最大交互级别。 用\(J = 2\) （ 决策树桩 ），不允许变量之间进行交互。 用\(J = 3\)该模型可能包括多达两个变量之间的相互作用的影响，依此类推。

Hastie等。 \[10\]评论通常\(4 \leq J \leq 8\)对于提升效果很好，结果对选择\(J\)在这个范围内\(J = 2\)不足以用于许多应用程序，并且\(J > 10\)不太可能是必需的。

## 正则化

过于紧密地拟合训练集可能导致模型的泛化能力下降。 几种所谓的正则化技术通过限制拟合过程来减少这种[过度拟合的效果](../Page/過適.md "wikilink")。

一个自然的正则化参数是梯度提升迭代的次数*M* （即，当基础学习者是决策树时，模型中的树的数量）。 *M的*增加会减少训练集上的误差，但将其设置得过高可能会导致过度拟合。 通常通过监视单独的验证数据集上的预测误差来选择*M*的最佳值。 除了控制*M外* ，还使用其他几种正则化技术。

另一个正则化参数是树的深度。 该值越高，模型越可能适合训练数据。

### 收缩率

梯度增强方法的一个重要部分是通过收缩进行正则化，它包括如下修改更新规则：

  -
    \(F_m(x) = F_{m-1}(x) + \nu \cdot \gamma_m h_m(x), \quad 0 < \nu \leq 1,\)

哪里参数 \(\nu\)被称为“学习率”。

根据经验发现，使用较小的学习率 （例如\(\nu < 0.1\) ）在不缩小（而不缩小）的情况下，极大地提高了模型的泛化能力\(\nu = 1\) ）。 \[11\] 然而，这是以在训练和[查询期间增加](../Page/信息檢索.md "wikilink")[计算时间为代价的](../Page/时间复杂度.md "wikilink")：较低的学习率需要更多的迭代。

### 随机梯度增强

引入梯度增强后不久，Friedman在Breiman的[bootstrap聚合](../Page/Bagging算法.md "wikilink") （“装袋”）方法的启发下 ，对该算法进行了较小的修改。 \[12\] 具体来说，他提出在算法的每次迭代中，基础学习者都应适合随机抽取的训练集的子样本，而无需替换。 \[13\] 弗里德曼（Friedman）观察到，通过这种修改，梯度增强的精度有了显着提高。

子样本大小是某个常数\(f\)训练集的大小。 什么时候\(f = 1\) ，该算法是确定性的，并且与上述算法相同。 较小的值\(f\)将随机性引入算法中，并防止[过度拟合](../Page/過適.md "wikilink") ，作为一种正则化 。 该算法也变得更快，因为回归树必须在每次迭代时都适合较小的数据集。 弗里德曼\[14\]获得了\(0.5 \leq f \leq 0.8\)在中小型训练集上可获得良好的结果。 因此， \(f\)通常将其设置为0.5，这意味着训练集的一半用于构建每个基础学习者。

同样，像在装袋中一样，子采样允许通过评估那些在下一个基础学习者的构建中未使用的观察值的预测来定义预测性能改进的袋外误差 。 预算外的估计有助于避免需要独立的验证数据集，但通常会低估实际性能的提高和最佳迭代次数。 \[15\] \[16\]

### 叶子中的观察数

梯度树增强实现通常还通过限制树的终端节点中的最小观察次数来使用正则化（此参数在[R](../Page/R语言.md "wikilink") `gbm`软件包\[17\]称为`n.minobsinnode` ）。 通过忽略导致导致节点包含少于此训练集实例数量的节点的任何拆分，在树构建过程中使用它。

施加此限制有助于减少叶子预测的差异。

### 惩罚树木的复杂性

用于梯度增强[树的另一种有用的正则化技术是惩罚学习模型的模型复杂性](../Page/决策树.md "wikilink")。 \[18\] 模型复杂度可以定义为学习树中叶子的比例。 损失和模型复杂性的联合优化对应于后修剪算法，该算法可删除未能将损失降低阈值的分支。 其他种类的正规化，例如\(\ell_2\)还可以添加对叶子值的惩罚以避免[过度拟合](../Page/過適.md "wikilink") 。

## 用法

梯度提升可以用于学习排名 。 商业网络搜索引擎[Yahoo](../Page/雅虎.md "wikilink") \[19\]和[Yandex](../Page/Yandex.md "wikilink") \[20\]在其机器学习的排名引擎中使用了梯度增强的变体。

## 名字

该方法有多种名称。 弗里德曼（Friedman）将他的回归技术称为“梯度提升机”（GBM）。 \[21\] 梅森，巴克斯特等。将广义的算法抽象类描述为“功能梯度提升”。 \[22\] \[23\] 弗里德曼（Friedman）等人。将梯度提升模型的进展描述为多重可加回归树（MART）； \[24\] Elith等。将这种方法描述为“增强回归树”（BRT）。 \[25\]

[R的一种流行的开源实现将其称为](../Page/R语言.md "wikilink")“通用提升模型”， \[26\]但是，使用BRT扩展这项工作的软件包。 \[27\] Salford Systems的商业实现使用名称“ Multiple Additive Regression Trees”（MART）和TreeNet，两者均为商标。   <sup>\[ *[<span title="This claim needs references to reliable sources. (August 2018)">需要引用</span>](https://zh.wikipedia.org/wiki/Wikipedia:来源请求 "wikilink")* \]</sup>

## 也可以看看

  - [AdaBoost](../Page/AdaBoost.md "wikilink")
  - [随机森林](../Page/随机森林.md "wikilink")
  - [XGBoost](../Page/XGBoost.md "wikilink")
  - CatBoost
  - [决策树学习](../Page/决策树学习.md "wikilink")

## 参考文献

## 外部链接

  - [如何解释梯度提升](http://explained.ai/gradient-boosting/index.html)
  - [梯度增强回归树](https://blog.datarobot.com/gradient-boosted-regression-trees)

[Category:决策树](https://zh.wikipedia.org/wiki/Category:决策树 "wikilink") [Category:分類演算法](https://zh.wikipedia.org/wiki/Category:分類演算法 "wikilink")

1.
2.
3.
4.
5.
6.
7.
8.
9.  Note: in case of usual CART trees, the trees are fitted using least-squares loss, and so the coefficient \(b_{jm}\) for the region \(R_{jm}\) is equal to just the value of output variable, averaged over all training instances in \(R_{jm}\).
10.
11.
12.
13. Note that this is different from bagging, which samples with replacement because it uses samples of the same size as the training set.
14.
15. Ridgeway, Greg (2007). [Generalized Boosted Models: A guide to the gbm package.](https://cran.r-project.org/web/packages/gbm/gbm.pdf)
16. [Learn Gradient Boosting Algorithm for better predictions (with codes in R)](https://www.analyticsvidhya.com/blog/2015/09/complete-guide-boosting-methods/)
17. Ridgeway, Greg (2007). [Generalized Boosted Models: A guide to the gbm package.](https://cran.r-project.org/web/packages/gbm/gbm.pdf)
18. Tianqi Chen. [Introduction to Boosted Trees](http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)
19. Cossock, David and Zhang, Tong (2008). [Statistical Analysis of Bayes Optimal Subset Ranking](http://www.stat.rutgers.edu/~tzhang/papers/it08-ranking.pdf) , page 14.
20. [Yandex corporate blog entry about new ranking model "Snezhinsk"](http://webmaster.ya.ru/replies.xml?item_no=5707&ncrnd=5118) (in Russian)
21.
22.
23.
24.
25.
26. Ridgeway, Greg (2007). [Generalized Boosted Models: A guide to the gbm package.](https://cran.r-project.org/web/packages/gbm/gbm.pdf)
27.
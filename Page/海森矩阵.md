**黑塞矩阵**（德语：Hesse-Matrix；英语： 或
），又译作**海森矩阵**、**海塞矩阵**或**海瑟矩阵**，是一个以德国数学家[奥托·黑塞命名的多变量实值函数的二阶](https://zh.wikipedia.org/wiki/奥托·黑塞 "wikilink")[偏导数组成的](../Page/偏导数.md "wikilink")[方块矩阵](../Page/方块矩阵.md "wikilink")，假設有一實數函数
\(\textstyle f(x_1, x_2, \dots, x_n),\)如果 \(f\) 所有的二阶偏导数都存在，那么 \(f\)
的黑塞矩阵的第 \(ij\)-項即：

\[H(f)_{ij}(x) = D_i D_j f(x)\] 其中\(x = (x_1, x_2, \dots, x_n)\)，即

\[H(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1\,\partial x_n} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2\,\partial x_n} \\  \\
\vdots & \vdots & \ddots & \vdots \\  \\
\frac{\partial^2 f}{\partial x_n\,\partial x_1} & \frac{\partial^2 f}{\partial x_n\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}\]

（也有人把黑塞定义为以上矩阵的[行列式](../Page/行列式.md "wikilink")\[1\]。）

黑塞矩阵被应用于[牛顿法解决的大规模优化问题](../Page/牛顿法.md "wikilink")。

## 黑塞矩阵及其对称性

由[高等数学知识可知](../Page/高等数学.md "wikilink")，若一元[函数](../Page/函数.md "wikilink")\(f(x)\)在\(x=x_0\)点的某个[邻域内具有任意阶](../Page/邻域.md "wikilink")[导数](../Page/导数.md "wikilink")，则\(f(x)\)在\(x=x_0\)点处的[泰勒展开式为](https://zh.wikipedia.org/wiki/泰勒展开 "wikilink")
\(f(x)=f(x_0)+f'(x)(\Delta x)+\frac {f''(x)}{2!}(\Delta x)^2+\cdots\)其中，\(\Delta x=x-x_0\)。

同理，二元函数\(f(x_1,x_2)\)在\(x_0(x_{10},x_{20})\)点处的泰勒展开式为\(f(x_1,x_2)=f(x_{10},x_{20})+f_{x_1}(x_0)\Delta x_1+f_{x_2}(x_0)\Delta x_2+\frac {1}{2}[f_{x_1 x_1}(x_0)\Delta x_1^2+2f_{x_1 x_2}(x_0)\Delta x_1\Delta x_2+f_{x_2 x_2}(x_0)\Delta x_2^2]+\cdots\)
其中，\(\Delta x_1=x_1-x_{10}\)，\(\Delta x_2=x_2-x_{20}\)，\(f_{x_1x_1}=\frac{\partial^2 f}{\partial x_1^2}\)，\(f_{x_2x_2}=\frac{\partial^2 f}{\partial x_2^2}\)，\(f_{x_1x_2}=\frac{\partial^2 f}{\partial x_1 \partial x_2}=\frac{\partial^2 f}{\partial x_2 \partial x_1}\)。

将上述展开式写成矩阵形式，则有

\(f(x)=f(x_0)+\nabla f(x_0)^T\Delta x+\frac{1}{2}\Delta x^TH(x_0)\Delta x+\cdots\)
其中，\(\Delta x=(\Delta x_1,\Delta x_2 )\)，\(\Delta x^T=\begin{bmatrix}\Delta x_1 \\  \\ \Delta x_2\end{bmatrix}\)是\(\Delta x\)的[转置](https://zh.wikipedia.org/wiki/轉置 "wikilink")（此处“转置”用上角标\(T\)表示），\(\nabla f(x_0)=\begin{bmatrix}\frac{\partial f}{\partial x_1}\\  \\
\frac{\partial f}{\partial x_2}\end{bmatrix}\)是函数\(f(x_1,x_2)\)的[梯度](../Page/梯度.md "wikilink")，矩阵\(H(x_0)=\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} \end{bmatrix}_{x_0}\)

即函数\(f(x_1,x_2)\)在\(x_0(x_{10},x_{20})\)点处的二阶黑塞矩阵。它是由函数\(f(x_1,x_2)\)在\(x_0(x_{10},x_{20})\)点处的二阶偏导数所组成的方阵。由函数的二次连续性，有

\(\frac{\partial^2 f}{\partial x_1 \partial x_2}=\frac{\partial^2 f}{\partial x_2 \partial x_1}\)

所以，黑塞矩阵\(H(x_0)\)为[对称矩阵](https://zh.wikipedia.org/wiki/对称矩阵 "wikilink")。

将二元函数的泰勒展开式推广到多元函数时，\(f(x_1,x_2,\cdots,x_n)\)在\(x_0\)点处的泰勒展开式为\(f(x)=f(x_0)+\nabla f(x_0)^T\Delta x+\frac {1}{2}\Delta x^TH(x_0)\Delta x+\cdots\)
其中，\(\nabla f(x_0)=\begin{bmatrix}\frac {\partial f}{\partial x_1} & \frac {\partial f}{\partial x_2} & \cdots & \frac {\partial f}{\partial x_n}\end{bmatrix}_{x_0}^T\)
为函数\(f(x)\)在\(x_0\)点的梯度。 \(H(x_0)= \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1\,\partial x_n} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2\,\partial x_n} \\  \\
\vdots & \vdots & \ddots & \vdots \\  \\
\frac{\partial^2 f}{\partial x_n\,\partial x_1} & \frac{\partial^2 f}{\partial x_n\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}_{x_0}\)
为函数\(f(x)\)在\(x_0\)点的\(n\)阶黑塞矩阵。若函数有\(n\)次连续性，则函数的\(n\)阶黑塞矩阵也是对称矩阵。\[2\]

## 在映射 \(f: \mathbb{R}^2 \to \mathbb{R}\) 的應用

給定二階導數連續的[映射](https://zh.wikipedia.org/wiki/映射 "wikilink")\(f: \mathbb{R}^2 \to \mathbb{R}\)，黑塞矩陣的行列式，可用於分辨\(f\)的臨界點是屬於[鞍點還是](../Page/鞍點.md "wikilink")[極值点](https://zh.wikipedia.org/wiki/極值点 "wikilink")。

對於\(f\)的臨界點\((x_0, y_0)\)一點，有\(\frac{\partial f(x_0, y_0)}{\partial x} = \frac{\partial f(x_0, y_0)}{\partial y} = 0\)，然而憑一階導數不能判斷它是鞍點、局部極大點還是局部極小點。黑塞矩陣可能解答這個問題。

  -
    <math>

H = \\begin{vmatrix} \\frac{\\partial^2 f}{\\partial x^2} &
\\frac{\\partial^2 f}{\\partial x\\,\\partial y} \\\\ \\\\
\\frac{\\partial^2 f}{\\partial y\\,\\partial x} & \\frac{\\partial^2
f}{\\partial y^2}

`\end{vmatrix} = \frac{\partial^2 f}{\partial x^2} \frac{\partial^2 f}{\partial y^2} - (\frac{\partial^2 f}{\partial y\,\partial x})^2`

</math>

  - H \>
    0：若\(\frac{\partial^2 f}{\partial x^2} > 0\)，則\((x_0, y_0)\)是局部極小點；若\(\frac{\partial^2 f}{\partial x^2} < 0\)，則\((x_0, y_0)\)是局部極大點。
  - H \< 0：\((x_0, y_0)\)是鞍點。
  - H = 0：二階導數無法判斷該臨界點的性質，得從更高階的導數以[泰勒公式考慮](../Page/泰勒公式.md "wikilink")。

### 在高维情况下的推广

当[函数](../Page/函数.md "wikilink")\(f: \mathbb{R}^n \to \mathbb{R}\)二阶连续可导时，Hessian矩阵H在临界点\(x_0\)上是一个\(n\times n\)阶的对称矩阵。

  - 当H是[正定矩阵时](../Page/正定矩阵.md "wikilink")，临界点\(x_0\)是一个局部的极小值。
  - 当H是[负定矩阵时](https://zh.wikipedia.org/wiki/负定矩阵 "wikilink")，临界点\(x_0\)是一个局部的极大值。
  - H=0,需要更高阶的导数来帮助判断。
  - 在其余情况下，临界点\(x_0\)不是局部极值。

## 参看

  - [雅可比矩阵](../Page/雅可比矩阵.md "wikilink")

## 参考文献

[Category:矩陣](https://zh.wikipedia.org/wiki/Category:矩陣 "wikilink")
[Category:多变量微积分](https://zh.wikipedia.org/wiki/Category:多变量微积分 "wikilink")

1.
2.
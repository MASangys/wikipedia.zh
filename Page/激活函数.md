在[计算网络中](../Page/人工神经网络.md "wikilink")， 一个节点的**激活函数**(Activation Function)定义了该节点在给定的输入或输入的集合下的输出。标准的[计算机芯片电路可以看作是根据输入得到](../Page/集成电路.md "wikilink")**开**（1）或**关**（0）输出的[數位電路激活函数](../Page/数字电路.md "wikilink")。这与神经网络中的[线性感知机的行为类似](../Page/感知器.md "wikilink")。然而，只有[非線性激活函数才允許這種網絡僅使用少量節點來計算非](../Page/非線性系統.md "wikilink")[平凡問題](../Page/平凡_\(數學\).md "wikilink")。 在[人工神經網絡中](../Page/人工神经网络.md "wikilink")，這個功能也被稱為[傳遞函數](../Page/传递函数.md "wikilink")。

## 函數

下表列出了幾個激活函数，它們的輸入為單一[變量](https://zh.wikipedia.org/wiki/变量 "wikilink")。

<table>
<thead>
<tr class="header">
<th><p>名稱</p></th>
<th><p><a href="../Page/函数图形.md" title="wikilink">函數圖形</a></p></th>
<th><p><a href="../Page/方程.md" title="wikilink">方程</a>式</p></th>
<th><p><a href="../Page/导数.md" title="wikilink">導數</a></p></th>
<th><p><a href="../Page/區間.md" title="wikilink">區間</a></p></th>
<th><p><a href="https://zh.wikipedia.org/wiki/Smoothness#Order_of_continuity" title="wikilink">Order of continuity</a></p></th>
<th><p><a href="../Page/单调函数.md" title="wikilink">單調</a></p></th>
<th><p>Derivative Monotonic</p></th>
<th><p>Approximates identity near the origin</p></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/恆等函數" title="wikilink">恆等函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_identity.svg" title="fig:File:Activation identity.svg"><a href="File:Activation">File:Activation</a> identity.svg</a></p></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = <em>x</em></span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) = 1</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p><a href="../Page/单位阶跃函数.md" title="wikilink">單位階躍函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_binary_step.svg" title="fig:File:Activation binary step.svg"><a href="File:Activation">File:Activation</a> binary step.svg</a></p></td>
<td><p><span class="math inline">$f(x) = \begin{cases}
    0 &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(x) = \begin{cases}
    0 &amp; \text{for } x \ne 0\\
    ? &amp; \text{for } x = 0\end{cases}$</span></p></td>
<td><p><span class="math inline">{0, 1}</span></p></td>
<td><p><span class="math inline"><em>C</em><sup> − 1</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="../Page/邏輯函數.md" title="wikilink">邏輯函數</a> (也被稱為<a href="../Page/S函数.md" title="wikilink">S函數</a>)</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_logistic.svg" title="fig:File:Activation logistic.svg"><a href="File:Activation">File:Activation</a> logistic.svg</a></p></td>
<td><p><span class="math inline">$f(x)=\sigma(x)=\frac{1}{1+e^{-x}}$</span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) = <em>f</em>(<em>x</em>)(1 − <em>f</em>(<em>x</em>))</span></p></td>
<td><p><span class="math inline">(0, 1)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p><a href="https://zh.wikipedia.org/wiki/双曲正切函数" title="wikilink">雙曲正切函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_tanh.svg" title="fig:File:Activation tanh.svg"><a href="File:Activation">File:Activation</a> tanh.svg</a></p></td>
<td><p><span class="math inline">$f(x)=\tanh(x)=\frac{(e^{x} - e^{-x})}{(e^{x} + e^{-x})}$</span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) = 1 − <em>f</em>(<em>x</em>)<sup>2</sup></span></p></td>
<td><p><span class="math inline">( − 1, 1)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="../Page/反正切.md" title="wikilink">反正切</a>函數</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_arctan.svg" title="fig:File:Activation arctan.svg"><a href="File:Activation">File:Activation</a> arctan.svg</a></p></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = tan<sup> − 1</sup>(<em>x</em>)</span></p></td>
<td><p><span class="math inline">$f'(x)=\frac{1}{x^2+1}$</span></p></td>
<td><p><span class="math inline">$\left(-\frac{\pi}{2},\frac{\pi}{2}\right)$</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>Softsign函數[1][2]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_softsign.png" title="fig:File:Activation softsign.png"><a href="File:Activation">File:Activation</a> softsign.png</a></p></td>
<td><p><span class="math inline">$f(x)=\frac{x}{1+|x|}$</span></p></td>
<td><p><span class="math inline">$f'(x)=\frac{1}{(1+|x|)^2}$</span></p></td>
<td><p><span class="math inline">( − 1, 1)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>1</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>反平方根函數(ISRU)[3]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_ISRU.svg" title="fig:File:Activation_ISRU.svg"><a href="File:Activation_ISRU.svg">File:Activation_ISRU.svg</a></a></p></td>
<td><p><span class="math inline">$f(x) = \frac{x}{\sqrt{1 + \alpha x^2}}$</span></p></td>
<td><p><span class="math inline">$f'(x) = \left(\frac{1}{\sqrt{1 + \alpha x^2}}\right)^3$</span></p></td>
<td><p><span class="math inline">$\left(-\frac{1}{\sqrt{\alpha}},\frac{1}{\sqrt{\alpha}}\right)$</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p><a href="../Page/线性整流函数.md" title="wikilink">線性整流函數</a>(ReLU)</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_rectified_linear.svg" title="fig:File:Activation rectified linear.svg"><a href="File:Activation">File:Activation</a> rectified linear.svg</a></p></td>
<td><p><span class="math inline">$f(x) = \begin{cases}
    0 &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(x) = \begin{cases}
    0 &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">[0, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/线性整流函数#带泄露线性整流" title="wikilink">帶泄露線性整流函數</a>(Leaky ReLU)</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_prelu.svg" title="fig:File:Activation prelu.svg"><a href="File:Activation">File:Activation</a> prelu.svg</a></p></td>
<td><p><span class="math inline">$f(x) = \begin{cases}
    0.01x &amp; \text{for } x &lt; 0\\
    x     &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(x) = \begin{cases}
    0.01 &amp; \text{for } x &lt; 0\\
    1    &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>參數化線性整流函數(PReLU)[4]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_prelu.svg" title="fig:File:Activation prelu.svg"><a href="File:Activation">File:Activation</a> prelu.svg</a></p></td>
<td><p><span class="math inline">$f(\alpha,x) = \begin{cases}
    \alpha x &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(\alpha,x) = \begin{cases}
    \alpha &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/线性整流函数#带泄露随机线性整流" title="wikilink">帶泄露隨機線性整流函數</a>(RReLU)[5]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_prelu.svg" title="fig:File:Activation prelu.svg"><a href="File:Activation">File:Activation</a> prelu.svg</a></p></td>
<td><p><span class="math inline">$f(\alpha, x) = \begin{cases}
    \alpha x &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(\alpha, x) = \begin{cases}
    \alpha &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>指數線性函數(ELU)[6]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_elu.svg" title="fig:File:Activation elu.svg"><a href="File:Activation">File:Activation</a> elu.svg</a></p></td>
<td><p><span class="math inline">$f(\alpha,x) = \begin{cases}
    \alpha(e^x - 1) &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(\alpha,x) = \begin{cases}
    f(\alpha,x) + \alpha &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − <em>α</em>, ∞)</span></p></td>
<td><p><span class="math inline">$\begin{cases}
C_ 1
&amp; \text{when }
\alpha=1
\\
C_0 &amp; \text{otherwise }
\end{cases}$</span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>擴展指數線性函數(SELU)[7]</p></td>
<td></td>
<td><p><span class="math inline">$f(\alpha,x) = \lambda \begin{cases}
    \alpha(e^x - 1) &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span> with <span class="math inline"><em>λ</em> = 1.0507</span> and <span class="math inline"><em>α</em> = 1.67326</span></p></td>
<td><p><span class="math inline">$f'(\alpha,x) = \lambda \begin{cases}
    \alpha(e^x) &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − <em>λ</em><em>α</em>, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>S 型線性整流激活函數(SReLU)[8]</p></td>
<td></td>
<td><p><span class="math inline">$f_{t_l,a_l,t_r,a_r}(x) = \begin{cases}
    t_l + a_l (x - t_l) &amp; \text{for } x \le t_l\\
    x &amp; \text{for } t_l &lt; x &lt; t_r\\
    t_r + a_r (x - t_r) &amp; \text{for } x \ge t_r\end{cases}$</span><br />
<span class="math inline"><em>t</em><sub><em>l</em></sub>, <em>a</em><sub><em>l</em></sub>, <em>t</em><sub><em>r</em></sub>, <em>a</em><sub><em>r</em></sub></span> are parameters.</p></td>
<td><p><span class="math inline">$f'_{t_l,a_l,t_r,a_r}(x) = \begin{cases}
    a_l &amp; \text{for } x \le t_l\\
    1   &amp; \text{for } t_l &lt; x &lt; t_r\\
    a_r &amp; \text{for } x \ge t_r\end{cases}$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>反平方根線性函數(ISRLU)[9]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_ISRLU.svg" title="fig:File:Activation_ISRLU.svg"><a href="File:Activation_ISRLU.svg">File:Activation_ISRLU.svg</a></a></p></td>
<td><p><span class="math inline">$f(x) = \begin{cases}
    \frac{x}{\sqrt{1 + \alpha x^2}} &amp; \text{for } x &lt; 0\\
    x &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(x) = \begin{cases}
    \left(\frac{1}{\sqrt{1 + \alpha x^2}}\right)^3 &amp; \text{for } x &lt; 0\\
    1 &amp; \text{for } x \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$\left(-\frac{1}{\sqrt{\alpha}},\infty\right)$</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>2</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>自適應分段線性函數(APL)[10]</p></td>
<td></td>
<td><p><span class="math inline">$f(x) = \max(0,x) + \sum_{s=1}^{S}a_i^s \max(0, -x + b_i^s)$</span></p></td>
<td><p><span class="math inline">$f'(x) = H(x) - \sum_{s=1}^{S}a_i^s H(-x + b_i^s)$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>0</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>SoftPlus函數[11]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_softplus.svg" title="fig:File:Activation softplus.svg"><a href="File:Activation">File:Activation</a> softplus.svg</a></p></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = ln (1 + <em>e</em><sup><em>x</em></sup>)</span></p></td>
<td><p><span class="math inline">$f'(x)=\frac{1}{1+e^{-x}}$</span></p></td>
<td><p><span class="math inline">(0, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>彎曲恆等函數</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_bent_identity.svg" title="fig:File:Activation bent identity.svg"><a href="File:Activation">File:Activation</a> bent identity.svg</a></p></td>
<td><p><span class="math inline">$f(x)=\frac{\sqrt{x^2 + 1} - 1}{2} + x$</span></p></td>
<td><p><span class="math inline">$f'(x)=\frac{x}{2\sqrt{x^2 + 1}} + 1$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p>Sigmoid-weighted linear unit (SiLU)[12] (也被稱為Swish[13])</p></td>
<td></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = <em>x</em> ⋅ <em>σ</em>(<em>x</em>)</span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) = <em>f</em>(<em>x</em>) + <em>σ</em>(<em>x</em>)(1 − <em>f</em>(<em>x</em>))</span></p></td>
<td><p><span class="math inline">[ ≈  − 0.28, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p>SoftExponential函數[14]</p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_soft_exponential.svg" title="fig:File:Activation soft exponential.svg"><a href="File:Activation">File:Activation</a> soft exponential.svg</a></p></td>
<td><p><span class="math inline">$f(\alpha,x) = \begin{cases}
    -\frac{\ln(1-\alpha (x + \alpha))}{\alpha} &amp; \text{for } \alpha &lt; 0\\
    x &amp; \text{for } \alpha = 0\\
        \frac{e^{\alpha x} - 1}{\alpha} + \alpha &amp; \text{for } \alpha &gt; 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(\alpha,x) = \begin{cases}
    \frac{1}{1-\alpha (\alpha + x)} &amp; \text{for } \alpha &lt; 0\\
    e^{\alpha x} &amp; \text{for } \alpha \ge 0\end{cases}$</span></p></td>
<td><p><span class="math inline">( − ∞, ∞)</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="https://zh.wikipedia.org/wiki/正弦函数" title="wikilink">正弦函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_sinusoid.svg" title="fig:File:Activation sinusoid.svg"><a href="File:Activation">File:Activation</a> sinusoid.svg</a></p></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = sin (<em>x</em>)</span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) = cos (<em>x</em>)</span></p></td>
<td><p><span class="math inline">[ − 1, 1]</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><p><a href="../Page/Sinc函数.md" title="wikilink">Sinc函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_sinc.svg" title="fig:File:Activation sinc.svg"><a href="File:Activation">File:Activation</a> sinc.svg</a></p></td>
<td><p><span class="math inline">$f(x)=\begin{cases}
        1 &amp; \text{for } x = 0\\
    \frac{\sin(x)}{x} &amp; \text{for } x \ne 0\end{cases}$</span></p></td>
<td><p><span class="math inline">$f'(x)=\begin{cases}
    0 &amp; \text{for } x = 0\\
    \frac{\cos(x)}{x} - \frac{\sin(x)}{x^2} &amp; \text{for } x \ne 0\end{cases}$</span></p></td>
<td><p><span class="math inline">[ ≈  − .217234, 1]</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><p><a href="../Page/高斯函数.md" title="wikilink">高斯函數</a></p></td>
<td><p><a href="https://zh.wikipedia.org/wiki/File:Activation_gaussian.svg" title="fig:File:Activation gaussian.svg"><a href="File:Activation">File:Activation</a> gaussian.svg</a></p></td>
<td><p><span class="math inline"><em>f</em>(<em>x</em>) = <em>e</em><sup> − <em>x</em><sup>2</sup></sup></span></p></td>
<td><p><span class="math inline"><em>f</em>′(<em>x</em>) =  − 2<em>x</em><em>e</em><sup> − <em>x</em><sup>2</sup></sup></span></p></td>
<td><p><span class="math inline">(0, 1]</span></p></td>
<td><p><span class="math inline"><em>C</em><sup>∞</sup></span></p></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

  -

    此處是[單位階躍函數](../Page/单位阶跃函数.md "wikilink")。

    是在訓練時間從[均勻分佈中抽取的隨機變量](../Page/連續型均勻分布.md "wikilink")，並且在測試時間固定為分佈的[期望值](../Page/期望值.md "wikilink")。

    此處\(\sigma\)是[邏輯函數](../Page/邏輯函數.md "wikilink")。

下表列出了幾個激活函数，它們的輸入為多個[變量](https://zh.wikipedia.org/wiki/变量 "wikilink")。

| [名稱](https://zh.wikipedia.org/wiki/名稱 "wikilink") | [方程式](https://zh.wikipedia.org/wiki/方程式 "wikilink")                     | [導數](https://zh.wikipedia.org/wiki/導數 "wikilink")                                                                                                                                                              | [區間](../Page/區間.md "wikilink") | [Order of continuity](https://zh.wikipedia.org/wiki/Smoothness#Order_of_continuity "wikilink") |
| ------------------------------------------------- | ----------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------ | ---------------------------------------------------------------------------------------------- |
| [Softmax函數](../Page/Softmax函数.md "wikilink")      | \(f_i(\vec{x}) = \frac{e^{x_i}}{\sum_{j=1}^J e^{x_j}}\)    for  = 1, …, | \(\frac{\partial f_i(\vec{x})}{\partial x_j} = f_i(\vec{x})(\delta_{ij} - f_j(\vec{x}))\)                                                                                                                      | \((0,1)\)                      | \(C^\infty\)                                                                                   |
| Maxout函數\[15\]                                    | \(f(\vec{x}) = \max_i x_i\)                                             | \(\frac{\partial f}{\partial x_j} = \begin{cases}
        1 & \text{for } j = \underset{i}{\operatorname{argmax}} \,  x_i\\
    0 & \text{for } j \ne\underset{i}{\operatorname{argmax}} \,   x_i\end{cases}\) | \((-\infty,\infty)\)           | \(C^0\)                                                                                        |

此處是[克羅內克δ函數](../Page/克罗内克δ函数.md "wikilink")。

## 參見

  - [邏輯函數](../Page/邏輯函數.md "wikilink")
  - [線性整流函數](../Page/线性整流函数.md "wikilink")
  - [Softmax函數](../Page/Softmax函数.md "wikilink")
  - [人工神經網路](../Page/人工神经网络.md "wikilink")
  - [深度學習](../Page/深度学习.md "wikilink")

## 參考資料

<references />

[Category:人工神经网络](https://zh.wikipedia.org/wiki/Category:人工神经网络 "wikilink")

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12. [Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning](https://arxiv.org/abs/1702.03118)
13. [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)
14.
15.
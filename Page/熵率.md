> 本文内容由[熵率](https://zh.wikipedia.org/wiki/熵率)转换而来。


在[概率](../Page/概率.md "wikilink")的数学理论中，非正式地说，一个[随机过程](../Page/随机过程.md "wikilink")的**熵率**或**信源信息率**是在一个随机过程的平均信息的时间密度。对于一个索引[可数的随机过程](https://zh.wikipedia.org/wiki/可数 "wikilink")，熵率 Η(*X*) 是 *n* 个 *X*<sub>*k*</sub> 过程作为成员的联合熵，在 *n* [趋向](../Page/极限_\(数学\).md "wikilink")[无穷](../Page/无穷.md "wikilink")时的极限：

\[\Eta(X) = \lim_{n \to \infty} \frac{1}{n} \Eta(X_1, X_2, \dots X_n)\]

前提是该极限存在。另一种相关量为：

\[\Eta'(X) = \lim_{n \to \infty} \Eta(X_n|X_{n-1}, X_{n-2}, \dots X_1)\]

对于[强平稳随机过程](../Page/平稳过程.md "wikilink")， \(\Eta(X) = \Eta'(X)\)熵率可以被认为是随机信源的一般特性；这是渐近均分割性。

## 马尔可夫链的熵率

因为由不可约、非周期性、持久性的[马尔可夫链](../Page/马尔可夫链.md "wikilink")定义的随机过程呈平稳分布，熵率与初始分布无关。

例如，对于在[可数状态下定义的](https://zh.wikipedia.org/wiki/可数 "wikilink")，[转移矩阵为](https://zh.wikipedia.org/wiki/转移矩阵 "wikilink") *P*<sub>*ij*</sub> 的马尔可夫链 *Y*<sub>*k*</sub>，Η(*Y*) 由下式给出：

\[\displaystyle \Eta(Y) = - \sum_{ij} \mu_i P_{ij} \log P_{ij}\]

其中 *μ*<sub>*i*</sub> 是该链的[平稳分布](https://zh.wikipedia.org/wiki/平稳分布 "wikilink")。

此定义的一个简单结果是，一个独立同分布的[随机过程](../Page/随机过程.md "wikilink")的熵率与该过程中的任何个别成员的[熵](../Page/熵.md "wikilink")相同。

## 参见

  - 信源(数学)
  - 马氏信源
  - 渐近均分割性

## 参考文献

  - Cover, T. and Thomas, J. (1991) Elements of Information Theory, John Wiley and Sons, Inc., ISBN 0-471-06259-6 [1](http://www3.interscience.wiley.com/cgi-bin/bookhome/110438582?CRETRY=1&SRETRY=0)

## 外部链接

  - [Systems Analysis, Modelling and Prediction (SAMP), University of Oxford](https://web.archive.org/web/20120430015528/http://www.eng.ox.ac.uk/samp/) [MATLAB](../Page/MATLAB.md "wikilink")代码，估计随机过程的信息论量。

[Category:信息论](https://zh.wikipedia.org/wiki/Category:信息论 "wikilink") [Category:熵](https://zh.wikipedia.org/wiki/Category:熵 "wikilink") [Category:马尔可夫模型](https://zh.wikipedia.org/wiki/Category:马尔可夫模型 "wikilink")
在[统计学](../Page/统计学.md "wikilink")中，**皮尔逊积矩相关系数**（，又称作 **PPMCC**或**PCCs**\[1\], 文章中常用r或Pearson's r表示）用于度量两个变量X和Y之间的[相关](../Page/相关.md "wikilink")程度（线性相关），其值介于-1与1之间。在自然科学领域中，该系数广泛用于度量两个变量之间的线性相关程度。它是由[卡尔·皮尔逊](../Page/卡尔·皮尔逊.md "wikilink")从[弗朗西斯·高尔顿在](https://zh.wikipedia.org/wiki/弗朗西斯·高尔顿 "wikilink")19世纪80年代提出的一个相似却又稍有不同的想法演变而来。\[2\]\[3\]这个相关系数也称作“皮尔森相关系数r”。

[Correlation_examples2.svg](https://zh.wikipedia.org/wiki/File:Correlation_examples2.svg "fig:Correlation_examples2.svg")

## 定义

两个变量之间的皮尔逊相关系数定义为两个变量之间的[-{zh-hans:协方差; zh-hant:共變異數; zh-cn:协方差; zh-tw:共變異數; zh-hk:共變異數; zh-sg:协方差}-和](../Page/协方差.md "wikilink")[标准差的商](https://zh.wikipedia.org/wiki/标准差 "wikilink")：

\[\rho_{X,Y}={\mathrm{cov}(X,Y) \over \sigma_X \sigma_Y} ={E[(X-\mu_X)(Y-\mu_Y)] \over \sigma_X\sigma_Y}\]

上式定义了**总体**相关系数，常用希腊小寫字母 *ρ* (rho) 作為代表符號。估算[样本的](https://zh.wikipedia.org/wiki/样本 "wikilink")-{zh-hans:协方差; zh-hant:共變異數; zh-cn:协方差; zh-tw:共變異數; zh-hk:共變異數; zh-sg:协方差}-和标准差，可得到**样本相关系数**(样本皮尔逊系数)，常用英文小寫字母 r 代表：

\[r = \frac{\sum\limits ^n _{i=1}(X_i - \overline{X})(Y_i - \overline{Y})}{\sqrt{\sum\limits ^n _{i=1}(X_i - \overline{X})^2} \sqrt{\sum\limits ^n _{i=1}(Y_i - \overline{Y})^2}}\]

r 亦可由\((X_i,Y_i)\)[样本点的](https://zh.wikipedia.org/wiki/样本 "wikilink")[標準分數](../Page/標準分數.md "wikilink")均值估算，得到與上式等價的表達式：

\[r = \frac{1}{n-1} \sum\limits ^n _{i=1} \left( \frac{X_i - \overline{X}}{\sigma_X} \right) \left( \frac{Y_i - \overline{Y}}{\sigma_Y} \right)\]

其中 \(\frac{X_i - \overline{X}}{\sigma_X}\)、\(\overline{X}\) 及 \(\sigma_X\) 分别是 \(X_i\) 样本的標準分數、样本[平均值和样本标准差](https://zh.wikipedia.org/wiki/平均值 "wikilink")。

## 数学特性

总体和样本皮尔逊系数的绝对值小于或等于1。如果样本数据点精确的落在直线上（计算样本皮尔逊系数的情况），或者双变量分布完全在直线上（计算总体皮尔逊系数的情况），则相关系数等于1或-1。皮尔逊系数是对称的：corr(X,Y) = corr(Y,X)。

皮尔逊相关系数有一个重要的数学特性是，因两个变量的位置和尺度的变化并不会引起该系数的改变，即它该变化的[不变量](https://zh.wikipedia.org/wiki/不变量 "wikilink") (由符号确定)。也就是说，我们如果把X移动到a + bX和把Y移动到c + dY，其中a、b、c和d是常数，并不会改变两个变量的相关系数（该结论在总体和样本皮尔逊相关系数中都成立）。我们发现更一般的线性变换则会改变相关系数：参见[之后章节对该特性应用的介绍](https://zh.wikipedia.org/wiki/#去除相关性 "wikilink")。

由于μ<sub>X</sub> = E(X), σ<sub>X</sub><sup>2</sup> = E\[(X − E(X))<sup>2</sup>\] = E(X<sup>2</sup>) − E<sup>2</sup>(X)，Y也类似, 并且

\[E[(X-E(X))(Y-E(Y))]=E(XY)-E(X)E(Y),\,\]

故相关系数也可以表示成

\[\rho_{X,Y}=\frac{E(XY)-E(X)E(Y)}{\sqrt{E(X^2)-(E(X))^2}~\sqrt{E(Y^2)- (E(Y))^2}}.\]

对于**样本**皮尔逊相关系数:

\[r_{xy}=\frac{\sum x_iy_i-n \bar{x} \bar{y}}{(n-1) s_x s_y}=\frac{n\sum x_iy_i-\sum x_i\sum y_i}
{\sqrt{n\sum x_i^2-(\sum x_i)^2}~\sqrt{n\sum y_i^2-(\sum y_i)^2}}.\]

以上方程给出了计算样本皮尔逊相关系数简单的单流程算法，但是其依赖于涉及到的数据，有时它可能是[数值不稳定的](https://zh.wikipedia.org/wiki/數值穩定性 "wikilink")。

## 解释

皮尔逊相关系数的变化范围为-1到1。 系数的值为1意味着*X* 和 *Y*可以很好的由直线方程来描述，所有的数据点都很好的落在一条 [直线上](https://zh.wikipedia.org/wiki/line_\(mathematics\) "wikilink")，且 *Y* 随着 *X* 的增加而增加。系数的值为−1意味着所有的数据点都落在直线上，且 *Y* 随着 *X* 的增加而减少。系数的值为0意味着两个变量之间没有线性关系。

更一般的, 我们发现，当且仅当 *X*<sub>*i*</sub> and *Y*<sub>*i*</sub> 均落在他们各自的均值的同一侧， 则(*X*<sub>*i*</sub> − <font style="text-decoration: overline;">*X*</font>)(*Y*<sub>*i*</sub> − <font style="text-decoration: overline;">*Y*</font>) 的值为正。 也就是说，如果*X*<sub>*i*</sub> 和 *Y*<sub>*i*</sub> 同时趋向于大于, 或同时趋向于小于他们各自的均值，则相关系数为正。 如果 *X*<sub>*i*</sub> 和 *Y*<sub>*i*</sub> 趋向于落在他们均值的相反一侧，则相关系数为负。

### 几何学角度的解释

[Regression_lines.png](https://zh.wikipedia.org/wiki/File:Regression_lines.png "fig:Regression_lines.png")\]

对于没有进行中心化的数据, 相关系数与两条可能的[回归线y](../Page/線性回歸.md "wikilink")=g<sub>x</sub>(x) 和 x=g<sub>y</sub>(y) 夹角的余弦值一致。

对于中心化过的数据 (也就是说, 数据移动一个样本平均值以使其均值为0), 相关系数也可以被视作由两个随机变量[向量](../Page/向量.md "wikilink")[夹角](https://zh.wikipedia.org/wiki/夹角 "wikilink")\(\ \theta\) 的[余弦值](https://zh.wikipedia.org/wiki/cosine "wikilink")（见下方）。

一些人 倾向于使用非中心化的相关系数 (non-Pearson-compliant) 。 比较如下。

例如，有5个国家的国民生产总值分别为 10, 20, 30, 50 和 80 亿美元。 假设这5个国家 (顺序相同) 的贫困百分比分别为 11%, 12%, 13%, 15%, 和 18% 。 令 **x** 和 **y** 分别等于包含上述5个数据的向量: **x** = (1, 2, 3, 5, 8) 和 **y** = (0.11, 0.12, 0.13, 0.15, 0.18)。

利用通常的方法计算两个向量之间的夹角 \(\ \theta\) (参见 [数量积](https://zh.wikipedia.org/wiki/dot_product "wikilink")), *未中心化* 的相关系数是:

\[\cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 2.93 } { \sqrt { 103 } \sqrt { 0.0983 } } = 0.920814711.\]

我们发现以上的数据特意选定为完全相关: *y* = 0.10 + 0.01 *x*。 于是，皮尔逊相关系数应该等于1。将数据中心化 (通过E(**x**) = 3.8移动 **x** 和通过 E(**y**) = 0.138 移动 **y** ) 得到 **x** = (−2.8, −1.8, −0.8, 1.2, 4.2) 和 **y** = (−0.028, −0.018, −0.008, 0.012, 0.042), 从中，

\[\cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 0.308 } { \sqrt { 30.8 } \sqrt { 0.00308 } } = 1 = \rho_{xy},\]

### 对相关系数大小的解释

| 相关性 | 负            | 正           |
| --- | ------------ | ----------- |
| 无   | −0.09 to 0.0 | 0.0 to 0.09 |
| 弱   | −0.3 to −0.1 | 0.1 to 0.3  |
| 中   | −0.5 to −0.3 | 0.3 to 0.5  |
| 强   | −1.0 to −0.5 | 0.5 to 1.0  |

一些著作的作者\[4\]\[5\] 给出了某些解释相关系数的指南。 然而, 所有这些标准从某种意义上说是武断的和不严格的。\[6\] 对相关系数的解释是依赖于具体的应用背景和目的的。 例如，若是在运用高性能的仪器来验证一个物理定律实验这样的应用背景下，0.9的相关系数可能是很低的。但如果是应用在社会科学中，由于社会科学受到各种复杂多变因素影响，0.9的相关系数是相当高的。

### 皮尔逊距离

*皮尔逊距离*度量的是两个变量X和Y，它可以根据皮尔逊系数定义成\[7\]

\[d_{X,Y}=1-\rho_{X,Y}.\] 我们可以发现，皮尔逊系数落在\([-1, 1]\)，而皮尔逊距离落在\([0, 2]\)。

## 统计推断：显著性检验与置信区间

[correlation_significance.svg](https://zh.wikipedia.org/wiki/File:correlation_significance.svg "fig:correlation_significance.svg")基于皮尔逊相关系数的统计推断通常关注以下两个目标。

1.  验证[零假设](../Page/零假设.md "wikilink")是否为真，即相关系数 *ρ* 是否等于 0, 该相关系数使用的是样本相关系数 *r*。
2.  在給定的[置信水平α之下](https://zh.wikipedia.org/wiki/置信水平 "wikilink")，构建一个围绕*r*的[置信区间](../Page/置信区间.md "wikilink")。

### 随机采样方法

提供了一种假设检验和构造置信区间的直接方法。

对皮尔逊相关系数的**显著性检验**包括以下两个步骤：

1.  随机地将原始的数据对 (*x*<sub>*i*</sub>, *y*<sub>*i*</sub>)重新定义成数据集 (*x*<sub>*i*</sub>, *y*<sub>*i′*</sub>), 其中 *i′* 表示数列 {1,...,*n*}。 数列 *i′* 的选取是随机的, 以相同的概率落在 *n*\! 种可能的数列中。这等价于随机地"不可重复地"从数列{1,..., *n*}中选取 *i′*。一种相近的且合乎情理的方法（[自助抽样法](https://zh.wikipedia.org/wiki/自助法 "wikilink")）是“可重复地”从数列{1,..., *n*}中选取 *i* 和 *i′*
2.  由随机数据构造相关系数*r*。

为了完成显著性检验，需要多次重复步骤(i)和(ii) 。显著性检验的[P值是由测试数据除以步骤](https://zh.wikipedia.org/wiki/P值 "wikilink")（ii）得到的*r*，其中*r*大于由原始数据计算出的皮尔逊相关系数。在这里“大”可能是绝对值比较大或者是数值比较大，这取决于测试使用的是或者是。

### 自助抽样法

[自助抽样法可以被用来构造皮尔逊系数的置信区间](https://zh.wikipedia.org/wiki/自助法 "wikilink")。在"非参数"的自助抽样法中，“可重复”地从观测数据集*n*中重新采样*n* 对的 (*x*<sub>*i*</sub>, *y*<sub>*i*</sub>) 数据，用来计算相关系数*r*。这个过程重复了大量次数,。重新采样后数据的 *r*值的分布被用来估计统计学上的。*ρ*的95%的[置信区间](../Page/置信区间.md "wikilink")可以被定义成重新采样样本 *r*值的%2.5到%97.5之间。

### 基于数学近似的方法

对于近似[高斯分布的数据](https://zh.wikipedia.org/wiki/高斯分布 "wikilink")，皮尔逊相关系数的**近似於自由度为*N* − 2的[t分布](https://zh.wikipedia.org/wiki/t分布 "wikilink")**。特别地，如果两个变量服从双变量正态分布，变量

\[t = r\sqrt{\frac{n-2}{1 - r^2}}\]

也會服从不相关的t分布。\[8\] 如果样本容量不是特别小，这个结论也大致成立，即便观测数据不是正态分布的。\[9\]如果需要构建置信区间和进行有力的分析，还需要采用如下的可逆变换

\[r = \frac{t}{\sqrt{n - 2 + t^2}}.\]

或者，也可以采用大量采样数据的方法。

早期对样本相关系数的研究得益于[R. A. Fisher](https://zh.wikipedia.org/wiki/R._A._Fisher "wikilink")\[10\]\[11\]和A. K. Gayen.\[12\]的工作。 另一篇早期的论文\[13\] 给出了在小样本的情况下总体相关系数 *ρ*的图表, 并讨论了相关的计算方法。

### 准确服从高斯分布的数据

准确的双变量样本相关系数的分布是\[14\]\[15\]

\[f\left(r\right) = \frac{\left(n - 2\right)\, \mathbf{\Gamma}\left(n - 1\right) \left(1 - \rho^2\right)^{\frac{n - 1}{2}} \left(1 - r^2\right)^{\frac{n - 4}{2}}}{\sqrt{2\pi}\, \mathbf{\Gamma}\left(n - \frac{1}{2}\right) \left(1 - \rho r\right)^{n - \frac{3}{2}}} \,\mathbf{_2F_1}\left(\frac{1}{2}, \frac{1}{2}; \frac{2n - 1}{2}; \frac{\rho r + 1}{2}\right)\]

其中 \(\mathbf{\Gamma}\)是[伽玛函数](../Page/Γ函数.md "wikilink")，\(\,\mathbf{_2F_1}(a,b;c;z)\) 是[高斯超几何函数](../Page/超几何函数.md "wikilink")。

注意到 \(E\left(r\right) = \rho - \frac{\rho \left(1 - \rho^2\right)}{2 \left(n - 1\right)} + \cdots\), 因此 *r* 是\(\,\rho\)的一个有偏估计。一种获得无偏估计的方法是解\(\,\rho\)的方程 \(r = E\left(r\right) = \rho - \frac{\rho \left(1 - \rho^2\right)}{2 \left(n - 1\right)}\) 。 然而，解 \(\breve{\rho} = r \left[1 + \frac{1 - r^2}{2\left(n - 1\right)}\right]\)是次优的。 一种无偏估计, 可以从 *n*较大情况下的最小方差和有偏序列 \(\frac{1}{n - 1}\), 通过最大化 \(\log{f\left(r\right)}\), 也就是\(\hat{\rho} = r \left[1 - \frac{1 - r^2}{2\left(n - 1\right)}\right]\)获得。

特殊情况下，当 \(\,\rho = 0\)时，分布可以被写成

\[f\left(r\right) = \frac{\left(1 - r^2\right)^{\frac{n - 4}{2}}}{\mathbf{B}\left(\frac{1}{2}, \frac{n - 2}{2}\right)}\] 其中 \(\mathbf{B}\)是[贝塔函数](../Page/Β函数.md "wikilink")。

### 费舍尔变换

实际应用中, 与ρ相关的[置信区间](../Page/置信区间.md "wikilink")和[假设检验通常是通过](https://zh.wikipedia.org/wiki/假设检验 "wikilink")[费舍尔变换获得](../Page/费雪变换.md "wikilink")

  -
    \(F(r) = {1 \over 2}\ln{1 + r \over 1 - r} = \operatorname{arctanh}(r).\)

如果*F*(*r*)是*r*的费舍尔变换，*n* 是样本容量，那么*F*(*r*)近似服从[正态分布](../Page/正态分布.md "wikilink")

\[\text{mean} = F(\rho) = \operatorname{arctanh}(\rho)\]    and standard error    \(\text{SE} = \frac{1}{\sqrt{n - 3}}.\)

也就是[标准分是](https://zh.wikipedia.org/wiki/标准分数 "wikilink")

\[z = \frac{x - \text{mean}}{\text{SE}} = [F(r) - F(\rho_0)]\sqrt{n - 3}\]

对\(\rho = \rho_0\) 进行[零假设](../Page/零假设.md "wikilink")，可以设想样本数据对是[独立同分布](../Page/独立同分布.md "wikilink")并且服从[双变量正态分布](https://zh.wikipedia.org/wiki/双变量正态分布 "wikilink")。因此[P值估计可以从正态分布概率表中获得](https://zh.wikipedia.org/wiki/P值 "wikilink")。比如，如果观测数据 *z* = 2.2，并且要用双边p值对 \(\rho = 0\)进行零假设检验，p值是 2·Φ(−2.2) = 0.028， 其中*Φ*是正态分布的[累积分布函数](../Page/累积分布函数.md "wikilink")。

### 置信区间

为了获得*ρ*的信賴区间，首先，我们应该计算 *F*(*\(\rho\)*)的信賴区间：

\[100(1 - \alpha)\%\text{CI}: \operatorname{arctanh}(\rho) \in [\operatorname{arctanh}(r) \pm z_{\alpha/2}SE]\]

通过可逆Fisher变换可以获得相关尺度上的区间。

\[100(1 - \alpha)\%\text{CI}: \rho \in [\operatorname{tanh}(\operatorname{arctanh}(r) - z_{\alpha/2}SE), \operatorname{tanh}(\operatorname{arctanh}(r) + z_{\alpha/2}SE)]\]

举例来说，假设我们观测到 *r* = 0.3，样本容量 *n*=50，并且我们期望获得*ρ*的95%的信賴区间。变换后的值是artanh(*r*) = 0.30952，所以在变换尺度上的信賴区间是 0.30952 ± 1.96/√47，或者 (0.023624, 0.595415)。变换回相关尺度上是 (0.024, 0.534)。

## 皮尔逊相关系数和最小方差回归分析

样本相关系数的平方, 亦称作 [coefficient of determination](https://zh.wikipedia.org/wiki/coefficient_of_determination "wikilink"), 利用[简单线性回归估计由](https://zh.wikipedia.org/wiki/simple_linear_regression "wikilink")*X*引起的 *Y*的变化。 一开始, *Y*<sub>*i*</sub> 围绕它们平均值上的变化可以分解成

\[\sum_i (Y_i - \bar{Y})^2 = \sum_i (Y_i-\hat{Y}_i)^2 + \sum_i (\hat{Y}_i-\bar{Y})^2,\]

其中 \(\hat{Y}_i\) 是作回归分析时的适应值。 整理后得

\[1 = \frac{\sum_i (Y_i-\hat{Y}_i)^2}{\sum_i (Y_i - \bar{Y})^2} + \frac{\sum_i (\hat{Y}_i-\bar{Y})^2}{\sum_i (Y_i - \bar{Y})^2}.\]

两个被加数是由*X* (右边)引起的*Y*的变化和不是由*X* (左边) 引起的变化。

接下来, 我们利用最小方差回归模型, 使 \(\hat{Y}_i\) 和 \(Y_i-\hat{Y}_i\) 的样本协方差为0。 于是, 观测数据和适应值的样本相关系数可以被写成

\(\begin{align}
r(Y,\hat{Y}) &= \frac{\sum_i(Y_i-\bar{Y})(\hat{Y}_i-\bar{Y})}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{\sum_i(Y_i-\hat{Y}_i+\hat{Y}_i-\bar{Y})(\hat{Y}_i-\bar{Y})}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{ \sum_i [(Y_i-\hat{Y}_i)(\hat{Y}_i-\bar{Y}) +(\hat{Y}_i-\bar{Y})^2 ]}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{ \sum_i (\hat{Y}_i-\bar{Y})^2 }{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\

&= \sqrt{\frac{\sum_i(\hat{Y}_i-\bar{Y})^2}{\sum_i(Y_i-\bar{Y})^2}}.
\end{align}\)

于是

\[r(Y,\hat{Y})^2 = \frac{\sum_i(\hat{Y}_i-\bar{Y})^2}{\sum_i(Y_i-\bar{Y})^2}\]

是由*X*的线性方程引起的 *Y* 的平均变化。

## 数据分布的敏感度

### 存在性

总体皮尔逊相关系数被定义成 [矩](https://zh.wikipedia.org/wiki/moment_\(mathematics\) "wikilink"), 因此任意的双变量[概率分布是非零的](https://zh.wikipedia.org/wiki/probability_distribution "wikilink")， 也就是说 [总体](https://zh.wikipedia.org/wiki/statistical_population "wikilink") [协方差](https://zh.wikipedia.org/wiki/covariance "wikilink") 和 [边缘](https://zh.wikipedia.org/wiki/marginal_distribution "wikilink") [总体方差](https://zh.wikipedia.org/wiki/population_variance "wikilink") 是由定义的。 一些概率分布， 诸如 [柯西分布](https://zh.wikipedia.org/wiki/Cauchy_distribution "wikilink") 有未定义的方差，因此*X* or *Y* 如果服从这种分布，ρ便是未定义的。 在实际应用中, 如果有数据被怀疑服从[重尾分布](https://zh.wikipedia.org/wiki/heavy-tailed_distribution "wikilink"), 这个条件就需要引起重视。 然而, 相关系数的存在性通常并需要太介意; 例如, 如果分布是有界的, ρ 便总是有意义的。

### 大样本的特性

在双变量 [正态分布的案例中](https://zh.wikipedia.org/wiki/normal_distribution "wikilink")， 只要边缘均值和方差是已知的，总体相关系数描述的是便是联合分布。 在其他的双变量分布中，这个结论并不正确。 总之, 不论两个随机变量的联合分布是不是正态的，相关系数在研究的它们之间的线性依赖性都是有帮助的。\[16\] 样本相关系数是对两个正态分布变量总体相关系数的[最大似然估计](https://zh.wikipedia.org/wiki/maximum_likelihood_estimate "wikilink") 并且是 [渐进](https://zh.wikipedia.org/wiki/asymptotic_distribution "wikilink") [无偏的](https://zh.wikipedia.org/wiki/bias_of_an_estimator "wikilink") 和 [有效的](https://zh.wikipedia.org/wiki/efficiency_\(statistics\) "wikilink"), 这也就是说如果数据是正态的并且样本容量是中等的或大量的，就不可能构造出一个比样本相关系数更准确的估计。对于非正态的数据, 样本相关系数大致上是无偏的，但有可能是无效的。 只要样本均值、方差和协方差是一致的（当[大数定理可以应用的情况下](https://zh.wikipedia.org/wiki/law_of_large_numbers "wikilink")），样本相关系数是总体相关系数的 [一致估计](https://zh.wikipedia.org/wiki/consistent_estimator "wikilink") 。

### 稳健性

与其他常用的统计指标相似的, 样本指标*r* 不是 [稳健的](https://zh.wikipedia.org/wiki/robust_statistics "wikilink")\[17\] 。因此如果由 [异常值](https://zh.wikipedia.org/wiki/outlier "wikilink")，这个指标是有误导性的。\[18\]\[19\] 特别的, PMCC 既不是稳健分布的, 也不是异常值稳健的\[20\] (see [Robust statistics\#Definition](https://zh.wikipedia.org/wiki/Robust_statistics#Definition "wikilink"))。 对*X* 和 *Y*的[散点图的观察可以很明显的揭示出缺乏稳健性的情况](https://zh.wikipedia.org/wiki/scatterplot "wikilink"),在这种情况下，采用的联合的方法是比较明智的。 注意到，虽然大多数稳健的估计器从某种程度上说都是有[统计依赖的](https://zh.wikipedia.org/wiki/statistical_dependence "wikilink"), 它们总的来说，在总体相关系数的尺度上都是可辨的。

基于皮尔逊相关系数的统计推断对数据分布式敏感的。 如果数据大致是正态分布的，可以使用精确检验和基于[Fisher变换的渐进检验](https://zh.wikipedia.org/wiki/Fisher_transformation "wikilink")，但是它们可能由误导性。 在一些情况下, [自助采样](https://zh.wikipedia.org/wiki/bootstrapping_\(statistics\) "wikilink") 可以用来构造置信区间。 同时， [重复抽样](https://zh.wikipedia.org/wiki/resampling_\(statistics\) "wikilink") 可以应用在假设检验中。 这些[非参数化](https://zh.wikipedia.org/wiki/non-parametric_statistics "wikilink") 的方法在某些情况下，如双变量正态分布不能保证时，可能得出更有意义的结论。 然而，这些方法的标准形式依赖于数据的 [可交换性](https://zh.wikipedia.org/wiki/exchangeable_random_variables "wikilink")。这也就意味着被分析的数据时没有顺序的和组别的。因为这有可能会影响估计相关系数的特性。

分层分析是一种容许缺少双变量正态性的方法，或者说是用来隔离相互关联因素的关联结果。 如果 *W* 代表聚类成员或者其它需要被控制的因素，我们可以分离基于*W*的数据, 然后我们可以再每个层里计算相关系数。 当我们控制变量*W*，我们便能在层的等级上估计与所有相关系数相关的各自的相关系数。\[21\]

## 计算加权相关系数

假设我们要计算关联性的观测数据有着不同的重要程度，表示成权值向量 *w*。 利用权值向量*w* (总长度 *n*)计算向量 *x* 和 *y* 的相关系数,\[22\]\<ref\>[A MATLAB Toolbox for computing Weighted Correlation Coefficients](http://www.mathworks.com/matlabcentral/fileexchange/20846)</ref>

  - 加权均值:

<!-- end list -->

  -

      -
        \(\operatorname{m}(x; w) = {\sum_i w_i x_i \over \sum_i w_i}.\)

<!-- end list -->

  - 加权协方差

<!-- end list -->

  -

      -
        \(\operatorname{cov}(x,y;w) = {\sum_i w_i (x_i - \operatorname{m}(x; w)) (y_i - \operatorname{m}(y; w)) \over \sum_i w_i }.\)

<!-- end list -->

  - 加权相关系数

<!-- end list -->

  -

      -
        \(\operatorname{corr}(x,y;w) = {\operatorname{cov}(x,y;w) \over \sqrt{\operatorname{cov}(x,x;w) \operatorname{cov}(y,y;w)}}.\)

## 去除相关性

我们总是可以通过一定的线性变换去除随机变量之间的相关性, 即便变量间的关系是非线性的。 Cox & Hinkley\[23\]给出了在总体相关系数中的表达形式。

与此相应的，样本相关系数也存在这样的结论，使得样本相关系数变为0。假设长度为 *n* 的随机变量被随机采样 *m* 次。 令 *X* 是一个矩阵，其中 \(X_{i,j}\) 是第*i*次采样的第 *j*个变量。 令 \(Z_{m,m}\) 是一个所有元素都为1的 *m* \* *m* 的方阵。 那么 *D* 是变换后的数据，使得随机变量的均值为0, 并且 *T* 是变换后的数据，使得所有的变量均值为0和与除自身外的其他变量的相关系数为0 - *T*的矩作为身份矩阵。 为了得到单位方差，还需要除以标准差。 虽然变换后的数据有可能不是[独立的](https://zh.wikipedia.org/wiki/Statistical_independence "wikilink")，但他们一定是不相关的。

\[D = X -\frac{1}{m} Z_{m,m} X\]

\[T = D (D^T D)^{-\frac{1}{2}}\]

其中，指数-1/2表示矩阵置换后的 [矩阵方根](https://zh.wikipedia.org/wiki/矩阵方根 "wikilink")。T的协方差被当做身份矩阵。如果新的样本数据x是n个元素的向量, 那么相同的变换可以应用到x中以获得变换向量d和t：

\[d = x - \frac{1}{m} Z_{1,m} X\]

\[t = d (D^T D)^{-\frac{1}{2}}\] 这个去相关性的方法被应用到多变量的[主成分分析](../Page/主成分分析.md "wikilink")中。

## 反射相关性

反射相关系数是皮尔逊相关系数的变体，数据并不是以他们的均值为中心。总体反射相关系数是

\[\text{Corr}_r(X,Y) = \frac{E[XY]}{\sqrt{EX^2\cdot EY^2}}.\]

反射相关系数是对称的, 但在如下的变换中并不是不变的

\[\text{Corr}_r(X, Y) = \text{Corr}_r(Y, X) = \text{Corr}_r(X, bY) \neq \text{Corr}_r(X, a + b Y), \quad a \neq 0, b > 0.\]

样本反射相关系数是

\[rr_{xy} = \frac{\sum x_i y_i}{\sqrt{(\sum x_i^2)(\sum y_i^2)}}.\]

样本加权相关系数是

\[rr_{xy, w} = \frac{\sum w_i x_i y_i}{\sqrt{(\sum w_i x_i^2)(\sum w_i y_i^2)}}.\]

## 比例关系

规模的相关性是一个变种的皮尔森相关数据的范围限制故意以受控的方式揭示时间序列之间的快速成分的相关性。比例相关的定义是在短数据段的平均相关性。 对于给定规模S，令K为可以适应信号的总长度的段数：

\[\mathbf{K}=\mathbf{Sound}\left( \frac{T}{s} \right)\] 比例相关的整个信号的r<sub>s</sub>的计算公式为

\[\overrightarrow{r_s}=\frac{1}{K}\sum_{k=1}^K r_k\] r<sub>s</sub>为k的部分皮尔森相关系数。 通过对参数s的选择，减少值的范围和较长的时间尺度上的相关性被过滤掉，只有在很短的时间尺度上的相关性被发现。因此，慢分量的贡献被删除，快分量被保留。

## 强噪声条件下

强噪声条件下，提取相关系数两个随机变量之间的是平凡的，特别是在典型相关分析报告在退化的相关值的情况下，由于存在大量噪声。一种概括的方法在其他地方给出。

## 維基相關條目

  - [相關](https://zh.wikipedia.org/wiki/相關 "wikilink")
  - [史匹曼等級相關係數](https://zh.wikipedia.org/wiki/史匹曼等級相關係數 "wikilink")
  - [Disattenuation](https://zh.wikipedia.org/wiki/Disattenuation "wikilink")
  - [Maximal information coefficient](https://zh.wikipedia.org/wiki/Maximal_information_coefficient "wikilink")
  - [圖模式](../Page/圖模式.md "wikilink")
  - [马尔可夫链](../Page/马尔可夫链.md "wikilink")
  - [马尔可夫逻辑网络](../Page/马尔可夫逻辑网络.md "wikilink")

## 外部連結

  - [相關係數：使用皮爾森檢定與斯皮爾曼等級檢定的研究問題](http://mail.cmu.edu.tw/~tcli/%B2%C4%A4Q%A4%BB%B3%B9.pdf)（中國醫藥大學，生物統計課程）
  - [相關係數：資料型態與適用統計方法](http://www2.cmu.edu.tw/~biostat/online/teaching_corner_038-2.pd)（中國醫藥大學，生物統計課程）

## 註腳

[ru:Корреляция\#Линейный коэффициент корреляции](https://zh.wikipedia.org/wiki/ru:Корреляция#Линейный_коэффициент_корреляции "wikilink")

[Category:协方差与相关性](https://zh.wikipedia.org/wiki/Category:协方差与相关性 "wikilink") [Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink") [Category:比率](https://zh.wikipedia.org/wiki/Category:比率 "wikilink")

1.  "The human disease network", Albert Barabasi et al., Plos.org
2.  J. L. Rodgers and W. A. Nicewander. [Thirteen ways to look at the correlation coefficient](http://www.jstor.org/stable/2685263). The American Statistician, 42(1):59–66, February 1988.
3.
4.  A. Buda and A.Jarynowski (2010) *Life-time of correlations and its applications vol.1*, Wydawnictwo Niezalezne: 5–21, December 2010, ISBN 978-83-915272-9-0
5.
6.  Cohen, J. (1988). *Statistical power analysis for the behavioral sciences* (2nd ed.)
7.  Fulekar (Ed.), M.H. (2009) *Bioinformatics: Applications in Life and Environmental Sciences*, Springer (pp. 110) ISBN 1402088795
8.  N.A Rahman, A Course in Theoretical Statistics; Charles Griffin and Company, 1968
9.  Kendall, M.G., Stuart, A. (1973)*The Advanced Theory of Statistics, Volume 2: Inference and Relationship*, Griffin. ISBN 0852642156 (Section 31.19)
10.
11.
12.
13. Soper, H.E., Young, A.W., Cave, B.M., Lee, A., Pearson, K. (1917). "On the distribution of the correlation coefficient in small samples. Appendix II to the papers of "Student" and R. A. Fisher. A co-operative study", *[Biometrika](https://zh.wikipedia.org/wiki/Biometrika "wikilink")*, 11, 328-413. <doi:10.1093/biomet/11.4.328>
14. Kenney, J. F. and Keeping, E. S., *Mathematics of Statistics*, Pt. 2, 2nd ed. Princeton, NJ: Van Nostrand, 1951.
15. [Correlation Coefficient - Bivariate Normal Distribution](http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html)
16.
17.
18.
19.
20.
21. Katz., Mitchell H. (2006) *Multivariable Analysis - A Practical Guide for Clinicians*. 2nd Edition. Cambridge University Press. ISBN 9780521549851. ISBN 052154985X
22. <http://sci.tech-archive.net/Archive/sci.stat.math/2006-02/msg00171.html>
23. Cox, D.R., Hinkley, D.V. (1974) *Theoretical Statistics*, Chapman & Hall (Appendix 3) ISBN 0412124203
> 本文内容由[相关](https://zh.wikipedia.org/wiki/相关)转换而来。


在[概率论和](https://zh.wikipedia.org/wiki/概率论 "wikilink")[统计学](../Page/统计学.md "wikilink")中，**相关**（Correlation），显示两个[随机变量](../Page/随机变量.md "wikilink")之间线性关系的强度和方向。在统计学中，相关的意义是用来衡量两个变量相对于其相互独立的距离。在这个广义的定义下，有许多根据数据特点而定义的用来衡量数据相关的系数。

[Correlation_examples2.svg](https://zh.wikipedia.org/wiki/File:Correlation_examples2.svg "fig:Correlation_examples2.svg")

## 历史

英国生物学家和统计学家[弗朗西斯·高尔顿首先提出](https://zh.wikipedia.org/wiki/弗朗西斯·高尔顿 "wikilink")“相关”这一概念，英国数学家[卡尔·皮尔逊](../Page/卡尔·皮尔逊.md "wikilink")在此基础上做出了进一步发展。

## 各種相關係數

对于不同[測量尺度](../Page/測量尺度.md "wikilink")的變數，有不同的相關系数可用：

  - [皮尔逊相关系数](../Page/皮尔逊积矩相关系数.md "wikilink")（Pearson's *r*）：衡量兩個[等距尺度或](https://zh.wikipedia.org/wiki/測量尺度#等距尺度 "wikilink")[等比尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#等比尺度 "wikilink")。是最常見的，也是學習統計學時第一個接觸的相關係數。
  - [淨相關](https://zh.wikipedia.org/wiki/淨相關 "wikilink")（）：在模型中有多個自變數（或解釋變數）時，去除掉其他自變數的影響，只衡量特定一個自變數與因變數之間的相關性。自變數和因變數皆為連續變數。
  - 相關比（）：衡量兩個連續變數之相關性。

<!-- end list -->

  - [Gamma相關係數](https://zh.wikipedia.org/wiki/Gamma相關係數 "wikilink")：衡量兩個[次序尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#次序尺度 "wikilink")。

  - [斯皮尔曼等级相关系数](../Page/斯皮尔曼等级相关系数.md "wikilink")：衡量兩個[次序尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#次序尺度 "wikilink")。

  - ：衡量兩個人為[次序尺度變數](https://zh.wikipedia.org/wiki/測量尺度#次序尺度 "wikilink")（原始資料為[等距尺度](https://zh.wikipedia.org/wiki/測量尺度#等距尺度 "wikilink")）之相關性。

  - 肯德尔和諧係數：衡量兩個[次序尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#次序尺度 "wikilink")。

<!-- end list -->

  - [Phi相關係數](../Page/Phi相關係數.md "wikilink")（）：衡量兩個真正[名目尺度的二分變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")。
  - 列聯相關係數（）：衡量兩個真正[名目尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")。
  - 四分相關（）：衡量兩個人為[名目尺度](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")（原始資料為[等距尺度](https://zh.wikipedia.org/wiki/測量尺度#等距尺度 "wikilink")）的二分變數之相關性。
  - Kappa一致性係數（）：衡量兩個[名目尺度變數之相關性](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")。

<!-- end list -->

  - 點二系列相關係數（）：X變數是真正[名目尺度二分變數](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")。Y變數是連續變數。
  - 二系列相關係數（）：X變數是人為[名目尺度二分變數](https://zh.wikipedia.org/wiki/測量尺度#名目尺度 "wikilink")。Y變數是連續變數。

## 皮尔逊积差系数

### 数学特征

\[\rho_{X,Y}={\mathrm{cov}(X,Y)\over \sigma_X \sigma_Y} ={E((X-\mu_X)(Y-\mu_Y)) \over \sigma_X\sigma_Y}\]， 其中，*E*是[数学期望](https://zh.wikipedia.org/wiki/数学期望 "wikilink")，cov表示[协方差](../Page/协方差.md "wikilink")，\(\sigma_X\)和\(\sigma_Y\)是[標準差](../Page/標準差.md "wikilink")。

因为\(\mu_X = E (X)\)，\(\sigma_X^2 = E(X^2) - E^2 (X)\)，同样地，对于\(Y\)，可以写成

\[\rho_{X,Y}=\frac{E (XY)-E (X)E (Y)}{\sqrt{E(X^2)-E^2 (X)}~\sqrt{E(Y^2)-E^2 (Y)}}\]。

当两个变量的[標準差](../Page/標準差.md "wikilink")都不为零，相关系数才有定义。从[柯西-施瓦茨不等式](../Page/柯西-施瓦茨不等式.md "wikilink")可知，相关系数的[絕對值不超过](https://zh.wikipedia.org/wiki/絕對值 "wikilink")1。当两个变量的线性关系增强时，相关系数趋于1或-1。当一个变量增加而另一变量也增加时，相关系数大于0。当一个变量的增加而另一变量减少时，相关系数小于0。当两个变量独立时，相关系数为0，但反之并不成立。这是因为相关系数仅仅反映了两个变量之间是否线性相关。比如说，*X*是区间［－1，1］上的一个均匀分布的随机变量。*Y* = *X*<sup>2</sup>.那么*Y*是完全由*X*确定。因此*Y*和*X*不独立，但相关系数为0。或者说他们是不相关的。当*Y*和*X*服从联合正态分布时，其相互独立和不相关是等价的。

当一个或两个变量带有测量误差时，他们的相关性就受到削弱，这时，“反衰减”性（disattenuation）是一个更准确的系数。

### 几何特征

对于居中的数据来说（何谓居中？也就是每个数据减去样本均值，居中后它们的平均值就为0），相关系数可以看作是两个随机变量中得到的样本集向量之间夹角的cosine函数。一些实际工作者更喜欢用非居中的相关系数（与皮尔逊系数不相兼容）。看下面的例子中有一个比较。例如，假设五个国家的国民生产总值分别是1、2、3、5、8（单位10亿美元），又假设这五个国家的贫困比例分别是11%、12%、13%、15%、18%。则我们现在有两个有序的包含5个元素的向量x、y：x =（1, 2, 3, 5, 8）、 y =（0.11, 0.12, 0.13, 0.15, 0.18） 使用一般的方法来计算向量间夹角（参考[数量积](https://zh.wikipedia.org/wiki/数量积 "wikilink")），未居中的相关性系数如下：

\[\cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 2.93 } { \sqrt { 103 } \sqrt { 0.0983 } } = 0.920814711\]。 上面的数据实际上是故意选择了一个完美的线性关系：y = 0.10 + 0.01 x。因此皮尔逊相关系数应该就是1。把数据居中（x中数据减去E (x) = 3.8，y中数据减去E (y) = 0.138）后得到：x =（−2.8, −1.8, −0.8, 1.2, 4.2）、y =（−0.028, −0.018, −0.008, 0.012, 0.042），由此得到了预期结果：

\[\cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 0.308 } { \sqrt { 30.8 } \sqrt { 0.00308 } } = 1 = \rho_{xy}\]，

## 统计学上的相关

相关系数的计算过程可表示为：将每个变量都转化为标准单位，乘积的平均数即为相关系数\[1\]。

两个变量的关系可以直观地用散点图表示，当其紧密地群聚于一条直线的周围时，变量间存在强相关\[2\]。

一个散点图可以用五个统计量来概括。所有x值得平均数，所有x值的SD，所有y值得平均数，所有y值的SD，相关系数r.

将第一个变量记为x ,第二个变量记为y ,相关系数为r，则可以通过以下公式：

r = \[（以标准单位表示的x）X（以标准单位表示的y）\]的平均数

## 參考文獻

## 参见

  - [相关不蕴涵因果](https://zh.wikipedia.org/wiki/相关不蕴涵因果 "wikilink")
  - [關聯係數](../Page/關聯係數.md "wikilink")

{{-}}

[Category:协方差与相关性](https://zh.wikipedia.org/wiki/Category:协方差与相关性 "wikilink") [Category:统计学术语](https://zh.wikipedia.org/wiki/Category:统计学术语 "wikilink")

1.
2.
> 本文内容由[神威·太湖之光](https://zh.wikipedia.org/wiki/神威·太湖之光)转换而来。


'''神威·太湖之光 ''' （）是由中國[国家并行计算机工程技术研究中心研制的](https://zh.wikipedia.org/wiki/国家并行计算机工程技术研究中心 "wikilink")[超級電腦](https://zh.wikipedia.org/wiki/超級電腦 "wikilink")，2016年6月20日在[LINPACK](../Page/LINPACK.md "wikilink")效能測試中以 93 PFLOPS 的測試結果超越同為中國組建的[天河二號](https://zh.wikipedia.org/wiki/天河二號 "wikilink")（LINPACK成績約為34 PFLOPS），成爲当时[世界上最快的超级计算机](../Page/TOP500.md "wikilink")\[1\]\[2\]\[3\]\[4\]，直到2018年6月8日被美國的超級電腦[高峰](../Page/高峰_\(超級電腦\).md "wikilink")（）超越\[5\]。「太湖之光」的命名，是來源於無錫旁邊的[太湖](../Page/太湖.md "wikilink")。目前神威·太湖之光部署在[江蘇省](https://zh.wikipedia.org/wiki/江蘇省 "wikilink")[無錫市的](https://zh.wikipedia.org/wiki/無錫市 "wikilink")[國家超級計算無錫中心](https://zh.wikipedia.org/wiki/國家超級計算無錫中心 "wikilink")\[6\]\[7\]，由[清華大學負責运营](https://zh.wikipedia.org/wiki/清華大學 "wikilink")\[8\]。

神威·太湖之光也是[中國大陸首度自行設計不使用](https://zh.wikipedia.org/wiki/中國大陸 "wikilink")[英特爾等美國公司的核心產品而登上TOP](https://zh.wikipedia.org/wiki/英特爾 "wikilink")500第一名寶座的超級電腦。\[9\]该機組也被認為是中國政府面對美國政府限制英特爾、[輝達等廠商對華出售運算裝置的正面回應](https://zh.wikipedia.org/wiki/輝達 "wikilink")\[10\]，在中國大陸的媒體報導中，也多強調該機組的組件均由中國自主設計並於中國生產。\[11\]

## 硬體

神威·太湖之光使用国家高性能集成电路（上海）设计中心研发的[SW26010](https://zh.wikipedia.org/wiki/SW26010 "wikilink")。\[12\]此款處理器，基於[DEC Alpha 64微架構](../Page/DEC_Alpha.md "wikilink")、64位元、[精簡指令集](https://zh.wikipedia.org/wiki/精簡指令集 "wikilink")、[亂序執行](https://zh.wikipedia.org/wiki/亂序執行 "wikilink")、支援[SIMD的](https://zh.wikipedia.org/wiki/SIMD "wikilink")[申威-64架構](../Page/申威处理器.md "wikilink")，製程未知。每個處理器晶片中有260個，採用大規模多核心並行運算的結構，其中4個為資源管理用途，稱為MPE（Management Processing Element，管理處理元件），採用[對稱多處理器的結構](https://zh.wikipedia.org/wiki/對稱多處理 "wikilink")；另外256個作通用運算用途，每64個核心組成一個處理器核心陣列，共計4個陣列，合稱為CPE（Computing Processing Element，運算處理元件）。MPE和CPE的連接佈局類似於[Cell的協處理器式](../Page/Cell_\(微處理器\).md "wikilink")、[非對稱多處理](../Page/非對稱多處理.md "wikilink")的佈局（PPE+SPE），而CPE的陣列則與[Xeon Phi](https://zh.wikipedia.org/wiki/Xeon_Phi "wikilink")、[GPGPU等的流處理器形式相近](https://zh.wikipedia.org/wiki/GPGPU "wikilink")。CPE核心和MPE核心都是相同的指令集，同樣具備256位元SIMD單元，但不同的是MPE均支援用戶模式和系統模式、32KiB一級指令快取、32KiB一級資料快取、256KiB二級快取，而CPE僅支援用戶模式、16KiB一級指令快取、64KiB本地而無資料快取，而且存取系統記憶體需要與MPE溝通。該CPU[時脈設定在](https://zh.wikipedia.org/wiki/時脈 "wikilink") 1.45GHz。不過，記憶體存取方面的規格相對較為貧弱，使用的是[四通道](https://zh.wikipedia.org/wiki/四通道 "wikilink")[DDR3 SDRAM](../Page/DDR3_SDRAM.md "wikilink")，而不是最新的[DDR4 SDRAM](../Page/DDR4_SDRAM.md "wikilink")，各通道擁有獨立的、128位元位寬的[記憶體控制器](https://zh.wikipedia.org/wiki/記憶體控制器 "wikilink")，每通道容量 8GiB，一顆CPU可最大支援32GiB的DDR3-2133，儘管如此，每個晶片的記憶體[頻寬仍達](https://zh.wikipedia.org/wiki/頻寬 "wikilink") 136.5GB/s。除此以外，每顆晶片上還內建了，而非傳統的[快取一致性處理](https://zh.wikipedia.org/wiki/快取一致性 "wikilink")。因此，該CPU與Cell寬頻引擎一樣，偏重於浮點數運算。\[13\]\[14\]

整套系統高達 40,960 個 SW26010處理器，共有 10,649,600 個CPU核心。每個處理器為一個節點單元，一塊主機板上有兩顆處理器，32塊這樣的主機板組成一架主機，每台主機作為一個「超級節點」，一共有256個這樣的超級節點。根據資料圖顯示，這樣的構造使得主機需採用非標準設計，而非標準的[刀鋒伺服器](../Page/刀鋒伺服器.md "wikilink")機架和機櫃，這樣的一種機櫃可以容納4台主機機架。運算節點單元之間全數採用PCIe匯流排互聯，互聯結構分為三層，頂層網路是「中央切換網路」，中間層是「超級節點網路」，底層是「資源共用網路」。\[15\]

## 軟體

神威·太湖之光採用的是基於[Linux核心的神威睿思](https://zh.wikipedia.org/wiki/Linux核心 "wikilink")（即RaiseOS 2.0.5），也是[分佈式作業系統](https://zh.wikipedia.org/wiki/分佈式作業系統 "wikilink")\[16\]，已有10多年历史，主要面向高性能领域和通用计算领域。[中国工程院](../Page/中国工程院.md "wikilink")院士[陈左宁](../Page/陈左宁.md "wikilink")表示，在通用计算领域，神威睿思操作系统的主要优势在于自主可控度高和安全性强等方面\[17\]。

该系统具有其自身的定制化实现的[OpenACC](../Page/OpenACC.md "wikilink")2.0以帮助代码并行化\[18\]。

## 效能

理論浮點數運算效能為125,435.9 [TFlops](https://zh.wikipedia.org/wiki/FLOPS "wikilink")，而LINPACK測試中的實際效能為93,014.6 [TFlops](https://zh.wikipedia.org/wiki/FLOPS "wikilink")，有74%的效率，相比天河二號（62%）以及排名第三的泰坦（65.8%）都要高。本機組的圖形效能也較為突出，在Graph500排名中位列亞軍。\[19\]不過遇上記憶體存取較為頻繁的運算處理操作、整數數值較多的運算，記憶體存取的樽頸效應就開始顯現了。\[20\]

相較[天河二號系統功耗達](https://zh.wikipedia.org/wiki/天河二號 "wikilink")17.8百萬瓦（開啟散熱系統全速運轉時則高達24百萬瓦），神威·太湖之光僅使用15.3百萬瓦，且每瓦效能達到 6 GFLOPS/W，截至2017年11月為止，在Green 500能效比排名中排名第20位。\[21\]\[22\]

## 應用

[清華大學地球系统科学研究中心與](https://zh.wikipedia.org/wiki/清華大學地球系统科学研究中心 "wikilink")[计算机系合作](https://zh.wikipedia.org/wiki/清華大學计算机系 "wikilink")，利用“神威·太湖之光”首次实现了百万核规模、高[分辨率](../Page/分辨率.md "wikilink")的地球系统数值模拟。此前，[中國大陸的地球模拟系统模式只能达到](https://zh.wikipedia.org/wiki/中國大陸 "wikilink")200公里网格规模的分辨率，但现在已可开展25公里网格分辨率的地球系统模拟工作，在[海洋上可达到](https://zh.wikipedia.org/wiki/海洋 "wikilink")10公里分辨率。

目前，三十多家用户单位在[天气气候](https://zh.wikipedia.org/wiki/氣象學 "wikilink")、[航空航天](../Page/航空航天.md "wikilink")、[海洋科学](https://zh.wikipedia.org/wiki/海洋科学 "wikilink")、新药创制、先进[制造](https://zh.wikipedia.org/wiki/制造 "wikilink")、新[材料等领域与国家超算无锡中心开展了合作](https://zh.wikipedia.org/wiki/材料學 "wikilink")\[23\]。2016年神威·太湖之光超級電腦上的「全球大氣非靜力雲分辨模擬」應用軟體得[戈登貝爾獎](https://zh.wikipedia.org/wiki/戈登貝爾獎 "wikilink")，該獎項是頒發給超級電腦上的應用軟體設計獎，因為硬體性能的有效發揮最終還是取決於軟體設計，此前30年該獎都由美日兩國獲得，首次有第三國打破此規則。\[24\]\[25\]

## 逸聞

2017年網路春晚，舉辦了欢唱太湖之光橋段，由[羽泉演唱成名曲](https://zh.wikipedia.org/wiki/羽泉 "wikilink")《奔跑》，與太湖之光20多位科學家連線接龍對唱。\[26\]

同時網路春晚公開了目前太湖之光計算機的維護與操作小組成員，由清華大學女博士(在讀)丁楠領隊，楊晉喆(倫敦帝國理工學院博士)，甘霖(清華大學博士后)，劉加賀(清華大學碩士在讀)等20多人組成。\[27\]

## 参见

  - [中國超級計算機行業](https://zh.wikipedia.org/wiki/中國超級計算機行業 "wikilink")

  - [TOP500](../Page/TOP500.md "wikilink")

  - [神威藍光](https://zh.wikipedia.org/wiki/神威藍光 "wikilink") - 另一套使用[申威處理器的中國製超級電腦](https://zh.wikipedia.org/wiki/申威處理器 "wikilink")

  - [天河二號](https://zh.wikipedia.org/wiki/天河二號 "wikilink") - 採用Xeon E5 + Xeon Phi為運算單元的超級電腦

  - [泰坦 (超級電腦)](../Page/泰坦_\(超級電腦\).md "wikilink") - 首套使用[通用圖形處理器作為主運算單元問鼎Top](https://zh.wikipedia.org/wiki/通用圖形處理器 "wikilink")500的超級電腦

  - [京 (超级电脑)](https://zh.wikipedia.org/wiki/京_\(超级电脑\) "wikilink") - 使用 88,128 颗八核心[富士通](../Page/富士通.md "wikilink")製造的[SPARC](../Page/SPARC.md "wikilink")64中央處理器的超級電腦

  -
  -
  - [Linux](../Page/Linux.md "wikilink")

## 参考文献

## 外部連結

  - [Top500 list entry for the Sunway TaihuLight](http://www.top500.org/system/178764)

{{-}}

[Category:中国超级计算机](https://zh.wikipedia.org/wiki/Category:中国超级计算机 "wikilink") [Category:2016年中国科技](https://zh.wikipedia.org/wiki/Category:2016年中国科技 "wikilink")

1.
2.
3.
4.
5.
6.
7.
8.
9.
10. [「純中国製」スパコン、速度世界一　心臓部も自主開発、米国の輸出規制が促す？](http://www.asahi.com/articles/DA3S12418963.html) 朝日新聞デジタル
11.
12.
13.
14.
15.
16.
17.
18.
19.
20. [ISC 2016開幕、93PFLOPSの「中国純正」スパコンが世界首位](http://techon.nikkeibp.co.jp/atcl/event/15/062100069/062100001/) 日経テクノロジー
21.
22.
23.
24.
25.
26.
27.
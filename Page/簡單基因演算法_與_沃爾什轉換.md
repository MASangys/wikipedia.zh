**簡單基因演算法 與 沃爾什轉換**
簡單基因演算法為解決最佳化的搜尋演算法，是進化演算法的一種，而沃爾什轉換是在頻譜分析上最常用的一種離散傅立葉變換的替代。
Analysis (of a GA) using Walsh Transform

  - Analysis (of a GA) using Walsh Transform
  - Analysis from perspective of the Walsh basis

## Walsh Transform & Walsh Analysis

  - 離散傅立葉轉換的替代方案

### 使用 Walsh Transform 來分析基因演算法

  - 幫助正式化定義 "building block" 和 "deception"
  - 研究基因演算法上的變異(variation)

### Fitness & the Standard Basis

  - 假設 individual 為 固定長度的二進位字串, \(x \in {\{0,1\}}^l\)
  - Implied basis:
  - \(f(j)=\sum_{i=00...0}^{11...1} {f_i{\delta}_{ij}}, where ~{\delta}_{ij} = 1 ~when~i =j~and~0~otherwise\)

### Walsh Analysis of Fitness(適度)

### Overview of Schema

  - Schemata: sets of search points sharing some “syntactic feature”

\(s \in {\{0,1,*\}}^l\)
\(x \in s, \iff \forall i~(x_i = s_i) \or (s_i = *)\)

### Walsh Functions

Define:

  - <math>\\alpha(s_i) =

\\begin{cases} 0, & \\mbox{if }n\\mbox{ = \*} \\\\ 1, & \\mbox{if
}n\\mbox{ = 0, 1} \\end{cases}</math> A “0” indicates an undefined
position, while a “1” indicates one that is defined.

Defines the partition number of a schema

  - \(j_p(s)=\sum_{i=1}^{l} {\alpha(s_i)s^{i-1}}\)

Define auxiliary string, where 1 7→ −1 and 0 7→ 1. Multiplication can
now act as XOR.

  - \(y_i = {(-1)}^{x_i}\)

Define Walsh Functions, which provide the set of \(2^l\) monomials of
aux string variables:

  - \(\psi_j(y) = \prod_{k=1}^l {y_k}^{j_k}\)

#### A brief segue

  - Note that we only care about values of \(y_l\) which are -1

(or when \(x_k\) = 1)

  - In fact, we only care about the number of such factors

included in the product

  - This number is simply the number of positions k that

both x and j contain a 1 \(x^Tj\)

  - We could re-write the Walsh Function as follows:

\(\psi_j(x) = {(-1)}^{x^Tj}\)

  - Rather than see this as a set of functions that produce

vectors, we could see it as a matrix: \(\psi_{xj}\)

### Note about Walsh Functions

  - \(\psi_{j}\) defines a basis over some real vector \(\vec{w}\), just
    as the delta function did earlier over \(\vec{f}\):
  - \(f(j)=\sum_{i=00...0}^{11...1} {w_j\psi_{j}(y(x))}\)

The \(\psi_j\) basis is orthogonal:

  - <math>f(j)=\\sum_{i=00...0}^{11...1}
    {\\psi_{i}(y(x))\~\\psi_{j}(y(x))} =

\\begin{cases} 2^l, & \\mbox{if }i\\mbox{ = j} \\\\ 0, & \\mbox{if }i
\\ne \\mbox{ j} \\end{cases}</math>

## Walsh Coefficients & Schema Avg

  - \(w_j\): Walsh Coefficient
  - \(w_j = \frac{1}{2^l}\sum_{i=00...0}^{11...1} {f(x)~\psi_{j}(y(x))}\)
  - However, there exists a Fast Walsh Transform, similar to the Fast
    Fourier Transform
  - Once obtained, we can use then in linear summations to produce
    schema averages

### The relationship between the Walsh coefficients and schema averages

  - <math>\\begin{align}

f(s) & = \\frac{1}{|s|}\\sum _{x \\in s} f(x) \\\\

`    & = \frac{1}{|s|}\sum _{x \in s} \sum_{i=00...0}^{11...1} {w_j\psi_{j}(y(x))} \\`
`    & = \frac{1}{|s|}\sum _{j=00...0}^{11...1} ~w_j \sum_{x \in s} {\psi_{j}(y(x))} \\`
`    & = \frac{1}{|s|}\sum _{j=00...0}^{11...1} ~w_j \sum_{i=00...0}^{11...1} {\prod_{i=1}^l {y_i(x_i)}^{j_i}} \\`
`    \end{align}`</math>

Now we consider schema averages as the partial sum of signed Walsh
coefficients: \(\begin{array}{|c|c|} Partition & Average Fitness \\
\hline
***&w_0\\
**f&w_0 \pm w_1\\
*f*&w_0 \pm w_2\\
*ff&w_0 \pm w_1 \pm w_2 \pm w_3\\
f**&w_0 \pm w_4\\
f*f&w_0 \pm w_1 \pm w_4 \pm w_5\\
ff*&w_0 \pm w_2 \pm w_4 \pm w_6\\
fff&w_0 \pm w_0 \pm w_1 \pm w_2 \pm w_3 \pm w_4 \pm w_5 \pm w_6 \pm w_7\\
\end{array}\)

For example:

  - \(f(*01) = w_0 - w_1 + w_2 - w_3\)

Example Fitness Function: \(OneMax(x) = \sum_{i=0}^l x_i\)

  - <math>

\\begin{array}{|c|c c| |c|c} x& f(x) & j & Part \&w_j \\\\ \\hline 000
& 0.0 & 0 & \*\*\* &+1.5\\\\ 001 & 1.0 & 1 & \*\*f &-0.5\\\\ 010 & 1.0 &
2 & \*f\* &-0.5\\\\ 011 & 2.0 & 3 & \*ff &0\\\\ 100 & 1.0 & 4 & f\*\*
&-0.5\\\\ 101 & 2.0 & 5 & f\*f &0\\\\ 110 & 2.0 & 6 & ff\* &0\\\\ 111 &
3.0 & 7 & fff &0\\\\ \\end{array} </math>

### Constructing Deception

Traditional view of GA demands that low order walsh coefficients
“predict” higher order ones Now it is easy to see how a deceptive
function can be constructed:

  - When low order estimates fail to predict the optimum
  - E.g., For two bit problem where \(f(11) > f(00), f(01), f(10)\) but
    \(f(*0) > f(*1) ~or~ f(0*) > f(1*)\)
  - Here \(w_1 > 0 ~or~ w_2 > 0\) permit this

#### A fully deceptive, 3-bit problem

To be deceptive, we need:

  - \(w_1 + w_3 > 0, w_2 + w_3 > 0, w_1 + w_2 > 0\)
  - \(w_1 + w_5 > 0, w_4 + w_5 > 0, w_1 + w_4 > 0\)
  - \(w_6 + w_4 > 0, w_6 + w_2 > 0, w_2 + w_4 > 0\)

To preserve optimality:

  - \(-(w_1 + w_2 + w_4) > w_7\)
  - \(w_3 + w_5 >  w_2 + w_7\)
  - \(w_3 + w_6 >  w_1 + w_7\)
  - \(w_5 + w_3 >  w_2 + w_4\)
  - \(w_5 + w_6 >  w_4 + w_7\)
  - \(w_5 + w_6 >  w_1 + w_1\)
  - \(w_6 + w_3 >  w_1 + w_4\)

A fully deceptive 3-bit fitness landscape:

  - <math>

\\begin{array}{|c|c c| |c|c} x& f(x) & j & Part \&w_j \\\\ \\hline 000
& 13.0 & 0 & \*\*\* &0\\\\ 001 & 11.0 & 1 & \*\*f &+1.0\\\\ 010 & 7.0 &
2 & \*f\* &+2.0\\\\ 011 & -15.0 & 3 & \*ff &+3.0\\\\ 100 & -1.0 & 4 &
f\*\* &+4.0\\\\ 101 & -15.0 & 5 & f\*f &+5.0\\\\ 110 & -15.0 & 6 & ff\*
&+6.0\\\\ 111 & 15.0 & 7 & fff &-8.0\\\\ \\end{array} </math>

  - 0th order: 0
  - 1st order: 0 - 7 = -7
  - 2nd order: -7 + 14 = 7
  - Exact: 7 - (-8) = 15
  - **The lower order blocks do not correctly predict the optimum**

### Defining Deception

  - Near Optimal Set: \(N = \{x : f^* - f(x) \leq \epsilon \}\)
  - Op-Adj. Near Optimal
    Set\[N^' = \{x: f^{'*} - f^'(x) \leq \epsilon^'\}\]
  - Statically Deceptive: \(N - N^' \neq \varnothing\)
  - Statically Easy: \(N - N^' \neq \varnothing\)
  - Strictly Statically Easy: \(N = N^'\)

## Walsh Analysis of Mixing Matrices

### Overview of the Vose SGA & Mixing

  - Representation of individuals are discrete, fixed-length strings
    using alphabets of arbitrary cardinality (focus on binary)
  - Populations are infinite in size
  - Model the effects of selection and variation in a generation as a
    discrete time dynamical system
  - Interested in analyzing the expected dynamical behavior in a real GA
  - Population state represented as a vector of proportions of each
    genotype in population:
    \(\Delta^n = \{\vec{x}:x_i \in R, x_i \geq 0, \sum_i {x_i = 1}\}\)

<!-- end list -->

  - Dynamical map is a composition of steps in a GA generation:
    \(g = M \circ S \circ F\)
      - F assigns fitness, \(F: \Delta^n \to R^n\)
      - S redistributes proportions due to selection,
        \(S : R^n \to \Delta^n\)
      - M applies mutation and recombination effects,
        \(M : \Delta^n \to \Delta^n\)
      - Simplification:
          - \(\vec{x}^' = S(F(\vec{x}))\)
          - \(\vec{x}^{''} = M(\vec{x}^')\)

#### The Mixing Matrix

Let \(\sigma_k\) be the k permutation matrix and \(\oplus\) mean XOR

  - Define a mixing probabilities matrix \(M^{(0)}\), or just
    \(M: M = Pr[parent ~ i \times parent ~j \to child ~0]\)
  - We obtain \(M^(k)\) generally by permuting M:
    \(M^{(k)} = M_{i\oplus k,j \oplus k}\forall i, j\)

### Matrices

  - Define the twist \(A^*\) of a \(n \times n\) matrix A by
    \({A^*}_{i,j} = A_{i \oplus j, -i}\)
  - Define the conjugate transpose as the transpose of the complex
    conjugate of a matrix, denoted \(A^H\)

### Applying the Walsh Transform to M

  - A mixing matrix is dense under positive mutation, but has a sparse
    Fourier transform
  - If mutation is zero, \(M = \widehat{M}\)
  - \(\widehat{M^*}\) is lower triangular
  - If mutation is zero, \(M^*\) is upper triangular

## Conclusion

  - We can use the twist to more easily obtain the differential of
    mixing: \(dM_x = 2 \sum_u \sigma^T_u M^* \sigma_u \sigma_u\)
  - Some mathematical properties can be elicited from transformed mixing
    matrix:
      - Access to the spectrum of M obtained through \(M^*\)
      - Types of invariances under mixing exposed by Walsh transform
      - If mutation is positive, largest eigenvalue is 2 and all other
        eigenvalues are inside the unit disk
  - Efficiency improvement in calculating infinite population model from
    \(O^{(3l)}\) to \(O^{(l lg 3)}\)
  - Walsh provides a way to elicit model of inverse \[1\]

## 參考資料

1.  R. Paul Wiegand, Introduction to Walsh Analysis class note, George
    Mason University.
> 本文内容由[粒子濾波器](https://zh.wikipedia.org/wiki/粒子濾波器)转换而来。


**粒子滤波器**(particle filter)是一种使用[蒙特卡罗方法](https://zh.wikipedia.org/wiki/蒙特卡罗方法 "wikilink")(Monte Carlo method)的[递归滤波器](https://zh.wikipedia.org/wiki/递归滤波器 "wikilink")，透过一组具有权重的随机样本(稱為粒子)來表示[隨機事件的](../Page/事件_\(概率论\).md "wikilink")[後驗機率](../Page/后验概率.md "wikilink")，從含有雜訊或不完整的觀測序列，估計出動態系統的狀態，粒子濾波器可以運用在任何[狀態空間的模型上](../Page/状态空间.md "wikilink")。

粒子濾波器是[卡爾曼濾波器](../Page/卡尔曼滤波.md "wikilink")(Kalman filter)的一般化方法，卡爾曼濾波器建立在線性的狀態空間和[高斯分布的雜訊上](../Page/正态分布.md "wikilink")；而粒子濾波器的狀態空間模型可以是非線性，且雜訊分布可以是任何型式。

## 粒子濾波器原理

粒子濾波器能夠從一系列含有雜訊或不完整的觀測值中，估計出動態系統的內部狀態。在動態系統的分析中，需要兩個模型，一個用來描述狀態隨時間的變化**(系統模型)**，另一個用來描述每個狀態下觀測到的雜訊**(觀測模型)**，將這兩個模型都用機率來表示。

在許多情況下，每得到一個新的觀測值時，都必須對系統做出一次估計，利用[遞迴濾波器](https://zh.wikipedia.org/wiki/递归滤波器 "wikilink")，能夠有效地達到這樣的目的。遞迴濾波器會對得到的資料做連續處理，而非分批處理，因此不需要將完整的資料儲存起來，也不需要在得到新的觀測值時，將現有的資料重新做處理。遞迴濾波器包含兩個步驟：

**預測**：利用系統模型，由前一個狀態的資訊預測下一個狀態的[機率密度函數](../Page/機率密度函數.md "wikilink")。

**更新**：利用最新的觀測值，修改預測出的機率密度函數。

藉由[貝葉斯推論](../Page/贝叶斯推断.md "wikilink")(Baysian inference)，我們可以描述出[狀態空間的機率](../Page/状态空间.md "wikilink")，並在得到新的觀測值時，對系統做出更新，因而達成上述目的。

## 非線性貝葉斯追蹤

在動態系統中，我們常常需要對物體做追蹤。假設有一動態系統，已知其狀態序列\(\{x_k, k\in N\}\)定義為

\(x_k=f_k(x_{k-1},v_{k-1})\)

其中\(f_k:R^{n_x}\times R^{n_v}\rightarrow R^{n_x}\)是**狀態轉移函數**，可以是非線性的函數，\(\{v_{k-1},k\in N\}\)是一個**獨立且相同分布(i.i.d.)**的過程雜訊序列，\(n_x\)和\(n_v\)分別代表狀態和過程雜訊向量的維度，\(N\)為自然數的集合。追蹤的目標是要遞迴地從觀測值\(y_k\)估計出\(x_k\)，而觀測值\(y_k\)定義為

\(y_k=h_k(x_k,n_k)\)

其中\(h_k:R^{n_x}\times R^{n_n}\rightarrow R^{n_y}\)是**觀測函數**，可以是非線性的函數，\(\{n_k,k\in N\}\)是一個**獨立且相同分布(i.i.d.)**的觀測雜訊序列，\(n_y\)和\(n_n\)分別代表觀測值和觀測雜訊向量的維度。

從貝葉斯理論的觀點來看，追蹤問題是要根據到時間\(k\)為止的已知資訊\(y_{1:k}\)，遞迴地計算出時間\(k\)的狀態\(x_k\)的可信度，這個可信度用機率密度函數\(p(x_k\mid y_{1:k})\)來表示。假設初始機率密度函數\(p(x_0\mid y_0)\equiv p(x_0)\)(稱為[先驗機率](https://zh.wikipedia.org/wiki/先验概率 "wikilink"))為已知，則利用**「預測」**和**「更新」**兩個步驟就能遞迴地計算出機率密度函數\(p(x_k\mid y_{1:k})\)。

在此假設在時間\(k-1\)的機率密度函數\(p(x_{k-1}\mid y_{1:k-1})\)為已知。

### 預測

利用[查普曼-科爾莫戈羅夫等式](../Page/查普曼-科尔莫戈罗夫等式.md "wikilink")(Chapman–Kolmogorov equation)，可以由**狀態轉移函數**與時間\(k-1\)的機率密度函數\(p(x_{k-1}\mid y_{1:k-1})\)，計算出時間\(k\)的[先驗機率](https://zh.wikipedia.org/wiki/先验概率 "wikilink")\(p(x_k\mid y_{1:k-1})\)

\(\begin{align} p(x_k\mid y_{1:k-1}) & = \int p(x_k,x_{k-1}\mid y_{1:k-1})d{x_{k-1}} \\
& = \int p(x_k\mid x_{k-1}, y_{1:k-1})p(x_{k-1}\mid y_{1:k-1})d{x_{k-1}} \\
& = \int p(x_k\mid x_{k-1})p(x_{k-1}\mid y_{1:k-1})d{x_{k-1}} \\ \end{align}\)

其中，由於狀態轉移模型被假設為一階[馬可夫過程](../Page/馬可夫過程.md "wikilink")，時間\(k-1\)的狀態只由時間\(k\)決定，因此\(p(x_k\mid x_{k-1}, y_{1:k-1})=p(x_k\mid x_{k-1})\)。機率模型\(p(x_k\mid x_{k-1})\)由**狀態轉移函數**\(x_k=f_k(x_{k-1},v_{k-1})\)和\(v_{k-1}\)的統計值得到。

### 更新

在時間\(k\)，我們得到觀測值\(y_k\)，因此可以利用[貝氏定理](../Page/贝叶斯定理.md "wikilink")，由[先驗機率](https://zh.wikipedia.org/wiki/先验概率 "wikilink")\(p(x_k\mid y_{1:k-1})\)得到[後驗機率](../Page/后验概率.md "wikilink")\(p(x_k\mid y_{1:k})\)，也就是考慮觀測值後得到的機率。

\(p(x_k\mid y_{1:k})={p(y_k\mid x_k)p(x_k\mid y_{1:k-1})\over p(y_k\mid y_{1:k-1})}\)

其中的[歸一化常數](../Page/歸一化常數.md "wikilink")為

\(p(y_k\mid y_{1:k-1})=\int p(y_k\mid x_k)p(x_k\mid y_{1:k-1})dx_k\)

其中的[似然函數](../Page/似然函数.md "wikilink")\(p(y_k\mid x_k)\)由**觀測函數**\(y_k=h_k(x_k,n_k)\)和\(n_k\)的統計值得到。

上述**「預測」**與**「更新」**的遞迴關係，是貝葉斯最佳解的基本概念，然而公式中運用到的積分，對於一般非線性、非高斯的系統，難以得到解析解，因此需要利用[蒙地卡羅方法](../Page/蒙地卡羅方法.md "wikilink")來近似貝葉斯最佳解。

## 序列重要性重採樣(Sequential Importance Resampling, SIR)

### 序列重要性採樣(Sequential Importance Sampling, SIS)

**SIR**是由**SIS**加上**重採樣(resampling)**改良而來，在SIS中，我們將[後驗機率](../Page/后验概率.md "wikilink")\(p(x_k\mid y_{1:k})\)用\(N\)個隨機採樣的樣本(稱為粒子)與各自的權重表示為

\({\{x_k^{(i)},w_k^{(i)}\}}_{i=1}^N\)

其中的權重是根據[重要性採樣的規則產生](https://zh.wikipedia.org/wiki/重要性採樣 "wikilink")，且必須符合

\(\sum_{i=1}^N w_k^{(i)}=1\)

SIS是將重要性採樣遞迴執行的一種方法，根據重要性採樣的理論，一個函數\(f\)的期望值可以用加權平均來近似

\(\int f(x_k)p(x_k\mid y_{1:k})dx_k\approx \sum_{i=1}^N w_k^{(i)}f(x_k^{(i)})=1\)

在每一次遞迴過程中，我們希望由前一次採樣的權重，計算出下一次採樣的權重。假設採樣的樣本分布可以表示為

\(x^{(i)}\sim q(x),\) \(i=1,...,N\)

其中\(q(x)\)稱為**重要性密度(importance density)**。若樣本\(x_k^{(i)}\)是由重要性密度\(q(x_k\mid y_{1:k})\)抽取出來，則權重可表示為

\(w_k^{(i)}\propto{p(x_k^{(i)}\mid y_{1:k})\over q(x_k^{(i)}\mid y_{1:k})}\)

我們將重要性密度分解為

\(q(x_k\mid y_{1:k})=q(x_k\mid x_{k-1},y_{1:k})q(x_{k-1}\mid y_{1:k-1})\)

再將後驗機率表示為

\(\begin{align} p(x_k\mid y_{1:k}) & = {p(y_k\mid x_k,y_{1:k-1})p(x_k\mid y_{1:k-1})\over p(y_k\mid y_{1:k-1})} \\
& = {p(y_k\mid x_k,y_{1:k-1})p(x_k\mid x_{k-1},y_{1:k-1})p(x_{k-1}\mid y_{1:k-1})\over p(y_k\mid y_{1:k-1})} \\
& = {p(y_k\mid x_k)p(x_k\mid x_{k-1})p(x_{k-1}\mid y_{1:k-1})\over p(y_k\mid y_{1:k-1})} \\
& \propto p(y_k\mid x_k)p(x_k\mid x_{k-1})p(x_{k-1}\mid y_{1:k-1}) \\ \end{align}\)

則權重的遞迴式可以表示為

\(\begin{align} w_k^{(i)} & \propto{p(y_k\mid x_k^{(i)})p(x_k^{(i)}\mid x_{k-1}^{(i)})p(x_{k-1}^{(i)}\mid y_{1:k-1})\over q(x_k^{(i)}\mid x_{k-1}^{(i)},y_{1:k})q(x_{k-1}^{(i)}\mid y_{1:k-1})} \\
& = w_{k-1}^{(i)}{p(y_k\mid x_k^{(i)})p(x_k^{(i)}\mid x_{k-1}^{(i)})\over q(x_k^{(i)}\mid x_{k-1}^{(i)},y_{1:k})} \\ \end{align}\)

### 重採樣(resampling)

SIS可能會造成**退化問題(degeneracy problem)**，也就是在經過幾次遞迴後，很多粒子的權重都變小到可以忽略不計，只剩少數粒子的權重較大，如此會浪費大量的計算量在幾乎沒有作用的粒子上，而使估計性能下降。由於在遞迴過程中，權重的變異數只會愈來愈大，因此退化問題無法被避免。

為了評估退化問題，我們定義**有效粒子數**為

\(\widehat{N_{eff}}={1\over\sum_{i=1}^N (w_k^{(i)})^2}\)

在進行SIS時，若有效粒子數小於某一閾值，則對粒子做重採樣，即可減緩退化問題。重採樣的概念是去除權重過小的粒子，專注於權重較大的粒子。進行重採樣時，要由現有的粒子分布取樣，產生一組新的粒子\({\{x_k^{(i)*}\}}_{i=1}^N\)，由於產生出的新樣本為**獨立且相同分布(i.i.d.)**，因此將權重重新設定為\(w_k^{(i)}={1\over N}\)。

## 參見

  - [图像处理](../Page/图像处理.md "wikilink")
  - [机器学习](../Page/机器学习.md "wikilink")
  - [机器人学](../Page/机器人学.md "wikilink")
  - [人工智能](../Page/人工智能.md "wikilink")
  - [同步定位與地圖構建](../Page/即时定位与地图构建.md "wikilink")(simultaneous localization and mapping, SLAM)
  - [滾動時域估計](../Page/滾動時域估計.md "wikilink")

## 參考文獻

1.  M. S. Arulampalam, S. Maskell, N. Gordon and T. Clapp, "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking." In IEEE Transactions on Signal Processing, vol. 50, no. 2, pp. 174-188, Feb 2002.
2.  A. Doucet, N. de Freitas, N. Gordon, "An Introduction to Sequential Monte Carlo Methods." In A. Doucet, N. de Freitas, N. Gordon (eds.) Sequential Monte Carlo Methods in Practice. Statistics for Engineering and Information Science. Springer, New York, NY, 2001
3.  A. Doucet, "On sequential Monte Carlo methods for Bayesian filtering." Dept. Eng., Univ. Cambridge, UK, Tech. Rep., 1998.

[Category:蒙地卡羅方法](https://zh.wikipedia.org/wiki/Category:蒙地卡羅方法 "wikilink") [Category:計算統計學](https://zh.wikipedia.org/wiki/Category:計算統計學 "wikilink") [Category:控制理论](https://zh.wikipedia.org/wiki/Category:控制理论 "wikilink") [Category:机器人控制](https://zh.wikipedia.org/wiki/Category:机器人控制 "wikilink") [Category:统计力学](https://zh.wikipedia.org/wiki/Category:统计力学 "wikilink")
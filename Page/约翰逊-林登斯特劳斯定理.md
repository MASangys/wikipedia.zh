> 本文内容由[约翰逊-林登斯特劳斯定理](https://zh.wikipedia.org/wiki/约翰逊-林登斯特劳斯定理)转换而来。


**约翰逊-林登斯特劳斯定理(Johnson–Lindenstrauss theorem)**，又称**约翰逊-林登斯特劳斯引理(Johnson–Lindenstrauss lemma)**，是由和于1984年提出的一个关于[降维](../Page/降维.md "wikilink")的著名定理，在现代[机器学习](../Page/机器学习.md "wikilink")，尤其是[压缩感知](https://zh.wikipedia.org/wiki/压缩感知 "wikilink")、[降维](../Page/降维.md "wikilink")、和等领域中有很重要的应用。

这个定理告诉我们，一个高维空间中的点集，可以被**线性**地[镶嵌到低维空间中](../Page/嵌入_\(数学\).md "wikilink")，同时其空间结构只遭受比较小的形变。约翰逊-林登斯特劳斯定理的证明，还说明了如何用明确地求出这个变换，所用的算法只需要[随机多项式时间](https://zh.wikipedia.org/wiki/RP_\(复杂度\) "wikilink")。当然，降维不是免费的：如果要求形变很少的话，是被嵌入的低维空间维数不能很低；反之亦然，如果要求将点集嵌入很低维的空间，那么就不能很好地控制结构形变的程度。

因为能将维数下降到样本量的对数阶，更兼所用的变换是**线性的**、**显式的**还可以被**快速计算**，约翰逊-林登斯特劳斯定理是一个力度非常强的结论。

## 定理陈述

对任何给定的\(\epsilon\in(0,1)\)以及\(N\)维[欧几里德空间中的](https://zh.wikipedia.org/wiki/欧几里德空间 "wikilink")\(m\)个点\(\{x_1,\ldots,x_m\}\)，对于任意满足条件\(n>(\epsilon^2/2-\epsilon^3/3)^{-1}\log m\)的正整数\(n\)，存在一个**线性**映射\(f:\mathbb{R}^N\to\mathbb{R}^n\)，将这\(m\)个点，从\(\mathbb{R}^N\)(维数可能很高的空间)中映射到\(\mathbb{R}^n\)(低维空间)中，同时“基本上”保持了点集成员两两之间的距离，即：对于任意两个点\((x_i,x_j):1\leq i<j\leq m\)，都有

  -
    \((1-\epsilon)\|x_i-x_j\|_2^2\leq \|f(x_i)-f(x_j)\|_2^2\leq(1+\epsilon)\|x_i-x_j\|_2^2\)

更进一步地，这个线性映射\(f\)还可以在[随机多项式时间内求出](https://zh.wikipedia.org/wiki/RP_\(复杂度\) "wikilink")。

### 直观理解

约翰逊-林登斯特劳斯定理揭示了一些关于降维映射深刻事实，其中一些还是违反简单直觉的。因此，要想直观地理解这个定理，对初学者来说，可能比从数学式子上读懂证明还要难(反而此定理的证明只用到了比较简单的关于投影的)。举例来说，定理的结论表明，度量形变程度的误差参数\(\epsilon\)以及低维空间的维数\(n\)这两个度量降维水准的关键量，均与原始数据所在的空间维数\(N\)或者原始的\(m\)个点具体为何种空间结构无关，这是很不平凡的。

### 最优性

约翰逊-林登斯特劳斯定理是**不能**被本质性地改进的，即：给定任意正整数\(m\)和误差参数\(\epsilon\)，存在某个\(N\)以及\(\mathbb{R}^N\)中的\(m\)个点，这个点集“难以降维”——也就是说，对任何一个满足“基本保持点距”要求(即：\((1-\epsilon)\|x_i-x_j\|_2^2\leq \|f(x_i)-f(x_j)\|_2^2\leq(1+\epsilon)\|x_i-x_j\|_2^2\)要对任意\((i,j):1\leq i<j\leq n\)成立)的线性映射\(f:\mathbb{R}^N\to\mathbb{R}^n\)，它用来镶嵌高维数据的那个低维空间(即\(\mathbb{R}^n\))，至少必须具有

  -
    \(n=\Omega\left(\frac{\log m}{\epsilon^2}\right)\)

这么多的维数。

### 证明提要

定理可以用高年级本科生容易理解的方法证明，其思路是证明如下事实：多次独立地重复进行随机投影的试验，每次试验中随机抽取的投影\(f_0:\mathbb{R}^N\to\mathbb{R}^n\)都有至少\(1/n\)的概率符合定理中对映射\(f\)全部的要求(显然，验证任何一个\(f_0\)是否符合这些要求只需\(O(n^2)\)时间)，因此只要重复该独立实验\(\omega(n)\)次就能以逼近100%的概率产生至少一个符合要求的映射\(f\)。

## 参考文献

[Category:数学定理](https://zh.wikipedia.org/wiki/Category:数学定理 "wikilink") [Category:机器学习](https://zh.wikipedia.org/wiki/Category:机器学习 "wikilink")
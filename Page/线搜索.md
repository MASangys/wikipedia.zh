[最优化问题中](../Page/最优化.md "wikilink")，**线搜索**
是一种寻找[目标函数](../Page/目标函数.md "wikilink")
\(f:\mathbb R^n\to\mathbb R\) 的[局部最小值](../Page/极值.md "wikilink")
\(\mathbf{x}^*\)
的近似方法。它是最基础的[迭代近似方法之一](../Page/迭代.md "wikilink")，另一种是[置信域方法](../Page/置信域方法.md "wikilink")。

线搜索近似首先找到一个使目标函数 \(f\) 下降的方向，然后计算 \(\mathbf{x}\)
应该沿着这个方向移动的步长。下降方向可以通过多种方法计算，比如[梯度下降法](../Page/梯度下降法.md "wikilink")，[牛顿法和](../Page/牛顿法.md "wikilink")。计算出的步长不一定是精确的。

## 应用举例

以一个梯度法作为例子，其中第四步中使用到了线搜索。

1.  令迭代计数器 \(\displaystyle k=0\)，为最小值做一个初始估计 \(\mathbf{x}_0\)
2.  重复以下步骤：
3.      计算 \(\mathbf{p}_k\)
4.      选择 \(\displaystyle \alpha_k\) 以在 \(\alpha\in\mathbb R_+\)
    上粗略地最小化
    \(h(\alpha)=f(\mathbf{x}_k+\alpha\mathbf{p}_k)\)
5.      更新 \(\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{p}_k\), 以及
    \(\displaystyle k=k+1\)
6.  直到 \(\|\nabla f(\mathbf{x}_k)\|\) 小于容忍度。

在第四步的线搜索中算法可以通过解方程 \(h'(\alpha_k)=0\) 来*精确地*，或者只是通过寻找一个 \(h\)
的充分下降来*粗略地*最小化
\(h\)。前者的一个例子是[共轭梯度法](../Page/共轭梯度法.md "wikilink")。后者被称作不精确线搜索，有很多种实现方法，比如或者是使用。

与其它的最优化方法类似，线搜索也可以跟[模拟退火结合以越过一些](../Page/模拟退火.md "wikilink")[局部最小值](../Page/极值.md "wikilink")。

## 算法

### 直接搜索方法

这种方法里，必须先把最小值括在一个范围内，也就是说这个算法必须能够找到 \(x_1\) 和 \(x_2\)
使得要找的最小值在它们之间。接着通过计算这个区间内部的两个点
\(x_3\) 和 \(x_4\)，把区间分成几个子区间，抛弃掉外面两个点中与 \(x_3\) 和 \(x_4\)
中函数值更小的那个点不相邻的那一个。接下来的每一步中，只需要计算
额外的一个内部的点。在各种划分区间的方法中，\[1\]
[黄金分割法是一种特别简单而高效的方法](../Page/黄金分割法.md "wikilink")，它的划分比例在搜索进行中始终保持不变。

\[\frac{1}{\phi}(x_2-x_1)=x_4-x_1=x_2-x_3=\phi(x_2-x_4)=\phi(x_3-x_1)=\phi^2(x_4-x_3)\]
where \(\phi=\frac{1}{2}(1+\sqrt 5) \approx 1.618\)

## 参阅

  - [割线法](../Page/割线法.md "wikilink")
  - [牛顿法](../Page/牛顿法.md "wikilink")
  - [黄金分割法](../Page/黄金分割法.md "wikilink")

## 参考

<references />

[Category:最优化算法](https://zh.wikipedia.org/wiki/Category:最优化算法 "wikilink")

1.
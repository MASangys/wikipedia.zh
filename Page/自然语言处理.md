**自然語言處理**（，[缩写作](https://zh.wikipedia.org/wiki/缩写 "wikilink")
****）是[人工智慧和](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")[語言學領域的分支學科](https://zh.wikipedia.org/wiki/語言學 "wikilink")。此領域探討如何處理及運用[自然語言](https://zh.wikipedia.org/wiki/自然語言 "wikilink")；自然語言處理包括多方面和步骤，基本有认知、理解、生成等部分。

自然語言認知和理解是讓電腦把输入的[語言变成有意思的符号和关系](https://zh.wikipedia.org/wiki/語言 "wikilink")，然后根据目的再處理。自然語言生成系統则是把計算機數據轉化為自然語言。

## 歷史

自然語言處理大體是從1950年代開始，雖然更早期也有作為。1950年，[图灵發表論文](https://zh.wikipedia.org/wiki/图灵 "wikilink")「」，提出現在所謂的「[圖靈測試](https://zh.wikipedia.org/wiki/圖靈測試 "wikilink")」作為判斷智能的條件。

1954年的涉及全部超過60句俄文成為英文。研究人員聲稱三到五年之內即可解決機器翻譯的問題。\[1\]不過實際進展遠低於預期，1966年的發現十年研究未達預期目標，機器翻譯的研究經費遭到大幅削減。一直到1980年代末期，[統計機器翻譯系統發展出來](https://zh.wikipedia.org/wiki/統計機器翻譯 "wikilink")，機器翻譯的研究才得以更上一層樓。

1960年代發展特別成功的NLP系統包括——一個詞彙設限、運作於受限如「[積木世界](https://zh.wikipedia.org/wiki/積木世界 "wikilink")」的一種自然語言系統，以及1964-1966年[约瑟夫·维森鲍姆模擬](../Page/约瑟夫·维森鲍姆.md "wikilink")「[個人中心治療](../Page/個人中心治療.md "wikilink")」而設計的——幾乎未運用人類思想和感情的訊息，有時候卻能呈現令人訝異地類似人之間的互動。「病人」提出的問題超出ELIZA
極小的知識範圍之時，可能會得到空泛的回答。例如問題是「我的頭痛」，回答是「為什麼說你頭痛？」

1970年代，程式設計師開始設計「概念本體論」（conceptual
ontologies）的程式，將現實世界的資訊，架構成電腦能夠理解的資料。實例有MARGIE、SAM、PAM、TaleSpin、QUALM、Politics以及Plot
Unit。許多[聊天機器人在這一時期寫成](../Page/聊天機器人.md "wikilink")，包括 、 以及 。

一直到1980年代，多數自然語言處理系統是以一套複雜、人工訂定的規則為基礎。不過從1980年代末期開始，語言處理引進了[機器學習的演算法](https://zh.wikipedia.org/wiki/機器學習 "wikilink")，NLP產生革新。成因有兩個：運算能力穩定增加（參見[摩爾定律](https://zh.wikipedia.org/wiki/摩爾定律 "wikilink")）；以及[喬姆斯基](https://zh.wikipedia.org/wiki/喬姆斯基 "wikilink")
語言學理論漸漸喪失主導（例如[轉換-生成文法](https://zh.wikipedia.org/wiki/轉換-生成文法 "wikilink")）。該理論的架構不傾向於[語料庫](https://zh.wikipedia.org/wiki/語料庫 "wikilink")——機器學習處理語言所用方法的基礎。有些最早期使用的機器學習演算法，例如[決策樹](https://zh.wikipedia.org/wiki/決策樹 "wikilink")，是硬性的、「如果-則」規則組成的系統，類似當時既有的人工訂定的規則。不過將[隱馬爾可夫模型引入NLP](https://zh.wikipedia.org/wiki/隱馬爾可夫模型 "wikilink")，並且研究日益聚焦於軟性的、以[機率做決定的](https://zh.wikipedia.org/wiki/機率 "wikilink")[統計模型](https://zh.wikipedia.org/wiki/統計模型 "wikilink")，基礎是將輸入資料裡每一個特性賦予代表其份量的數值。許多[語音識別現今依賴的](https://zh.wikipedia.org/wiki/語音識別 "wikilink")即是一種統計模型的例子。這種模型通常足以處理非預期的輸入數據，尤其是輸入有錯誤（真實世界的數據總免不了），並且在整合到包含多個子任務的較大系統時，結果比較可靠。

許多早期的成功屬於[機器翻譯領域](https://zh.wikipedia.org/wiki/機器翻譯 "wikilink")，尤其歸功IBM的研究，漸次發展出更複雜的統計模型。這些系統得以利用加拿大和歐盟現有的[語料庫](https://zh.wikipedia.org/wiki/語料庫 "wikilink")，因為其法律規定政府的會議必須翻譯成所有的官方語言。不過，其他大部分系統必須特別打造自己的語料庫，一直到現在這都是限制其成功的一個主要因素，於是大量的研究致力於從有限的數據更有效地學習。

近來的研究更加聚焦於[非監督式學習和](https://zh.wikipedia.org/wiki/非監督式學習 "wikilink")的演算法。這種演算法，能夠從沒有人工註解理想答案的資料裡學習。大體而言，這種學習比[監督學習困難](https://zh.wikipedia.org/wiki/監督學習 "wikilink")，並且在同量的數據下，通常產生的結果較不準確。不過沒有註解的數據量極巨（包含了[全球資訊網](https://zh.wikipedia.org/wiki/全球資訊網 "wikilink")），彌補了較不準確的缺點。

近年來,
[深度學習技巧紛紛出爐](https://zh.wikipedia.org/wiki/深度學習 "wikilink")\[2\]\[3\]
在自然語言處理方面獲得最尖端的成果，例如語言模型\[4\]、語法分析\[5\]\[6\]等等。

## 任務和限制

理論上，NLP是一種很吸引人的人機交互方式。早期的语言处理系统如[SHRDLU](https://zh.wikipedia.org/wiki/SHRDLU "wikilink")，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。

由於理解（understanding）自然語言，需要關於外在世界的廣泛知識以及運用操作這些知識的能力，自然語言認知，同時也被視為一個人工智慧完備（AI-complete）的問題。同時，在自然語言處理中，"理解"的定義也變成一個主要的問題。

## 實際問題

一些NLP面臨的問題實例：

  - 句子“我們把香蕉給猴子，因為(-{牠}-們)餓了”和“我們把香蕉給猴子，因為(-{它}-們)熟透了”有同樣的結構。但是代詞“它們”在第一句中指的是“猴子”，在第二句中指的是“香蕉”。如果不了解猴子和香蕉的屬性，無法區分。(简体中文和英文的-{它/it}-沒有區分，但在中文(正體中文)裡-{「牠」和「它」}-是有區別的，只是代詞在中文裡常常被省略，因此需區別屬性並且標示出來)

## 自然語言處理的主要範疇

  - [文本朗讀](https://zh.wikipedia.org/wiki/文本朗讀 "wikilink")（Text to
    speech）/[語音合成](https://zh.wikipedia.org/wiki/語音合成 "wikilink")（Speech
    synthesis）
  - [語音識別](https://zh.wikipedia.org/wiki/語音識別 "wikilink")（Speech
    recognition）
  - [中文自动分词](https://zh.wikipedia.org/wiki/中文自动分词 "wikilink")（Chinese
    word segmentation）
  - [词性标注](https://zh.wikipedia.org/wiki/词性标注 "wikilink")（Part-of-speech
    tagging）
  - [句法分析](https://zh.wikipedia.org/wiki/句法分析 "wikilink")（Parsing）
  - [自然語言生成](https://zh.wikipedia.org/wiki/自然語言生成 "wikilink")（Natural
    language generation）
  - [文本分类](https://zh.wikipedia.org/wiki/文本分类 "wikilink")（Text
    categorization）
  - [信息检索](https://zh.wikipedia.org/wiki/信息检索 "wikilink")（Information
    retrieval）
  - [信息抽取](../Page/信息抽取.md "wikilink")（Information extraction）
  - [文字校對](../Page/校對.md "wikilink")（Text-proofing）
  - [問答系統](../Page/問答系統.md "wikilink")（Question answering）

<!-- end list -->

  -
    給一句人類語言的问句，決定其答案。 典型問題有特定答案 (像是加拿大的首都叫什麼?)，但也考慮些開放式問句(像是人生的意義是是甚麼?)

<!-- end list -->

  - [機器翻譯](https://zh.wikipedia.org/wiki/機器翻譯 "wikilink")（Machine
    translation）

<!-- end list -->

  -
    將某種人類語言自動翻譯至另一種語言

<!-- end list -->

  - [自動摘要](https://zh.wikipedia.org/wiki/自動摘要 "wikilink")（Automatic
    summarization）

<!-- end list -->

  -
    產生一段文字的大意，通常用於提供已知領域的文章摘要，例如產生報紙上某篇文章之摘要

<!-- end list -->

  - [文字蘊涵](../Page/文字蘊涵.md "wikilink")（Textual entailment）
  - [命名实体识别](https://zh.wikipedia.org/wiki/命名实体识别 "wikilink")（Named
    entity recognition）

## 自然語言處理研究的難點

### 單詞的邊界界定

  -
    在口語中，詞與詞之間通常是連貫的，而界定字詞邊界通常使用的辦法是取用能讓給定的上下文最為通順且在文法上無誤的一種最佳組合。在書寫上，[漢語也沒有詞與詞之間的邊界](https://zh.wikipedia.org/wiki/漢語 "wikilink")。

### 詞義的消歧

  -
    許多字詞不單只有一個意思，因而我們必須選出使句意最為通順的解釋。

### 句法的模糊性

  -
    [自然語言的](https://zh.wikipedia.org/wiki/自然語言 "wikilink")[文法通常是](../Page/文法.md "wikilink")[模稜兩可的](https://zh.wikipedia.org/wiki/模稜兩可 "wikilink")，針對一個句子通常可能會[剖析](../Page/語法分析器.md "wikilink")（Parse）出多棵[剖析樹](https://zh.wikipedia.org/wiki/剖析樹 "wikilink")（Parse
    Tree），而我們必須要仰賴[語意及前後文的資訊才能在其中選擇一棵最為適合的剖析樹](https://zh.wikipedia.org/wiki/語意 "wikilink")。

### 有瑕疵的或不規範的輸入

  -
    例如語音處理時遇到外國口音或地方口音，或者在文本的處理中處理拼寫，語法或者[光學字元識別](https://zh.wikipedia.org/wiki/光學字元識別 "wikilink")（OCR）的錯誤。

### 语言行为与计划

  -
    句子常常并不只是字面上的意思；例如，“你能把盐递过来吗”，一个好的回答应当是動手把盐递过去；在大多数上下文环境中，“能”将是糟糕的回答，虽说回答“不”或者“太远了我拿不到”也是可以接受的。再者，如果一门课程去年没开设，对于提问“这门课程去年有多少学生没通过？”回答“去年没开这门课”要比回答“没人没通过”好。

## 当前自然语言处理研究的发展趋势

第一，传统的基于句法-语义规则的理性主义方法过于复杂，随着语料库建设和语料库语言学的崛起，大规模真实文本的机器学习处理成为自然语言处理的主要选择。

第二，统计数学方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。

第三，浅层处理与深层处理并重，统计与规则方法并重，形成混合式的系统。

第四，自然语言处理中越来越重视词汇的作用，出现了强烈的“词汇主义”的倾向。词汇知识库的建造成为了普遍关注的问题。\[7\]

## 統計自然語言處理

統計自然語言處理運用了[推測學](https://zh.wikipedia.org/wiki/推測學 "wikilink")、[機率](https://zh.wikipedia.org/wiki/機率 "wikilink")、[統計的方法來解決上述](https://zh.wikipedia.org/wiki/統計 "wikilink")，尤其是針對容易高度模糊的長串句子，當套用實際文法進行分析產生出成千上萬筆可能性時所引發之難題。處理這些高度模糊句子所採用消歧的方法通常運用到[語料庫以及](https://zh.wikipedia.org/wiki/語料庫 "wikilink")[馬可夫模型](https://zh.wikipedia.org/wiki/馬可夫模型 "wikilink")（Markov
models）。統計自然語言處理的技術主要由同樣自[人工智慧下與學習行為相關的子領域](https://zh.wikipedia.org/wiki/人工智慧 "wikilink")：[機器學習及](https://zh.wikipedia.org/wiki/機器學習 "wikilink")[資料採掘所演進而成](https://zh.wikipedia.org/wiki/資料採掘 "wikilink")。

### 相關實例

  - [GATE: a Java Library for Text Engineering](http://gate.ac.uk/)
  - [LTP:语言技术平台（简体中文）](https://web.archive.org/web/20101222002124/http://ir.hit.edu.cn/demo/ltp/)
  - [MARF](../Page/MARF.md "wikilink")
  - [Python編程語言的自然語言處理工具包教程](http://www.nltk.org/book)
  - [fastNLP](https://github.com/fastnlp/fastNLP)

## 延伸閱讀

  -
  - Steven Bird, Ewan Klein, and Edward Loper (2009). *Natural Language
    Processing with Python*. O'Reilly Media. ISBN 978-0-596-51649-9.

  - Daniel Jurafsky and James H. Martin (2008). *Speech and Language
    Processing*, 2nd edition. Pearson Prentice Hall. ISBN
    978-0-13-187321-6.

  - Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze
    (2008). *Introduction to Information Retrieval*. Cambridge
    University Press. ISBN 978-0-521-86571-5. [Official html and pdf
    versions available without
    charge.](http://nlp.stanford.edu/IR-book/)

  - Christopher D. Manning and Hinrich Schütze (1999). *Foundations of
    Statistical Natural Language Processing*. The MIT Press. ISBN
    978-0-262-13360-9.

  - David M. W. Powers and Christopher C. R. Turk (1989). *Machine
    Learning of Natural Language*. Springer-Verlag. ISBN
    978-0-387-19557-5.

## 外部連結

  - [人類語言技術當前發展情況概覽](https://web.archive.org/web/20100616131036/http://www.cslu.ogi.edu/HLTsurvey/)
  - [哥倫比亞大學自然語言處理研究組](http://www.cs.columbia.edu/nlp/)
  - [卡内基梅隆大学語言技術研究院](http://www.lti.cs.cmu.edu/)
  - [斯坦福大學自然語言處理研究小組](http://nlp.stanford.edu/)
  - [中文自然語言處理開放平臺](http://www.nlp.org.cn/)
  - [ACL（美國電腦語言學協會）提供的相關雜誌以及研討會的論文](https://web.archive.org/web/20040916080945/http://acl.ldc.upenn.edu/)

## 参见

  -
  - [電腦語言學](https://zh.wikipedia.org/wiki/電腦語言學 "wikilink")

  - [受限自然語言](https://zh.wikipedia.org/wiki/受限自然語言 "wikilink")

  - [信息抽取](../Page/信息抽取.md "wikilink")

  - [資訊檢索](https://zh.wikipedia.org/wiki/資訊檢索 "wikilink")

  - [自然語言理解](https://zh.wikipedia.org/wiki/自然語言理解 "wikilink")

  - [潛在語義索引](https://zh.wikipedia.org/wiki/潛在語義索引 "wikilink")

  - [潜在语义学](../Page/潜在语义学.md "wikilink")

  -
  - [機器記者](../Page/機器記者.md "wikilink")

  -
  -
  -
  - [计算语言学](../Page/计算语言学.md "wikilink")

  -
  - [深度学习](https://zh.wikipedia.org/wiki/深度学习 "wikilink")

  -
  -
  -
  -
  - [隐含狄利克雷分布](../Page/隐含狄利克雷分布.md "wikilink")（LDA）

<!-- end list -->

  -
  -
  -
  - [擴展查詢](https://zh.wikipedia.org/wiki/擴展查詢 "wikilink")

  -
  -
  - [语音处理](../Page/语音处理.md "wikilink")

  -
  - [校對](../Page/校對.md "wikilink")

  -
  -
  -
  - [問答系統](../Page/問答系統.md "wikilink")

  - [Word2vec](../Page/Word2vec.md "wikilink")

{{-}}

[Category:人工智能应用](https://zh.wikipedia.org/wiki/Category:人工智能应用 "wikilink")
[Category:自然語言處理](https://zh.wikipedia.org/wiki/Category:自然語言處理 "wikilink")
[Category:人机交互](https://zh.wikipedia.org/wiki/Category:人机交互 "wikilink")
[Category:中文信息处理](https://zh.wikipedia.org/wiki/Category:中文信息处理 "wikilink")

1.
2.  Goldberg, Yoav (2016).
    <https://www.jair.org/media/4992/live-4992-9623-jair.pdf> A Primer
    on Neural Network Models for Natural Language Processing. Journal of
    Artificial Intelligence Research 57 (2016) 345–420
3.  Ian Goodfellow, Yoshua Bengio and Aaron Courville.
    <http://www.deeplearningbook.org/> Deep Learning\]. MIT Press.
4.  Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and
    Yonghui Wu (2016). <https://arxiv.org/abs/1602.02410> Exploring the
    Limits of Language Modeling
5.  Do Kook Choe and Eugene Charniak (EMNLP 2016).
    <http://www.aclweb.org/website/old_anthology/D/D16/D16-1257.pdf>
    Parsing as Language Modeling
6.  Vinyals, Oriol, et al. (NIPS2015).
    <https://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf>
7.  <http://www.lingviko.net/feng/4feature.pdf>
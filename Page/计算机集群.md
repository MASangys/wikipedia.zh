> 本文内容由[计算机集群](https://zh.wikipedia.org/wiki/计算机集群)转换而来。


[MEGWARE.CLIC.jpg](https://zh.wikipedia.org/wiki/File:MEGWARE.CLIC.jpg "fig:MEGWARE.CLIC.jpg")的技术人员在一个大型[Linux](../Page/Linux.md "wikilink")集群上工作\]\] [Sun_Microsystems_Solaris_computer_cluster.jpg](https://zh.wikipedia.org/wiki/File:Sun_Microsystems_Solaris_computer_cluster.jpg "fig:Sun_Microsystems_Solaris_computer_cluster.jpg")

**计算机集群**（）是一组松散或紧密连接在一起工作的[计算机](../Page/電子計算機.md "wikilink")。由于这些计算机协同工作，在许多方面它们可以被视为单个系统。与[网格计算](../Page/网格计算.md "wikilink")机不同，计算机集群将每个设置为执行相同的任务，由软件控制和调度。

集群的组件通常通过快速[局域网](../Page/局域网.md "wikilink")相互连接，每个**节点**（用作服务器的计算机）运行自己的[操作系统](../Page/操作系统.md "wikilink")实例。在大多数情况下，所有节点使用相同的硬件\[1\]和相同的操作系统，尽管在某些设置中（例如使用），可以在每台计算机或不同的硬件上使用不同的操作系统。\[2\]

部署集群通常是为了提高单台计算机的性能和可用性，而集群也通常比速度或可用性相当的单台计算机的成本效益要高。\[3\]

计算机集群的出现是许多计算趋势汇聚的结果，这些趋势包括低成本微处理器、高速网络以及用于高性能[分布式计算](../Page/分布式计算.md "wikilink")软件的广泛使用。集群使用和部署广泛，从小型企业集群到世界上最快[超级电脑](https://zh.wikipedia.org/wiki/超级电脑 "wikilink")（如[IBM的Sequoia](https://zh.wikipedia.org/wiki/红杉_\(超级电脑\) "wikilink")）。\[4\] 在集群出现之前，人们采用具有[模块冗余的单元](https://zh.wikipedia.org/wiki/Triple_modular_redundancy "wikilink")[容错](../Page/故障容許度.md "wikilink")[主机](../Page/大型计算机.md "wikilink")；但是，集群的前期成本较低，网络结构速度提高，这助推了人们采用集群这种方式。与高可靠性的大型机集群相比，扩展成本更低，但也增加了错误处理的复杂性，因为在集群中错误模式对于运行的程序是不透明的。\[5\]

## 基本概念

[Beowulf.jpg](https://zh.wikipedia.org/wiki/File:Beowulf.jpg "fig:Beowulf.jpg")。\]\] 为了通过组合低成本的商用现成计算机，来获得更大的计算能力和更好的可靠性，人们研究提出了各种架构和配置。

计算机集群方法通常通过快速[局域网](../Page/局域网.md "wikilink")连接许多现成的计算节点（例如用作服务器的个人计算机）。\[6\] 计算节点的活动由“集群中间件”协调，集群中间件是一个位于节点之上的软件层，让用户可以将集群视为一个整体的内聚计算单元（例如通过[单系统映像概念](https://zh.wikipedia.org/wiki/单系统映像 "wikilink")）。\[7\]

计算机集群依赖于一种集中管理方法，该方法把节点用作协调的共享服务器。它不同于其他方法（比如[对等计算或](../Page/對等網路.md "wikilink")[网格计算](../Page/网格计算.md "wikilink")），后者也使用许多节点，但具有更多的[分布式特性](../Page/分布式计算.md "wikilink")。\[8\]

计算机集群可能是一个简单的两节点系统，只连接两台个人电脑，也可能是一台速度非常快的[超级计算机](../Page/超级计算机.md "wikilink")。构建集群的基本方法是[贝奥武夫机群](../Page/贝奥武夫机群.md "wikilink")，它可以使用少量个人计算机构建，以产生与传统[高性能计算相比经济划算的替代方案](../Page/超级计算机.md "wikilink")。一个展示概念可行性的早期项目是133节点的[Stone Soupercomputer](https://zh.wikipedia.org/wiki/Stone_Soupercomputer "wikilink")。\[9\] 开发人员使用[Linux](../Page/Linux.md "wikilink")、工具包和[訊息傳遞介面](../Page/訊息傳遞介面.md "wikilink")库以相对较低的成本实现高性能。\[10\]

尽管一个集群可能仅由几台通过简单网络连接的个人计算机组成，但集群架构也可用于实现非常高的性能水平。[TOP500](../Page/TOP500.md "wikilink")组织每半年公布的500台最快[超级计算机](../Page/超级计算机.md "wikilink")的名单通常包括许多集群，例如，2011年世界上最快的机器是“[京](../Page/京_\(超级计算机\).md "wikilink")”，它有和集群架构。\[11\]

## 历史

[缩略图](https://zh.wikipedia.org/wiki/File:SPEC-1_VAX_05.jpg "fig:缩略图")集群 11/780, 拍摄于约1977年\]\] Greg Pfister指出，集群最初不是由特定的供应商发明的，而是由无法在一台计算机上完成所有工作或需要备份的客户发明的。 \[12\] 他估计计算机集群发明于20世纪60年代。 作为并行工作的一种方式，集群计算的正式工程基础可以说是由[IBM](../Page/IBM.md "wikilink")的[吉恩·阿姆達爾](../Page/吉恩·阿姆達爾.md "wikilink")发明的，因为他在1967年出版了被认为是关于并行处理的开创性论文：[阿姆达尔定律](https://zh.wikipedia.org/wiki/阿姆达尔定律 "wikilink")。

早期计算机集群的历史或多或少直接与早期网络的历史有关，因为网络发展的主要动机之一是连接计算资源，创建真正的计算机集群。

第一个被设计成集群的生产系统是20世纪60年代中期的Burroughs ，它允许多达四台计算机（每个计算机都有一个或两个处理器）紧密连接到一个公共磁盘存储系统，以平衡工作负载。与标准的多处理器系统不同，每台计算机都可以在不中断整体运行的情况下重新启动。

第一个商业松散耦合的集群产品是公司的“附加资源计算机”（Attached Resource Computer，ARC）系统，该系统于1977年开发，使用ARCNET作为集群接口。直到[迪吉多](../Page/迪吉多.md "wikilink")电脑公司在1984年为[VAX/VMS操作系统](https://zh.wikipedia.org/wiki/VAX/VMS "wikilink")（现在称为OpenVMS）发布了产品，集群才真正开始。ARC和VAX集群产品不仅支持并行计算，还支持共享[文件系统](../Page/文件系统.md "wikilink")和[外部设备](https://zh.wikipedia.org/wiki/外部设备 "wikilink")。其目的是提供并行处理的优势，同时保持数据的可靠性和唯一性。另外两个值得注意的早期商业集群是（大约1994年出现的高可用性产品）和*IBM S/390 Parallel Sysplex*（也在大约1994年出现，主要用于商业用途）。

同时，当商业网络使用计算机集群在计算机外部的并行性时，超级计算机开始在计算机内部中使用它们。继[CDC 6600在](https://zh.wikipedia.org/wiki/CDC_6600 "wikilink")1964年取得成功之后，也于1976年成功发布，并通过[向量处理引入了内部并行性](../Page/并行向量处理机.md "wikilink")。\[13\] 虽然早期的超级计算机不使用集群而是使用了[共享内存](https://zh.wikipedia.org/wiki/共享内存 "wikilink")，但一些速度最快的超级计算机（如[京](../Page/京_\(超级计算机\).md "wikilink")）最终依赖于集群架构。

## 集群的属性

[Balanceamento_de_carga_(NAT).jpg](https://zh.wikipedia.org/wiki/File:Balanceamento_de_carga_\(NAT\).jpg "fig:Balanceamento_de_carga_(NAT).jpg") 可以根据不同目的配置计算机集群，从一般用途的业务需求（如Web服务支持），到计算密集型的科学计算。在这两种情况下，集群都可以使用[高可用性方法](https://zh.wikipedia.org/wiki/high-availability_cluster "wikilink")。请注意，下面描述的属性并不是排他的，“计算机集群”也可以使用高可用性方法等等。

“[负载均衡](../Page/负载均衡.md "wikilink")”集群是集群节点共享计算工作负载，以提供更好的总体性能的配置。例如，Web服务器集群可以将不同的查询分配给不同的节点，因此总体响应时间将得到优化。\[14\] 然而，负载平衡的方法可能在不同的应用程序之间有很大的不同，例如，用于科学计算的高性能集群的平衡负载算法与Web服务器集群不同，Web服务器集群可能只是使用一种简单的[循环方法](https://zh.wikipedia.org/wiki/循環制 "wikilink")，将每个新请求分配到不同节点。\[15\]

计算机集群用于计算密集型目的，而不是处理[面向IO的操作](https://zh.wikipedia.org/wiki/I/O "wikilink")（如Web服务或数据库）。\[16\] 例如，计算机集群可能支持车祸或天气的[计算模拟](../Page/计算机模拟.md "wikilink")。非常紧密耦合的计算机集群被设计用于可能接近“[超级计算](../Page/超级计算机.md "wikilink")”的工作。

“高可用性集群”提高了集群方法的可用性。它们通过拥有冗余[节点来运行](../Page/节点_\(电信网络\).md "wikilink")，当系统组件出现故障时，这些节点将用于提供服务。高可用性集群实现试图使用集群组件的冗余来消除[单点故障](https://zh.wikipedia.org/wiki/单点故障 "wikilink")。许多操作系统都有高可用性集群的商业实现。[Linux-HA项目是](https://zh.wikipedia.org/wiki/Linux-HA "wikilink")[Linux](../Page/Linux.md "wikilink")操作系统常用的一个[自由软件](../Page/自由软件.md "wikilink")HA包。

## 优点

集群的设计主要考虑性能，但实际使用中还涉及许多其他因素，包括容错（*能够容许系统继续使用故障节点*）能力、[可扩展性](https://zh.wikipedia.org/wiki/可扩展性 "wikilink")、高性能、不需要频繁运行维护程序、资源整合（如[RAID](../Page/RAID.md "wikilink")）和集中管理。集群的优点包括在发生灾难时启用数据恢复、提供并行数据处理和高计算能力。\[17\]\[18\]

在可伸缩性方面，集群提供了水平添加节点的能力。这意味着可以向集群中添加更多的计算机，以提高其性能、冗余和容错。与在集群中扩展单个节点相比，添加节点是一个既节省成本，又可以使集群获得更高的性能的解决方案。计算机集群的这一大特性允许大量性能较低的计算机执行较大的计算负载。

向集群添加新节点时，可靠性也会增加，这是因为进行维护的时候不需要停下整个集群，只需停下单个节点维护，集群的其余节点承担该节点的负载即可。

如果集群包含大量的计算机，那么可以使用[分布式文件系统和](https://zh.wikipedia.org/wiki/分布式文件系统 "wikilink")[RAID](../Page/RAID.md "wikilink")，这两种方法可以大大提高集群的可靠性和速度。

## 设计与配置

[beowulf.png](https://zh.wikipedia.org/wiki/File:beowulf.png "fig:beowulf.png") 设计集群的问题之一是各个节点之间的耦合程度。例如，单个计算机作业可能需要节点之间的频繁通信：这意味着集群共享一个专用网络，位置密集，可能有同类节点。另一个极端是计算机作业使用一个或几个节点，并且需要很少或没有节点间通信，接近[网格计算](../Page/网格计算.md "wikilink")。

在[贝奥武夫机群](../Page/贝奥武夫机群.md "wikilink")中，应用程序从不会看到计算节点（也叫“从属计算机”），只与“主计算机”交互，而“主计算机”是处理从属计算机的调度和管理的特定计算机。\[19\] 在典型的实现中，主计算机具有两个网络接口，一个用于为从属设备与专用贝奥武夫网络通信，另一个用于组织的通用网络。\[20\] 从属计算机通常有同一操作系统、本地内存和磁盘空间的它们自己的版本。但是，专用从属网络还可以有大型共享文件服务器，该服务器存储全局持久数据，从属设备可以根据需要访问这些数据。\[21\]

一个特殊用途的144节点[DEGIMA集群被调整为使用多步行并行树码运行天体物理N体仿真](https://zh.wikipedia.org/wiki/DEGIMA_\(computer_cluster\) "wikilink")，而不是通用的科学计算。\[22\]

由于每一代[游戏机的计算能力不断增强](../Page/電子遊戲機.md "wikilink")，一种新的用途出现了，它们被重新用于[高性能计算](https://zh.wikipedia.org/wiki/High-performance_computing "wikilink")（HPC）集群。游戏机集群的例子有[索尼PlayStation集群和](https://zh.wikipedia.org/wiki/PlayStation_3_cluster "wikilink")[微软](../Page/微软.md "wikilink")[Xbox集群](../Page/Xbox_\(遊戲機\).md "wikilink")。另一个消费类游戏产品的例子是[Nvidia Tesla个人超级计算机工作站](https://zh.wikipedia.org/wiki/Nvidia_Tesla_Personal_Supercomputer "wikilink")，它使用多个图形加速处理器芯片。除了游戏机，也可以使用高端显卡。使用显卡进行网格计算比使用CPU更经济，尽管不太精确。但是，当使用双精度值时，它们变得像CPU一样精确，并且成本更低。\[23\]

计算机集群历来在使用相同[操作系统](../Page/操作系统.md "wikilink")的独立物理[计算机上运行](../Page/電子計算機.md "wikilink")。随着[虛擬化](../Page/虛擬化.md "wikilink")技术的出现，集群节点可以在具有不同操作系统的独立物理计算机上运行，这些操作系统上面绘制了一个虚拟层，使之看起来相似。\[24\] 当进行维护时，集群还可以在各种配置上进行虚拟化。一个示例实现是[Xen](../Page/Xen.md "wikilink")作为[Linux-HA的虚拟化管理器](https://zh.wikipedia.org/wiki/Linux-HA "wikilink")。\[25\]

## 数据共享与通信

### 数据共享

[Nec-cluster.jpg](https://zh.wikipedia.org/wiki/File:Nec-cluster.jpg "fig:Nec-cluster.jpg")的[Nehalem集群](../Page/Nehalem微架構.md "wikilink")\]\] 随着计算机集群在20世纪80年代的出现，[超级计算机](../Page/超级计算机.md "wikilink")也应运而生。早期的超级计算机依赖于[共享内存](https://zh.wikipedia.org/wiki/共享内存 "wikilink")，这是当时这三类计算机的区别之一。迄今为止，集群通常不使用物理共享内存，而许多超级计算机体系结构也放弃了这一点。

不过，在现代计算机集群中，[集群文件系统](../Page/集群文件系统.md "wikilink")的使用是必不可少的。例如、Microsoft的或。

### 消息传递与通信

用于集群节点间通信的两种广泛使用的方法是MPI（[訊息傳遞介面](../Page/訊息傳遞介面.md "wikilink")）和PVM（）。\[26\]

早在1989年MPI出现之前，PVM就在[橡树岭国家实验室](../Page/橡树岭国家实验室.md "wikilink")问世了。PVM必须直接安装在每个集群节点上，并提供一组软件库，将节点描绘成一个“并行虚拟机”。PVM为消息传递、任务和资源管理以及故障通知提供了一个运行时环境。PVM可以由用C、C++或Fortran等语言编写的用户程序使用。\[27\]\[28\]

20世纪90年代初，在40个组织的讨论中产生了MPI。最初的努力得到了[ARPA和](../Page/國防高等研究計劃署.md "wikilink")[国家科学基金会的支持](https://zh.wikipedia.org/wiki/国家科学基金会 "wikilink")。MPI的设计没有重新开始，而是利用了当时商业系统中可用的各种特性。MPI规范催生了具体的实现。MPI实现通常使用[TCP/IP和套接字连接](https://zh.wikipedia.org/wiki/TCP/IP协议族 "wikilink")。\[29\] MPI现在是一种广泛使用的通信模型，它使并行程序能够用[C](https://zh.wikipedia.org/wiki/C语言 "wikilink")、[Fortran](../Page/Fortran.md "wikilink")、[Python](../Page/Python.md "wikilink")等语言编写。\[30\] 因此，与提供具体实现的PVM不同，MPI是已经在诸如[MPICH和](https://zh.wikipedia.org/wiki/MPICH "wikilink")[Open MPI的系统中实现的规范](https://zh.wikipedia.org/wiki/Open_MPI "wikilink")。\[31\]\[32\]

## 集群管理

[Cubieboard_HADOOP_cluster.JPG](https://zh.wikipedia.org/wiki/File:Cubieboard_HADOOP_cluster.JPG "fig:Cubieboard_HADOOP_cluster.JPG")上使用[Apache Hadoop](../Page/Apache_Hadoop.md "wikilink")，低成本、低能耗的[Cubieboard微型集群](https://zh.wikipedia.org/wiki/Cubieboard "wikilink")\]\] 使用计算机集群服务器的挑战之一是管理它的成本，如果集群有N个节点，有时可能高达管理N个独立机器的成本。\[33\] 在某些情况下，这为管理成本较低的[共享内存架构提供了一个优势](https://zh.wikipedia.org/wiki/共享内存 "wikilink")。\[34\] 由于便于管理，这也使得[虚拟机非常流行](../Page/虛擬機器.md "wikilink")。\[35\]

### 任务调度

当大型多用户集群需要访问大量数据时，[任务调度就成为一个挑战](../Page/调度_\(计算机\).md "wikilink")。在具有复杂应用环境的异构CPU-GPU集群中，每项作业的性能取决于底层集群的特性。因此，将任务映射到CPU内核和GPU设备有巨大的挑战。\[36\] 这是一个正在进行的研究领域；结合和扩展[MapReduce](../Page/MapReduce.md "wikilink")和[Hadoop的算法已经被提出和研究](../Page/Apache_Hadoop.md "wikilink")。\[37\]

### 节点故障管理

当集群中的一个节点出现故障时，可以使用诸如“[fencing](https://zh.wikipedia.org/wiki/Fencing_\(computing\) "wikilink")”（隔离）之类的策略来保持系统的其余部分可操作。\[38\]\[39\] Fencing是在节点出现故障时隔离节点或保护共享资源的过程。有两类隔离方法；一类禁用节点本身，另一类禁用对资源（如共享磁盘）的访问。\[40\]

[STONITH方法](https://zh.wikipedia.org/wiki/STONITH "wikilink")（Shoot The Other Node In The Head）是说禁用或关闭可疑的节点。例如，**电源fencing**使用电源控制器来关闭无法操作的节点。\[41\]

**资源fencing**方法不允许在不关闭节点电源的情况下访问资源。这可能包括通过[SCSI3持久保留fencing](https://zh.wikipedia.org/wiki/SCSI3 "wikilink")，禁用[光纤通道端口的光纤通道fencing](https://zh.wikipedia.org/wiki/光纤通道 "wikilink")，或禁用[GNBD服务器访问的GNBD](../Page/网络块设备.md "wikilink") fencing。

## 软件开发和管理

### 并行编程

负载平衡集群（如Web服务器）使用集群架构来支持大量用户，通常每个用户请求都被路由到一个特定的节点，实现无需多节点协作的[任务并行](../Page/任务并行.md "wikilink")，因为系统的主要目标是让用户快速访问共享数据。然而，为少数用户执行复杂计算的"计算机集群"需要利用集群的并行处理能力，在多个节点之间划分"相同的计算"。\[42\]

程序的仍然是一个技术挑战，但是可以通过在不同的处理器上同时执行程序的不同部分来实现更高。\[43\]\[44\]

### 调试和监控

在集群上开发和调试并行程序需要并行语言原语以及合适的工具，例如**高性能调试论坛**（HPDF）所讨论的那些工具，HPD规范就是这样产生的。\[45\]\[46\] 像[TotalView这样的工具是为了在使用](https://zh.wikipedia.org/wiki/Rogue_Wave_Software "wikilink")[MPI或](../Page/訊息傳遞介面.md "wikilink")[PVM进行消息传递的计算机集群上调试并行实现而开发的](https://zh.wikipedia.org/wiki/Parallel_Virtual_Machine "wikilink")。

[Berkeley](../Page/加利福尼亞大學柏克萊分校.md "wikilink") NOW（Network of Workstations）系统收集集群数据并将其存储在数据库中，而在印度开发的PARMON系统允许对大型集群进行可视化观察和管理。\[47\]

当一个节点在长时间的多节点计算中失败时，可以使用来恢复给定的系统状态。\[48\] 这在大型集群中是必不可少的，因为随着节点数量的增加，在繁重的计算负载下节点失败的可能性也会增加。检查点可以将系统恢复到稳定状态，这样处理就可以在不重新计算结果的情况下继续进行。\[49\]

## 一些实现

GNU/Linux世界提供了各种集群软件；对于应用程序集群，有[distcc和](https://zh.wikipedia.org/wiki/distcc "wikilink")[MPICH](https://zh.wikipedia.org/wiki/MPICH "wikilink")。[Linux Virtual Server](../Page/Linux虚拟服务器.md "wikilink"), [Linux-HA等基于导向器的集群](https://zh.wikipedia.org/wiki/Linux-HA "wikilink")，允许传入的服务请求分布在多个集群节点上。[MOSIX](https://zh.wikipedia.org/wiki/MOSIX "wikilink")、[LinuxPMI](https://zh.wikipedia.org/wiki/LinuxPMI "wikilink")、[Kerrighed](https://zh.wikipedia.org/wiki/Kerrighed "wikilink")、[OpenSSI都是集成到](https://zh.wikipedia.org/wiki/OpenSSI "wikilink")[内核](../Page/内核.md "wikilink")中的成熟集群，它们可在同类节点之间自动进行进程迁移。[OpenSSI](https://zh.wikipedia.org/wiki/OpenSSI "wikilink")、[openMosix和](https://zh.wikipedia.org/wiki/openMosix "wikilink")[Kerrighed是](https://zh.wikipedia.org/wiki/Kerrighed "wikilink")[单系统映像实现](https://zh.wikipedia.org/wiki/单系统映像 "wikilink")。

基于[Windows Server平台的](../Page/Windows_Server.md "wikilink")[Microsoft Windows计算机群集Server](https://zh.wikipedia.org/wiki/Microsoft_Windows "wikilink") 2003为高性能计算提供了诸如Job Scheduler、MSMPI库和管理工具。

[gLite是](https://zh.wikipedia.org/wiki/gLite "wikilink")（EGEE）创建的一组中间件技术。

[slurm还用于调度和管理一些最大的超级计算机集群](../Page/Slurm工作调度工具.md "wikilink")（参见top500列表）。

## 其他方法

尽管大多数计算机集群都是永久性的，但是人们已经尝试用来为特定的计算构建短期集群。不过，更大规模的系统（如基于[BOINC](../Page/BOINC.md "wikilink")的系统）的追随者更多。

## 参见

<table style="width:36%;">
<colgroup>
<col style="width: 18%" />
<col style="width: 18%" />
</colgroup>
<tbody>
<tr class="odd">
<td><p>基本概念</p>
<p>:* <a href="../Page/集群文件系统.md" title="wikilink">集群文件系统</a></p>
<p>:* </p>
<p>:* </p>
<p>:* <a href="https://zh.wikipedia.org/wiki/单系统映像" title="wikilink">单系统映像</a></p>
<p>:* <a href="https://zh.wikipedia.org/wiki/对称多处理" title="wikilink">对称多处理</a> 分布式计算</p>
<p>:* <a href="../Page/分布式计算.md" title="wikilink">分布式计算</a></p>
<p>:* <a href="../Page/分散式檔案系統.md" title="wikilink">分散式檔案系統</a></p>
<p>:* <a href="../Page/分布式操作系统.md" title="wikilink">分布式操作系统</a></p>
<p>:* <a href="https://zh.wikipedia.org/wiki/分布式共享存储处理机" title="wikilink">分布式共享存储处理机</a></p></td>
<td><p>具体系统</p>
<p>:* <a href="https://zh.wikipedia.org/wiki/DEGIMA_(computer_cluster)" title="wikilink">DEGIMA (computer cluster)</a></p>
<p>:* <a href="../Page/京_(超级计算机).md" title="wikilink">京 (超级计算机)</a></p>
<p>:* </p>
<p>:* <a href="https://zh.wikipedia.org/wiki/红帽集群套件" title="wikilink">红帽集群套件</a></p>
<p>:* </p>
<p>:* </p>
<p>:* </p>
<p>计算工厂</p>
<p>:* </p>
<p>:* <a href="../Page/著色農場.md" title="wikilink">著色農場</a></p>
<p>:* <a href="../Page/服务器农场.md" title="wikilink">服务器农场</a></p></td>
</tr>
</tbody>
</table>

## 参考资料

## 延伸阅读

  -
  -
  -
  -
  -
## 外部链接

  - [IEEE Technical Committee on Scalable Computing (TCSC)](https://www.ieeetcsc.org/)
  - [Reliable Scalable Cluster Technology, IBM](http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=%2Fcom.ibm.cluster.rsct.doc%2Frsctbooks.html)
  - [Tivoli System Automation Wiki](https://www.ibm.com/developerworks/wikis/display/tivoli/Tivoli+System+Automation)
  - [Large-scale cluster management at Google with Borg](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/43438.pdf), April 2015, by Abhishek Verma, Luis Pedrosa, Madhukar Korupolu, David Oppenheimer, Eric Tune and John Wilkes

[Category:叢集計算](https://zh.wikipedia.org/wiki/Category:叢集計算 "wikilink") [Category:并行计算](https://zh.wikipedia.org/wiki/Category:并行计算 "wikilink") [Category:并发计算](https://zh.wikipedia.org/wiki/Category:并发计算 "wikilink") [Category:超級電腦](https://zh.wikipedia.org/wiki/Category:超級電腦 "wikilink") [Category:局域网](https://zh.wikipedia.org/wiki/Category:局域网 "wikilink") [Category:電腦的類別](https://zh.wikipedia.org/wiki/Category:電腦的類別 "wikilink")

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
36.
37.
38.
39.
40.
41.
42.
43.
44.
45.
46.
47.
48.
49.
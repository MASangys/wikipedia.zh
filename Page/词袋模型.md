> 本文内容由[词袋模型](https://zh.wikipedia.org/wiki/词袋模型)转换而来。


**词袋模型**（）是個在自然語言處理和信息檢索(IR)下被簡化的表達模型。此模型下，一段文本（比如一个句子或是一个文档）可以用一個装着这些词的袋子来表示，這種表示方式不考慮文法以及詞的順序。最近词袋模型也被應用在電腦視覺領域。\[1\]

词袋模型被廣泛應用在文件分類，詞出現的頻率可以用來當作訓練分類器的特徵。

關於"词袋"這個用字的由來可追溯到澤里格·哈里斯於1954年在*Distributional Structure*的文章*。*\[2\]

## 範例

下列文件可用词袋表示:

以下是兩個簡單的文件:

``` text
(1) John likes to watch movies. Mary likes movies too.
```

``` text
(2) John also likes to watch football games.
```

基於以上兩個文件，可以建構出下列清單:

``` javascript
[
    "John",
    "likes",
    "to",
    "watch",
    "movies",
    "also",
    "football",
    "games",
    "Mary",
    "too"
]
```

此處有10個不同的詞，使用清單的索引表示長度為10的向量:

`(1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1] (2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0] `

每個向量的索引內容對應到清單中詞出現的次數。

舉例來說，第一個向量(文件一)前兩個內容索引是1和2，第一個索引內容是"John"對應到清單第一個詞並且該值設定為1，因為"John"出現一次。

此向量表示法不會保存原始句子中詞的順序。該表示法有許多成功的應用，像是郵件過濾。

## Term weighting

在上述的範例，文件向量包含term頻率 。在IR和文字分類常用不同方法量term權重。常見方法為tf-idf。

## 範例:垃圾郵件過濾

分類一個郵件訊息，分類一個貝氏垃圾郵件分類假設訊息是一堆字並且隨機倒在兩堆袋子其中一個袋子裡，之後使用貝氏機率去決定哪個袋子是較有可能的。

## 参考文献

## 參見

  -
  - [n元语法](https://zh.wikipedia.org/wiki/n元语法 "wikilink")

  - [向量空間模型](../Page/向量空間模型.md "wikilink")

  - [自然語言處理](../Page/自然语言处理.md "wikilink")

  -
  - [文件分類](https://zh.wikipedia.org/wiki/文件分類 "wikilink")

  - [機器學習](../Page/机器学习.md "wikilink")

  -
  -
  - [最小哈希](../Page/最小哈希.md "wikilink")

  - [特徵擷取](https://zh.wikipedia.org/wiki/特徵擷取 "wikilink")

{{-}}

[Category:自然語言處理](https://zh.wikipedia.org/wiki/Category:自然語言處理 "wikilink") [Category:机器学习](https://zh.wikipedia.org/wiki/Category:机器学习 "wikilink")

1.
2.
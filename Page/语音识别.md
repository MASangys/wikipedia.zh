> 本文内容由[语音识别](https://zh.wikipedia.org/wiki/语音识别)转换而来。


**语音识别**（speech recognition）技术，也被称为**自动语音识别**（）、**電腦語音識別**（）或是**語音轉文本識別（****）**，其目标是以電腦自動将人类的语音内容转换为相應的文字。与及[说话人确认不同](https://zh.wikipedia.org/wiki/说话人确认 "wikilink")，后者尝试识别或确认发出语音的说话人而非其中所包含的词汇内容。

语音识别技术的应用包括语音拨号、语音导航、室内设备控制、[语音文档检索](https://zh.wikipedia.org/wiki/语音文档检索 "wikilink")、简单的听写数据录入等。语音识别技术与其他[自然语言处理](../Page/自然语言处理.md "wikilink")技术如[机器翻译](../Page/机器翻译.md "wikilink")及[语音合成](../Page/语音合成.md "wikilink")技术相结合，可以构建出更加复杂的应用，例如语音到语音的翻译。\[1\]

语音识别技术所涉及的领域包括：[信号处理](https://zh.wikipedia.org/wiki/信号处理 "wikilink")、[模式识别](../Page/模式识别.md "wikilink")、[概率论和](https://zh.wikipedia.org/wiki/概率论 "wikilink")[信息论](../Page/信息论.md "wikilink")、发声机理和听觉机理、[人工智能](../Page/人工智能.md "wikilink")等等。

## 历史

早在[计算机发明之前](https://zh.wikipedia.org/wiki/计算机 "wikilink")，自动语音识别的设想就已经被提上了议事日程，早期的[声码器可被视作语音识别及合成的雏形](https://zh.wikipedia.org/wiki/声码器 "wikilink")。而1920年代生产的"Radio Rex"玩具狗是最早的语音识别器，当这只狗的名字被呼唤的时候，它能够从底座上弹出来\[2\]。最早的基于电子计算机的语音识别系统是由AT\&T贝尔实验室开发的Audrey语音识别系统，它能够识别10个英文数字。其识别方法是跟踪语音中的[共振峰](../Page/共振峰.md "wikilink")。该系统得到了98%的正确率。\[3\]。到1950年代末，伦敦学院(Colledge of London)的Denes已经将语法概率加入语音识别中。

1960年代，人工神经网络被引入了语音识别。这一时代的两大突破是[线性预测编码](../Page/线性预测编码.md "wikilink") (LPC)， 及[动态时间规整](https://zh.wikipedia.org/wiki/动态时间规整 "wikilink")技术。

语音识别技术的最重大突破是[隐含马尔科夫模型](https://zh.wikipedia.org/wiki/隐含马尔科夫模型 "wikilink")的应用。从Baum提出相关数学推理，经过Rabiner等人的研究，[卡内基梅隆大学的](https://zh.wikipedia.org/wiki/卡内基梅隆大学 "wikilink")[李开复最终实现了第一个基于隐马尔科夫模型的大词汇量语音识别系统Sphinx](https://zh.wikipedia.org/wiki/李开复 "wikilink")\[4\]。此后严格来说语音识别技术并没有脱离HMM框架。

尽管多年来研究人员一直尝试将“听写机”推广，语音识别技术在目前还无法支持无限领域，无限说话人的听写机应用。

## 模型

目前，主流的大词汇量语音识别系统多采用统计模式识别技术。典型的基于统计模式识别方法的语音识别系统由以下几个基本模块所构成：

  - 信号处理及特征提取模块。该模块的主要任务是从输入信号中提取特征，供声学模型处理。同时，它一般也包括了一些信号处理技术，以尽可能降低环境噪声、信道、说话人等因素对特征造成的影响。
  - [声学模型](../Page/声学模型.md "wikilink")。典型系统多采用基于一阶隐马尔科夫模型进行建模。
  - [发音词典](https://zh.wikipedia.org/wiki/发音词典 "wikilink")。发音词典包含系统所能处理的词汇集及其发音。发音词典实际提供了声学模型建模单元与语言模型建模单元间的映射。
  - [语言模型](https://zh.wikipedia.org/wiki/语言模型 "wikilink")。语言模型对系统所针对的语言进行建模。理论上，包括正则语言，上下文无关文法在内的各种语言模型都可以作为语言模型，但目前各种系统普遍采用的还是基于统计的[N元文法及其变体](https://zh.wikipedia.org/wiki/N元文法 "wikilink")。
  - [解码器](https://zh.wikipedia.org/wiki/解码器 "wikilink")。解码器是语音识别系统的核心之一，其任务是对输入的信号，根据声学、语言模型及词典，寻找能够以最大概率输出该信号的词串。

从数学角度可以更加清楚的了解上述模块之间的关系。首先，统计语音识别的最基本问题是，给定输入信号或特征序列\(O= \{O_1, O_2, \cdots O_n\}\)，符号集（词典）\(\mathcal{W} = \{W_1,W_2,\cdots, W_n\}\)，求解符号串\(W=W_1,W_2,\cdots,W_k\)使得：

\[W = \arg\max P(W|O)\]

通过[贝叶斯公式](https://zh.wikipedia.org/wiki/贝叶斯公式 "wikilink")，上式可以改写为

\[W = \arg\max \frac{P(O|W)P(W)}{P(O)}\]

由于对于确定的输入串\(O\)，\(P(O)\)是确定的，因此省略它并不会影响上式的最终结果，因此，一般来说语音识别所讨论的问题可以用下面的公式来表示，可以将它称为语音识别的基本公式。 \(W = \arg\max P(O|W)P(W)\)

从这个角度来看，信号处理模块提供了对输入信号的预处理，也就是说，提供了从采集的语音信号(记为\(S\))到 特征序列\(O\)的映射\(\mathcal{O}:S\rightarrow O\)。而声学模型本身定义了一些更具推广性的声学建模单元\(\mathcal{\mu}=\{u_1,u_2,\cdots,u_m\}\)，并且提供了在给定输入特征下，估计\(P(O|u_k)\)的方法。

为了将声学模型建模单元串\(U=u_1,u_2,\cdots,u_l\)映射到符号集\(\mathcal{W}\)，就需要发音词典发挥作用。它实际上定义了映射\(\mathcal{D}:w\in\mathcal{W}\rightarrow U\)的映射。为了表示方便，也可以定义一个由\(\mathcal{W}\)到\(U\)的全集\(\mathcal{U}\)的笛卡尔积，而发音词典\(\mathcal{D}\)则是这个笛卡尔积的一个子集。并且有：

\[P(W,U) = \left\{ {\begin{array}{*{20}c}  {1,(W,U) \in D}  \\   {0,(W,U) \notin D}  \\ \end{array}} \right.\] 最后，语言模型则提供了\(P(W)\)。这样，基本公式就可以更加具体的写成：

\[W = \arg\max P(W)\cdot P(W,U)\cdot \prod_{u_i\in U}P(O|u_i)\]

对于解码器来说，就是要在由\(\mathcal{W}\),\(\mathcal{\mu}\),\(u_i\)以及时间标度\(t\)张成的搜索空间中，找到上式所指明的\(W\)。

## 系统构成

### 声学特征

声学特征的提取与选择是语音识别的一个重要环节。声学特征的提取既是一个信息大幅度压缩的过程，也是一个信号解卷过程，目的是使模式划分器能更好地划分。

由于语音信号的时变特性，特征提取必须在一小段语音信号上进行，也即进行短时分析。这一段被认为是平稳的分析区间称之为帧，帧与帧之间的偏移通常取帧长的1/2或1/3。通常要对信号进行预加重以提升高频，对信号加窗以避免短时语音段边缘的影响。

#### 常用的一些声学特征

  - [线性预测系数](https://zh.wikipedia.org/wiki/线性预测系数 "wikilink")（Linear Predictive Coefficient，LPC）：线性预测分析从人的发声机理入手，通过对声道的短管级联模型的研究，认为系统的传递函数符合全极点数字滤波器的形式，从而n时刻的信号可以用前若干时刻的信号的线性组合来估计。通过使实际语音的采样值和线性预测采样值之间达到均方差最小LMS，即可得到线性预测系数LPC。对LPC的计算方法有自相关法（德宾Durbin法）、协方差法、格型法等等。计算上的快速有效保证了这一声学特征的广泛使用。与LPC这种预测参数模型类似的声学特征还有线谱对LSP、反射系数等等。

<!-- end list -->

  - [倒谱系数](https://zh.wikipedia.org/wiki/倒谱系数 "wikilink")：利用同态处理方法，对语音信号求离散傅立叶变换DFT后取对数，再求反变换iDFT就可得到倒谱系数。对LPC倒谱（LPCCEP），在获得滤波器的线性预测系数后，可以用一个递推公式计算得出。实验表明，使用倒谱可以提高特征参数的稳定性。

<!-- end list -->

  - [梅尔频率倒谱系数](../Page/梅尔频率倒谱系数.md "wikilink")（Mel-Frequency Cepstral Coefficients，MFCCs）和[感知线性预测](https://zh.wikipedia.org/wiki/感知线性预测 "wikilink")（Perceptual Linear Predictive，PLP）：不同于LPC等通过对人的发声机理的研究而得到的声学特征，Mel倒谱系数MFCC和感知线性预测PLP是受人的听觉系统研究成果推动而导出的声学特征。对人的听觉机理的研究发现，当两个频率相近的音调同时发出时，人只能听到一个音调。临界带宽指的就是这样一种令人的主观感觉发生突变的带宽边界，当两个音调的频率差小于临界带宽时，人就会把两个音调听成一个，这称之为屏蔽效应。Mel刻度是对这一临界带宽的度量方法之一。

MFCC的计算首先用[FFT将](https://zh.wikipedia.org/wiki/FFT "wikilink")[时域信号转化成](https://zh.wikipedia.org/wiki/时域 "wikilink")[频域](https://zh.wikipedia.org/wiki/频域 "wikilink")，之后对其对数能量谱用依照Mel刻度分布的三角[滤波器组进行](https://zh.wikipedia.org/wiki/滤波器 "wikilink")[卷积](../Page/卷积.md "wikilink")，最后对各个滤波器的输出构成的向量进行[离散余弦变换](../Page/离散余弦变换.md "wikilink")DCT，取前N个系数。PLP仍用德宾法去计算LPC参数，但在计算[自相关参数时用的也是对听觉激励的对数能量谱进行DCT的方法](https://zh.wikipedia.org/wiki/自相关 "wikilink")。

#### 中文聲學特徵

以國語發音為例，我們會將一個字的發音切割成兩個部分，分別是聲母(initials)與韻母(finals)。而在發音的過程之中，聲母轉變至韻母是一個漸進而非瞬間的改變，因此我使用右文相關聲韻母模式（Right-Context-Dependent Initial Final, RCDIF）作為分析方法，可以更精準的辨識出正確的音節（syllable）。

而根據聲母的不同特徵，又可以將聲母分為下面四類：[缩略图](https://zh.wikipedia.org/wiki/File:Plosive.png "fig:缩略图")

  - [爆破音(Plosive)](https://zh.wikipedia.org/wiki/爆破音\(Plosive\) "wikilink")：

發音時嘴唇緊閉後，吐出氣流製造出類似爆破的聲音。其聲音震幅變化會先降至極小值後（代表嘴唇緊閉）後在急劇上升，而端視是否有持續送氣，倘若有持續送氣（aspirated），則震幅可能會有另一個波峰，若無（un-aspirated ）則在波峰之後，震幅將有所下降。如：ㄆ與ㄅ便是前述的關係，ㄆ有持續送氣，而ㄅ則無。右圖左為ㄅ，右圖右為ㄆ。

  - [摩擦音（Fricative）](https://zh.wikipedia.org/wiki/摩擦音（Fricative） "wikilink")：

發音時，舌頭緊貼硬顎，形成狹窄的通道，氣流通過時造成湍流發生摩擦，由此發出聲響。由於摩擦音是透過穩定輸出氣流，使得聲音震幅變化相較於爆破音變化幅度較小。如ㄏ、ㄒ 等皆為摩擦音。

  - [爆擦音（Affricate）](https://zh.wikipedia.org/wiki/爆擦音（Affricate） "wikilink")：

此類型的發聲模型兼具爆破音與摩擦音的發聲特性。其主要發聲構造如同摩擦音是由舌頭緊貼硬顎使氣流通過時產生摩擦的聲音。而其通道更加緊密，使得氣流會在瞬間衝出，產生出如同爆破音般的特徵。如：ㄑ 、ㄔ等。

  - [鼻音（Nasal）](https://zh.wikipedia.org/wiki/鼻音（Nasal） "wikilink")：

[缩略图](https://zh.wikipedia.org/wiki/File:Nasal.png "fig:缩略图") 發音時，軟顎會下壓，下壓後，由氣管吐出的氣流被阻塞，無法進入口腔，因而轉往鼻腔。也因此鼻腔與口腔會產生共振，如右圖的時頻譜上可以明顯地看到零點(formants)分佈有共振的現象，而這樣的共振現象在右文相關聲韻母模式（Right-Context-Dependent Initial Final, RCDIF）下與韻母倆相對較下更加明顯。因此，此一現象可作為辨識鼻音（Nasal）的重要依據之一。右圖便為鼻音ㄋ之特徵，其中紅點便為零點（formants）

而韻母又有雙母音、單母音之分，端視再發生時是否有音調的改變。而根據聲帶振動與否，又分為清音（unvoiced：聲帶不震動）等差異，以上發音時不同的方式，在時頻圖上大多可以找到相對應的特徵，透過處理二維的時頻圖，藉由傳統影像處理的方式，達到語音辨識的目的。

### 声学模型

语音识别系统的模型通常由声学模型和语言模型两部分组成，分别对应于语音到[音节概率的计算和音节到字概率的计算](https://zh.wikipedia.org/wiki/音节 "wikilink")。本节和下一节分别介绍声学模型和语言模型方面的技术。

HMM声学建模：[马尔可夫模型的概念是一个离散时域](https://zh.wikipedia.org/wiki/马尔可夫 "wikilink")[有限状态自动机](https://zh.wikipedia.org/wiki/有限状态自动机 "wikilink")，[隐马尔可夫模型](../Page/隐马尔可夫模型.md "wikilink")HMM是指这一马尔可夫模型的内部状态外界不可见，外界只能看到各个时刻的输出值。对语音识别系统，输出值通常就是从各个帧计算而得的声学特征。用HMM刻画语音信号需作出两个假设，一是内部状态的转移只与上一状态有关，另一是输出值只与当前状态（或当前的状态转移）有关，这两个假设大大降低了模型的复杂度。HMM的评估、解码和训练相应的算法是前向算法、Viterbi算法和前向后向算法。

语音识别中使用HMM通常是用从左向右单向、带自环、带跨越的[拓扑结构来对识别基元建模](https://zh.wikipedia.org/wiki/拓扑结构 "wikilink")，一个音素就是一个三至五状态的HMM，一个词就是构成词的多个音素的HMM串行起来构成的HMM，而连续语音识别的整个模型就是词和静音组合起来的HMM。 上下文相关建模：协同发音，指的是一个音受前后相邻音的影响而发生变化，从发声机理上看就是人的发声器官在一个音转向另一个音时其特性只能渐变，从而使得后一个音的频谱与其他条件下的频谱产生差异。上下文相关建模方法在建模时考虑了这一影响，从而使模型能更准确地描述语音，只考虑前一音的影响的称为Bi-Phone，考虑前一音和后一音的影响的称为Tri-Phone。

英语的上下文相关建模通常以音素为基元，由于有些音素对其后音素的影响是相似的，因而可以通过音素解码状态的[聚类进行模型参数的共享](https://zh.wikipedia.org/wiki/聚类 "wikilink")。聚类的结果称为senone。[决策树](../Page/决策树.md "wikilink")用来实现高效的triphone对senone的对应，通过回答一系列前后音所属类别（元/辅音、清/浊音等等）的问题，最终确定其HMM状态应使用哪个senone。[分类回归树CART模型用以进行词到音素的发音标注](https://zh.wikipedia.org/wiki/分类回归树 "wikilink")。

### 语言模型

语言模型主要分为[规则模型和](https://zh.wikipedia.org/wiki/规则模型 "wikilink")[统计模型两种](https://zh.wikipedia.org/wiki/统计模型 "wikilink")。统计语言模型是用概率统计的方法来揭示语言单位内在的统计规律，其中[n元语法简单有效](https://zh.wikipedia.org/wiki/n元语法 "wikilink")，被广泛使用。

n元语法：该模型基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。由于计算量太大，N一般取值不会很大，常用的是[二元语法](https://zh.wikipedia.org/wiki/二元语法 "wikilink")（Bi-Gram）和三元语法（Tri-Gram）。

语言模型的性能通常用交叉[熵和复杂度](../Page/熵_\(信息论\).md "wikilink")（Perplexity）来衡量。交叉熵的意义是用该模型对文本识别的难度，或者从压缩的角度来看，每个词平均要用几个位来编码。复杂度的意义是用该模型表示这一文本平均的分支数，其倒数可视为每个词的平均概率。平滑是指对没观察到的N元组合赋予一个概率值，以保证词序列总能通过语言模型得到一个概率值。通常使用的平滑技术有[图灵估计](../Page/图灵估计.md "wikilink")、删除插值平滑、[Katz平滑和Kneser](https://zh.wikipedia.org/wiki/Katz平滑 "wikilink")-Ney平滑。

### 搜索

连续语音识别中的搜索，就是寻找一个词模型序列以描述输入语音信号，从而得到词解码序列。搜索所依据的是对公式中的声学模型打分和语言模型打分。在实际使用中，往往要依据经验给语言模型加上一个高权重，并设置一个长词惩罚分数。

Viterbi：基于动态规划的Viterbi算法在每个时间点上的各个状态，计算解码状态序列对观察序列的[后验概率](../Page/后验概率.md "wikilink")，保留概率最大的路径，并在每个节点记录下相应的状态信息以便最后反向获取词解码序列。Viterbi算法在不丧失最优解的条件下，同时解决了连续语音识别中HMM模型状态序列与声学观察序列的非线性时间对准、词边界检测和词的识别，从而使这一算法成为语音识别搜索的基本策略。

由于语音识别对当前时间点之后的情况无法预测，基于目标函数的启发式剪枝难以应用。由于Viterbi算法的时齐特性，同一时刻的各条路径对应于同样的观察序列，因而具有可比性，束Beam搜索在每一时刻只保留概率最大的前若干条路径，大幅度的剪枝提高了搜索的效率。这一时齐Viterbi-Beam算法是当前语音识别搜索中最有效的算法。 N-best搜索和多遍搜索：为在搜索中利用各种知识源，通常要进行多遍搜索，第一遍使用代价低的知识源，产生一个候选列表或词候选网格，在此基础上进行使用代价高的知识源的第二遍搜索得到最佳路径。此前介绍的知识源有声学模型、语言模型和音标词典，这些可以用于第一遍搜索。为实现更高级的语音识别或口语理解，往往要利用一些代价更高的知识源，如4阶或5阶的N-Gram、4阶或更高的上下文相关模型、词间相关模型、分段模型或语法分析，进行重新打分。最新的实时大词表连续语音识别系统许多都使用这种多遍搜索策略。

N-best搜索产生一个候选列表，在每个节点要保留N条最好的路径，会使计算复杂度增加到N倍。简化的做法是只保留每个节点的若干词候选，但可能丢失次优候选。一个折衷办法是只考虑两个词长的路径，保留k条。词候选网格以一种更紧凑的方式给出多候选，对N-best搜索算法作相应改动后可以得到生成候选网格的算法。

前向后向搜索算法是一个应用多遍搜索的例子。当应用简单知识源进行了前向的Viterbi搜索后，搜索过程中得到的前向概率恰恰可以用在后向搜索的目标函数的计算中，因而可以使用启发式的A算法进行后向搜索，经济地搜索出N条候选。

### 系统实现

语音识别系统选择识别基元的要求是，有准确的定义，能得到足够数据进行训练，具有一般性。英语通常采用上下文相关的音素建模，汉语的协同发音不如英语严重，可以采用音节建模。系统所需的训练数据大小与模型复杂度有关。模型设计得过于复杂以至于超出了所提供的训练数据的能力，会使得性能急剧下降。

听写机：大词汇量、非特定人、连续语音识别系统通常称为听写机。其架构就是建立在前述声学模型和语言模型基础上的HMM拓扑结构。训练时对每个基元用前向后向算法获得模型参数，识别时，将基元串接成词，词间加上静音模型并引入语言模型作为词间转移概率，形成循环结构，用Viterbi算法进行解码。针对汉语易于分割的特点，先进行分割再对每一段进行解码，是用以提高效率的一个简化方法。

对话系统：用于实现人机口语对话的系统称为对话系统。受目前技术所限，对话系统往往是面向一个狭窄领域、词汇量有限的系统，其题材有旅游查询、订票、[数据库](../Page/数据库.md "wikilink")检索等等。其前端是一个语音识别器，识别产生的N-best候选或词候选网格，由语法分析器进行分析获取语义信息，再由对话管理器确定应答信息，由语音合成器输出。由于目前的系统往往词汇量有限，也可以用提取关键词的方法来获取语义信息。

### 自适应与強健性

语音识别系统的性能受许多因素的影响，包括不同的说话人、说话方式、环境噪音、传输信道等等。提高系统強健性，是要提高系统克服这些因素影响的能力，使系统在不同的应用环境、条件下性能稳定；[自适应的目的](https://zh.wikipedia.org/wiki/自適應控制 "wikilink")，是根据不同的影响来源，自动地、有针对性地对系统进行调整，在使用中逐步提高性能（其中以李开复博士的不特定语音识别系统为例）。以下对影响系统性能的不同因素分别介绍解决办法。

解决办法按针对语音特征的方法（以下称特征方法）和模型调整的方法（以下称模型方法）分为两类。前者需要寻找更好的、高強健性的特征参数，或是在现有的特征参数基础上，加入一些特定的处理方法。后者是利用少量的自适应语料来修正或变换原有的说话人无关（SI）模型，从而使其成为说话人自适应（SA）模型。

说话人自适应的特征方法有说话人规一化和说话人子空间法，模型方法有[贝叶斯方法](https://zh.wikipedia.org/wiki/貝葉斯推斷 "wikilink")、变换法和模型合并法。

语音系统中的噪声，包括环境噪声和录音过程加入的电子噪声。提高系统[鲁棒性的特征方法包括语音增强和寻找对噪声干扰不敏感的特征](https://zh.wikipedia.org/wiki/健壮性_\(计算机科学\) "wikilink")，模型方法有并行模型组合PMC方法和在训练中人为加入噪声。信道畸变包括录音时话筒的距离、使用不同灵敏度的话筒、不同增益的前置放大和不同的滤波器设计等等。特征方法有从倒谱矢量中减去其长时平均值和RASTA滤波，模型方法有倒谱平移。

#### 最大后验概率

最大後驗機率估計是後驗機率分布的眾數。利用最大後驗機率估計可以獲得對實驗數據中無法直接觀察到的量的點估計。它與最大似然估計中的經典方法有密切關係，但是它使用了一個增廣的優化目標，進一步考慮了被估計量的先驗機率分布。所以最大後驗機率估計可以看作是規則化的最大似然估計。

以此為基礎的自適性方法有以下特性：

  - 越大的調整測資（adaptation data）可以讓結果越接近理想的客製化模型
  - 當調整測資（adaptation data）不足時，無法顯著提升模型的精準度

#### 最大似然線性回歸

最大似然線性回歸（Maximum Likelihood Linear Regression(MLLR) ）是一種基於詞網的最大似然線性回歸(Lattice-MLLR)無監督自適應算法,並進行了改進。是一種基於變換的方法，對數據量依賴較小，常用於數據量較少的情況或進行快速自適應。

一種基於詞網的最大似然線性回歸(Lattice-MLLR)無監督自適應算法,並進行了改進。 Lattice-MLLR是根據解碼得到的詞網估計MLLR變換參數,詞網的潛在誤識率遠小於識別結果,因此可以使參數估計更為準確。 Lattice-MLLR的一個很大的缺點是計算量極大,較難實用。MLLR 是一種基於變換的方法，對數據量依賴較小，常用於數據量較少的情況或進行快速自適應。

以此為基礎的自適性方法有以下特性：

  - 在少量的調整測資（adaptation data）可以顯著提升模型的精準度
  - 當調整測資（adaptation data）達到一定量後，精準度的提升會進入飽和狀態，有明顯的效率上界

而最大似然線性回歸（Maximum Likelihood Linear Regression(MLLR) ）也有許多變形。其中區塊對角最大似然線性回歸（block-diagonal Maximum Likelihood Linear Regression(MLLR)）可以再更少量的調整測資下提升更大的精準度，然而其進入準度的飽和狀態也更快，精準度上限也更低。

綜合以上，端視調整測資（adaptation data）的多寡，可以選擇適當的方法，讓模型的精準度最高。

## 参见

  - [圖模式](../Page/圖模式.md "wikilink")
  - [马尔可夫链](../Page/马尔可夫链.md "wikilink")
  - [马尔可夫逻辑网络](../Page/马尔可夫逻辑网络.md "wikilink")

## 参考文献

<div class="references-small">

<references />

</div>

## 外部链接

  - [1](http://cmusphinx.sourceforge.net/html/cmusphinx.php) - CMU Sphinx 最早的语音识别软件
  - [2](http://htk.eng.cam.ac.uk/) - HTK 由剑桥大学开发的一套完备的语音识别系统
  - [simon](http://sourceforge.net/projects/speech2text/) - 一个开源的语音识别软件
  - [3](http://dev.hcicloud.com) - 灵云开发者社区，提供免费及商用的语音识别SDK

{{-}}

[Category:语音识别](https://zh.wikipedia.org/wiki/Category:语音识别 "wikilink")

1.  [語音輸入法](https://zh.wikipedia.org/wiki/語音輸入法 "wikilink")
2.  5.1 Automatic Speech Recognition (ASR) History, www.icsi.berkeley.edu/eecs225d/spr95/lecture05.ps.gz
3.  Davis, Biddulph and Balashek Automatic Recognition of Spoken Digits, Journal of the Acoustical Society of America Vol 24 No 6, November 1952
4.  Automatic Speech Recognition: The Development of the Sphinx Recognition System KF Lee, R Reddy - 1988 - Kluwer Academic Publishers Norwell, MA, USA
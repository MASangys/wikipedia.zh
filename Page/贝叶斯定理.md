**貝葉斯定理**（）是[概率論中的一個](https://zh.wikipedia.org/wiki/概率論 "wikilink")[定理](../Page/定理.md "wikilink")，描述在已知一些条件下，某事件的发生概率。比如，如果已知某癌症与寿命有关，使用贝叶斯定理则可以通过得知某人年龄，来更加准确地计算出他罹患癌症的概率。

通常，事件A在事件B已發生的條件下发生的概率，與事件B在事件A已發生的條件下发生的概率是不一樣的。然而，這兩者是有確定的關系的，貝葉斯定理就是這種關系的陳述。貝葉斯公式的一個用途，即通過已知的三個概率而推出第四個概率。贝叶斯定理跟[隨機變量的](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")[條件概率以及](https://zh.wikipedia.org/wiki/條件概率 "wikilink")[邊緣概率分布有關](https://zh.wikipedia.org/wiki/聯合分布 "wikilink")。

作為一個普遍的原理，貝葉斯定理對於所有概率的解釋是有效的。这一定理的主要应用为[贝叶斯推断](../Page/贝叶斯推断.md "wikilink")，是[推论统计学中的一种推断法](https://zh.wikipedia.org/wiki/推论统计学 "wikilink")。这一定理名稱來自於[托馬斯·-{貝葉斯}-](https://zh.wikipedia.org/wiki/托馬斯·貝葉斯 "wikilink")。

## 陈述

[Bayes'_Theorem_2D.svg](https://zh.wikipedia.org/wiki/File:Bayes'_Theorem_2D.svg "fig:Bayes'_Theorem_2D.svg")

贝叶斯定理是关于随机事件A和B的[条件概率的一則定理](../Page/条件概率.md "wikilink")。

其中P(A|B)是指在事件B发生的情况下事件A发生的概率。

在贝叶斯定理中，每个名词都有约定俗成的名称：

  - P(*A*|*B*)是已知B發生后A的[條件概率](https://zh.wikipedia.org/wiki/條件概率 "wikilink")，也由于得自B的取值而被稱作A的[后驗概率](https://zh.wikipedia.org/wiki/后驗概率 "wikilink")。
  - P(*A*)是A的[先驗概率](https://zh.wikipedia.org/wiki/先驗概率 "wikilink")（或[边缘概率](https://zh.wikipedia.org/wiki/边缘概率 "wikilink")）。之所以稱為"先驗"是因為它不考慮任何B方面的因素。
  - P(*B*|*A*)是已知A發生后B的條件概率，也由于得自A的取值而被稱作B的[后驗概率](https://zh.wikipedia.org/wiki/后驗概率 "wikilink")。
  - P(*B*)是B的[先驗概率](https://zh.wikipedia.org/wiki/先驗概率 "wikilink")。

按這些術語，贝叶斯定理可表述為：

  -
    后驗概率 = (似然性\*先驗概率)/標准化常量

也就是說，后驗概率与先驗概率和相似度的乘積成正比。

另外，比例P(*B*|*A*)/P(*B*)也有時被稱作標准似然度（），贝叶斯定理可表述為：

  -
    后驗概率 = 標准似然度\*先驗概率

## 從條件概率推導貝氏定理

根據[條件概率的定義](https://zh.wikipedia.org/wiki/條件概率 "wikilink")。在事件*B*发生的条件下事件*A*发生的概率是\[1\]：

\[P(A|B)=\frac{P(A \cap B)}{P(B)}\]。

其中 *A*与*B*的联合概率表示为\(P(A \cap B)\)或者\(P(A, B)\)或者\(P(AB)\)。

同樣地，在事件*A*发生的条件下事件*B*发生的概率

\[P(B|A) = \frac{P(A \cap B)}{P(A)}. \!\]

整理与合并這兩個方程式，我們可以得到

\[P(A|B)\, P(B) = P(A \cap B) = P(B|A)\, P(A). \!\]

这个引理有时称作概率乘法规则。上式兩邊同除以P(*B*)，若P(*B*)是非零的，我們可以得到贝叶斯定理:

\[P(A|B) = \frac{P(B|A)\,P(A)}{P(B)}. \!\]

## 二中擇一的形式

貝氏定理通常可以再寫成下面的形式：

\[P(B) = P(A, B) + P(A^C, B) = P(B|A) P(A) + P(B|A^C) P(A^C)\]，

其中*A*<sup>*C*</sup>是A的[補集](https://zh.wikipedia.org/wiki/補集 "wikilink")（即非A）。故上式亦可寫成：

\[P(A|B) = \frac{P(B | A)\, P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)} \!\]

在更一般化的情況，假設{*A*<sub>*i*</sub>}是事件集合裡的部份集合，對於任意的*A*<sub>*i*</sub>，貝氏定理可用下式表示：

\[P(A_i|B) = \frac{P(B | A_i)\, P(A_i)}{\sum_j P(B|A_j)\,P(A_j)}  \!\]

### 以可能性與相似率表示貝氏定理

貝氏定理亦可由[相似率Λ和](https://zh.wikipedia.org/wiki/相似率 "wikilink")[可能性](https://zh.wikipedia.org/wiki/可能性 "wikilink")*O*表示：

\[O(A|B)=O(A) \cdot \Lambda (A|B)\]

其中

\[O(A|B)=\frac{P(A|B)}{P(A^C|B)} \!\]

定義為B發生時，A發生的可能性（）；

\[O(A)=\frac{P(A)}{P(A^C)} \!\]

則是A發生的可能性。相似率（Likelihood ratio）則定義為：

\[\Lambda (A|B) = \frac{L(A|B)}{L(A^C|B)} = \frac{P(B|A)}{P(B|A^C)} \!\]

### 貝氏定理與概率密度

貝氏定理亦可用於連續機率分佈。由於[機率密度函數嚴格上並非機率](../Page/機率密度函數.md "wikilink")，由機率密度函數導出貝氏定理觀念上較為困難（詳細推導參閱\[2\]）。貝氏定理與機率密度的關係是由求極限的方式建立：

\[f(x|y) = \frac{f(x,y)}{f(y)} = \frac{f(y|x)\,f(x)}{f(y)} \!\]

全機率定理則有類似的論述：

\[f(x|y) = \frac{f(y|x)\,f(x)}{\int_{-\infty}^{\infty} f(y|x)\,f(x)\,dx}.
\!\]

如同離散的情況，公式中的每項均有名稱。 *f*(*x*, *y*)是*X*和*Y*的聯合分佈；
*f*（*x*|*y*）是給定*Y*=*y*後，*X*的後驗分佈； *f*（*y*|*x*）=
*L*（*x*|*y*）是*Y*=*y*後，*X*的相似度函數（為*x*的函數)；
*f*（*x*）和*f*（*y*）則是*X*和*Y*的邊際分佈；
*f*（*x*）則是*X*的先驗分佈。
為了方便起見，這裡的*f*在這些專有名詞中代表不同的函數（可以由引數的不同判斷之）。

### 貝氏定理的推廣

對於變數有二個以上的情況，貝氏定理亦成立。例如：

\[P(A|B,C) = \frac{P(A) \, P(B|A) \, P(C|A,B)}{P(B) \, P(C|B)} \!\]
這個式子可以由套用多次二個變數的貝式定理及[條件機率的定義導出](https://zh.wikipedia.org/wiki/條件機率 "wikilink")：

\[P(A|B,C) = \frac{P(A,B,C)}{P(B,C)} = \frac{P(A,B,C)}{P(B) \, P(C|B)} =\]

\[= \frac{P(C|A,B) \, P(A,B)}{P(B) \, P(C|B)} = \frac{P(A) \, P(B|A) \, P(C|A,B)}{P(B) \, P(C|B)}\]。

一般化的方法則是利用[聯合機率去分解待求的條件機率](https://zh.wikipedia.org/wiki/联合概率 "wikilink")，並對不加以探討的變數積分（意即對欲探討的變數計算邊緣機率）。取決於不同的分解形式，可以證明某些積分必為1，因此分解形式可被簡化。利用這個性質，貝氏定理的計算量可能可以大幅下降。[貝氏網路為此方法的一個例子](../Page/貝氏網路.md "wikilink")，[貝氏網路指定數個變數的](../Page/貝氏網路.md "wikilink")[聯合機率分佈的分解型式](../Page/联合分布.md "wikilink")，該機率分佈滿足下述條件：當其他變數的條件機率給定時，該變數的條件機率為一簡單型式。

## 範例

### 吸毒者检测

下面展示贝叶斯定理在检测吸毒者时的应用。假设一个常规的检测结果的敏感度与可靠度均为99%，即吸毒者每次检测呈阳性（+）的概率为99%。而不吸毒者每次检测呈阴性（-）的概率为99%。从检测结果的概率来看，检测结果是比较准确的，但是贝叶斯定理卻可以揭示一个潜在的问题。假设某公司对全体雇员进行吸毒检测，已知0.5%的雇员吸毒。请问每位检测结果呈阳性的雇员吸毒的概率有多高？

令“D”为雇员吸毒事件，“N”为雇员不吸毒事件，“+”为检测呈阳性事件。可得

  - P(D)代表雇员吸毒的概率，不考虑其他情况，该值为0.005。因为公司的预先统计表明该公司的雇员中有0.5%的人吸食毒品，所以这个值就是D的[先验概率](https://zh.wikipedia.org/wiki/先验概率 "wikilink")。
  - P(N)代表雇员不吸毒的概率，显然，该值为0.995，也就是1-P(D)。
  - P(+|D)代表吸毒者阳性检出率，这是一个[条件概率](../Page/条件概率.md "wikilink")，由于阳性检测准确性是99%，因此该值为0.99。
  - P(+|N)代表不吸毒者阳性检出率，也就是出错检测的概率，该值为0.01，因为对于不吸毒者，其检测为阴性的概率为99%，因此，其被误检测成阳性的概率为1
    - 0.99 = 0.01。
  - P(+)代表不考虑其他因素的影响的阳性检出率。该值为0.0149或者1.49%。我们可以通过[全概率公式计算得到](https://zh.wikipedia.org/wiki/全概率公式 "wikilink")：此概率
    = 吸毒者阳性检出率（0.5% x 99% = 0.495%)+ 不吸毒者阳性检出率（99.5% x 1% =
    0.995%)。P(+）=0.0149是检测呈阳性的[先验概率](https://zh.wikipedia.org/wiki/先验概率 "wikilink")。用数学公式描述为：

\[P(+)=P(+\cap D)+P(+\cap N)=P(+|D)P(D)+P(+|N)P(N)\]

根据上述描述，我们可以计算某人检测呈阳性时确实吸毒的条件概率P(D|+)：

\[\begin{align}P(D|+) & = \frac{P(+ | D) P(D)}{P(+)} \\
& = \frac{P(+ | D) P(D)}{P(+ | D) P(D) + P(+ | N) P(N)} \\
& = \frac{0.99 \times 0.005}{0.99 \times 0.005 + 0.01 \times 0.995} \\
& = 0.3322.\end{align}\]

尽管吸毒检测的准确率高达99%，但贝叶斯定理告诉我们：如果某人检测呈阳性，其吸毒的概率只有大约33%，不吸毒的可能性比较大。假阳性高，则检测的结果不可靠。

### 胰腺癌检测

基于贝叶斯定理：即使100%的胰腺癌症患者都有某症状，而某人有同样的症状，绝对不代表该人有100%的概率得胰腺癌，还需要考虑先验概率，假设胰腺癌的发病率是十万分之一，而全球有同样症状的人有万分之一，则此人得胰腺癌的概率只有十分之一，90%的可能是是假阳性。

### 不良种子检测

基于贝叶斯定理：假设100%的不良种子都表现A性状，而种子表现A性状，并不代表此种子100%是不良种子，还需要考虑先验概率，假设一共有6万颗不良种子，在种子中的比例是十万分之一（假設总共有60亿颗种子），假设所有种子中有1/3表现A性状（即20亿颗种子表现A性状），则此种子为不良种子的概率只有十万分之三。

## 参见

  - [概率论](https://zh.wikipedia.org/wiki/概率论 "wikilink")
  - [贝叶斯概率](../Page/贝叶斯概率.md "wikilink")
  - [贝叶斯推理](https://zh.wikipedia.org/wiki/贝叶斯推理 "wikilink")

## 參考文獻

<div class="references-small">

<references />

</div>

## 外部連結

  - [数学之美番外篇：平凡而又神奇的贝叶斯方法](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)

[Category:概率论](https://zh.wikipedia.org/wiki/Category:概率论 "wikilink")
[Category:数学定理](https://zh.wikipedia.org/wiki/Category:数学定理 "wikilink")

1.
2.  Papoulis A.(1984). Probability, Random Variables, and Stochastic
    Processes, 2nd edition. Section 7.3. New York: McGraw-Hill.
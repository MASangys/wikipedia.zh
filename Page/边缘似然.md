> 本文内容由[边缘似然](https://zh.wikipedia.org/wiki/边缘似然)转换而来。


在统计学中， **边缘似然函数**（marginal likelihood function），或**积分似然**（integrated likelihood），是一个某些参数变量边缘化的[似然函数](../Page/似然函数.md "wikilink")（likelihood function） 。在贝叶斯统计范畴，它也可以被称作为 **证据** 或者 **模型证据**的。

## 概念

给出一组 [独立同分布](../Page/独立同分布.md "wikilink")的数据点\(\mathbb{X}=(x_1,\ldots,x_n),\), \(x_i \sim p(x_i|\theta)\), 其中*θ* 是一个通过分布描述的 [随机变量](../Page/随机变量.md "wikilink")，即 \(\theta \sim p(\theta|\alpha),\) 概率\(p(\mathbb{X}|\alpha)\) ， 其中*θ*是[边缘分布](https://zh.wikipedia.org/wiki/边缘分布 "wikilink")(积分结果):

\[p(\mathbb{X}|\alpha) = \int_\theta p(\mathbb{X}|\theta) \, p(\theta|\alpha)\ \operatorname{d}\!\theta\]

上述定义是在贝叶斯统计范畴给出的。在经典的(频率派)的统计学中，边缘似然这一概念产生于联合参数*θ*=(*ψ*,*λ*)，其中 *ψ* 是我们关心的实际参数，*λ*是一个不关心的冗余参数。 如果*λ*服从概率分布，那么通常可以通过边缘化λ来考虑*ψ*的似然函数：

\[\mathcal{L}(\psi;\mathbb{X}) = p(\mathbb{X}|\psi) = \int_\lambda p(\mathbb{X}|\lambda,\psi) \, p(\lambda|\psi) \ \operatorname{d}\!\lambda\]

不幸的是，边缘似然一般很难计算。只有在边缘化输出参数是数据分布的[共轭先验的情况下](https://zh.wikipedia.org/wiki/共轭先验 "wikilink"), 很少的一部分分布的可以得到确切解。在其他情况下，需要通过一些数值积分方法得到，无论是通用的法如 [高斯求积](../Page/高斯求积.md "wikilink")或[蒙特卡洛方法](../Page/蒙地卡羅方法.md "wikilink")，或一种统计问题的专用方法，例如[拉普拉斯方法](../Page/拉普拉斯方法.md "wikilink"), 吉布斯/[梅特罗波利斯采样](../Page/梅特罗波利斯－黑斯廷斯算法.md "wikilink")，或者[最大期望算法](../Page/最大期望算法.md "wikilink")。

在贝叶斯的范畴内，这等价于数据点的先验预测分布。

## 应用

### 贝叶斯模型比较

在贝叶斯模型比较，被边缘化的变量的参数用于特定类型的模型，其余可变标识的的模型本身。 在这种情况下，边缘似然是数据点由模型给出的概率，而不是假设的任何特定的模型参数。 用θ表示模型参数，模型M的边缘似然是

\[p(x|M) = \int p(x|\theta, M) \, p(\theta|M) \, \operatorname{d}\!\theta\]

它是在这一背景下，术语模型证据是一种常见表达。这一数量是重要的，因为后验几率比为一个模型*M*<sub>1</sub> 针对另一个模型*M*<sub>2</sub> 的比率边缘似然，称为贝叶斯因子:

\[\frac{p(M_1|x)}{p(M_2|x)} = \frac{p(M_1)}{p(M_2)} \, \frac{p(x|M_1)}{p(x|M_2)}\]

它可以表示成如下形式

  -
    后验几率 =先验几率× 贝叶斯因子

## 参见

  - 经验贝叶斯方法
  - [边缘分布](https://zh.wikipedia.org/wiki/边缘分布 "wikilink")
  - Lindley's 悖论

## 参考文献

  - Charles S. Bos. "A comparison of marginal likelihood computation methods". In W. Härdle and B. Ronz, editors, *COMPSTAT 2002: Proceedings in Computational Statistics*, pp. 111–117. 2002. *(Available as a preprint on the web: [1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=332860&rec=1&srcabs=1187984&alg=5&pos=3))*
  - The on-line textbook: Information Theory, Inference, and Learning Algorithms\], by David J.C. MacKay.

[Category:贝叶斯统计](https://zh.wikipedia.org/wiki/Category:贝叶斯统计 "wikilink")
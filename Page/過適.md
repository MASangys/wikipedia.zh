[Overfitting.svg](https://zh.wikipedia.org/wiki/File:Overfitting.svg "fig:Overfitting.svg")

在[統計學中](https://zh.wikipedia.org/wiki/統計學 "wikilink")，**過適**（，或稱**過度擬合**）[現象](../Page/現象.md "wikilink")是指在調適一個[統計模型時](https://zh.wikipedia.org/wiki/統計模型 "wikilink")，使用過多[參數](https://zh.wikipedia.org/wiki/參數 "wikilink")。

對比於可取得的資料總量來說，一個荒謬的模型只要足夠複雜，是可以完美地適應資料。過適一般可以視為違反[奥卡姆剃刀](../Page/奥卡姆剃刀.md "wikilink")原則。

當可選擇的參數的自由度超過資料所包含資訊內容時，這會導致最後（調適後）模型使用任意的參數，這會減少或破壞模型一般化的能力更甚於適應資料。過適的可能性不只取決於參數個數和資料，也跟模型架構與資料的一致性有關。此外對比於資料中預期的雜訊或錯誤數量，跟模型錯誤的數量也有關。

過適現象的觀念對[機器學習也是很重要的](https://zh.wikipedia.org/wiki/機器學習 "wikilink")。通常一個學習[演算法是藉由訓練範例來訓練的](https://zh.wikipedia.org/wiki/演算法 "wikilink")。亦即預期結果的範例是可知的。而學習者則被認為須達到可以預測出其它範例的正確的結果，因此，應適用於一般化的情況而非只是訓練時所使用的現有資料（根據它的[歸納偏向](https://zh.wikipedia.org/wiki/歸納偏向 "wikilink")）。然而，學習者卻會去適應訓練資料中太特化但又隨機的特徵，特別是在當學習過程太久或範例太少時。在過適的過程中，當預測訓練範例結果的表現增加時，應用在未知資料的表現則變更差。

在統計和機器學習中，為了避免過適現象，須要使用額外的技巧（如[交叉驗證](../Page/交叉驗證.md "wikilink")、、、[赤池信息量準則或](https://zh.wikipedia.org/wiki/赤池信息量準則 "wikilink")），以指出何時會有更多訓練而沒有導致更好的一般化。[人工神經網路的過適過程亦被認知為過度訓練](https://zh.wikipedia.org/wiki/人工神經網路 "wikilink")（）。在treatmeant learning中，使用最小最佳支援值（）來避免過適。

相對於過適是指，使用過多參數，以致太適應資料而非一般情況，另一種常見的現象是使用太少參數，以致於不適應資料，這則稱為**乏適**（，或稱：擬合不足）現象。

## 參考文獻

  - Tetko, I.V.; Livingstone, D.J.; Luik, A.I. Neural network studies. 1. Comparison of Overfitting and Overtraining, [J. Chem. Inf. Comput. Sci., 1995, 35, 826-833](http://www.vcclab.org/articles/tetko.html#overtraining)

## 外部連結

  - <http://www.cs.sunysb.edu/~skiena/jaialai/excerpts/node16.html>
  - [過度訓練](http://www.vcclab.org/articles/tetko.html#overtraining)

## 參見

  -
[Category:回歸分析](https://zh.wikipedia.org/wiki/Category:回歸分析 "wikilink") [Category:數據挖掘](https://zh.wikipedia.org/wiki/Category:數據挖掘 "wikilink") [Category:機器學習](https://zh.wikipedia.org/wiki/Category:機器學習 "wikilink")
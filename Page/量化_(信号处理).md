[Quantized.signal.svg](https://zh.wikipedia.org/wiki/File:Quantized.signal.svg "fig:Quantized.signal.svg")
[Digital.signal.svg](https://zh.wikipedia.org/wiki/File:Digital.signal.svg "fig:Digital.signal.svg")
**量化**在[数字信号处理领域是指将信号的连续取值](../Page/数字信号处理.md "wikilink")（或者大量可能的离散取值）近似为有限多个（或较少的）离散值的过程。量化主要应用于从[连续信号到](https://zh.wikipedia.org/wiki/连续信号 "wikilink")[数字信号的转换中](https://zh.wikipedia.org/wiki/数字信号 "wikilink")。连续信号经过[采样成为](https://zh.wikipedia.org/wiki/采样 "wikilink")[离散信号](https://zh.wikipedia.org/wiki/离散信号 "wikilink")，离散信号经过量化即成为数字信号。注意离散信号并不需要经过量化的过程。信号的采样和量化通常都是由ADC实现的。

例如[CD音频信号就是按照](../Page/CD.md "wikilink")44100[Hz的频率采样](https://zh.wikipedia.org/wiki/Hz "wikilink")，按16[位元量化为有着](../Page/位元.md "wikilink")65536（=\(2^{16}\)）个可能取值的数字信号。

量化就是将模拟声音的波形转换为数字，表示采样值的二进制位数决定了量化的精度。量化的过程是先将整个幅度划分成有限个小幅度（量化阶距）的集合，把落入某个阶距内的样值归为一类，并赋予相同的量化值。

## 数学描述

最简单最易懂的量化是[标量](https://zh.wikipedia.org/wiki/scalar "wikilink")（有别于多维[矢量](https://zh.wikipedia.org/wiki/vector_\(spatial\) "wikilink")）量化，开始标量量化之前先要给出输入数据。
通常，一个标量量化操作可以给出下面的描述

\[Q(x) = g(\lfloor f(x) \rfloor)\]

其中

  - \(x\)是实数，
  - \(\lfloor x \rfloor\)是[下取整函数](../Page/取整函数.md "wikilink")，生成整数\(i = \lfloor f(x) \rfloor\)
  - \(f(x)\)和\(g(i)\)是任意的实值函数。

整数\(i\)是表示的数值，它通常被存储或者传输，然后在后来需要解释的时候使用\(g(i)\)进行最终的解释重建。整数\(i\)有时也称作*量化指数*。

在计算机或者其它应用，一个已知的量化方法*均匀量化*。在均匀量化方法里共有两个变量，叫*mid-rise*和*mid-tread*。

如果\(x\)是一个－1到1之间的数，一个mid-rise uniform量化操作，可以用"M"bit来表示量化的精度。

\[Q(x) = \frac{\left\lfloor 2^{M-1}x \right\rfloor+0.5}{2^{M-1}}\].

在这个例子中\(f(x)\)和\(g(i)\)运算符都是乘以比例因子（其中一个是另外一个的逆），并且在*g*（*i*）中带有一个偏移量以使得每个量化表示都位于输入区域的中间位置。\(2^{-(M-1)}\)经常称为*量化步长*。按照这个量化定律，假定在整个量化步长上量化噪声大致是[均匀分布的](https://zh.wikipedia.org/wiki/连续型均匀分布 "wikilink")，并且假定量化的输入信号\(x\)在整个-1到1的区间大致均匀分布，量化的[信噪比](../Page/信噪比.md "wikilink")（SNR）可以用下面的公式计算，

\[\frac{S}{N_q} \approx 20 \log_{10}(2^M)
=
6.0206 M \ \operatorname{dB}\].

根据这个等式，人们常说SNR大约是每[位](https://zh.wikipedia.org/wiki/位 "wikilink")6
[dB](https://zh.wikipedia.org/wiki/decibel "wikilink")。

在mid-tread一致量化中，偏移0.5将加在下取整函数内部而不是外部。

有时候，mid-rise量化使用时不加偏移0.5。这将信号与噪声比减小了大约6.02 dB，但是当步距小的时候为了简化这是可接受的。

在数字[电话系统中](../Page/电话.md "wikilink")，两个流行的量化机制是'[A-law](https://zh.wikipedia.org/wiki/A-law_algorithm "wikilink")'（在[欧洲占据主导地位](../Page/欧洲.md "wikilink")）和'[μ-law](https://zh.wikipedia.org/wiki/Mu-law_algorithm "wikilink")'（在[北美和](https://zh.wikipedia.org/wiki/北美 "wikilink")[日本占据主导地位](../Page/日本.md "wikilink")）。这些机制将离散的模拟数值映射到8位尺度，在小值的时候近似线性随着幅度增长按照对数增加。由于人耳对于[音量的感知近似对数曲线](https://zh.wikipedia.org/wiki/音量 "wikilink")，这就使用一定的位数在可听见的声音强度范围提供了更高的信噪比。

## 忽略熵约束：Lloyd–Max量化

在上面的陈述中，若令 \(\lambda\) 等于
0，从而忽略掉比特率约束，或等价地假设要用定长码（FLC）而非用（或其他[熵編碼法](../Page/熵編碼法.md "wikilink")，如[算术编码在率失真上就比定长码好](../Page/算术编码.md "wikilink")）来表示量化数据，这个最优化问题就简化为了只需最小化失真
\(D\) 的问题了。

\(M\) 级量化器产生的索引可以用 \(R = \lceil \log_2 M \rceil\) 比特/符号的定长码。例如当
\(M=\)256 阶时，定长码的比特率 \(R\) 为 8
比特/符号。由于这个原因，这样的量化器有时称作8比特量化器。不过使用定长码消除了压缩改进，但可以通过更好的熵编码来改善。

假设 \(M\) 阶定长码，率失真最小化问题可以简化为失真最小化问题。
简化的问题可以陈述为：给定一个[機率密度函數为](../Page/機率密度函數.md "wikilink")
\(f(x)\) 的信源 \(X\) ，并约束量化器必须仅使用 \(M\) 个分类区域，求得决策边界
\(\{b_k\}_{k=1}^{M-1}\) 与重建层级 \(\{y_k\}_{k=1}^M\) 来最小化得到的失真

\[D=E[(x-Q(x))^2] = \int_{-\infty}^{\infty} (x-Q(x))^2f(x)dx = \sum_{k=1}^{M} \int_{b_{k-1}}^{b_k} (x-y_k)^2 f(x)dx =\sum_{k=1}^{M} d_k\].

对上述问题求最优解得到的量化器有时叫做MMSQE（最小均方量化误差）解，而得到的概率密度函数最优化的（非均匀）量化器叫做*Lloyd–Max*量化器，是用独立发现迭代方法\[1\]\[2\]\[3\]从
\({\partial D / \partial b_k} = 0\) 和 \({\partial D/ \partial y_k} = 0\)
求解两组联立方程的两个人来命名的，如下：

\[{\partial D \over\partial b_k} = 0 \Rightarrow b_k = {y_k + y_{k+1} \over 2}\],
会将阈值置于每对重建值的中点，而

\[{\partial D \over\partial y_k} = 0 \Rightarrow y_k = { \int_{b_{k-1}}^{b_k} x f(x) dx \over \int_{b_{k-1}}^{b_k} f(x)dx } = \frac1{p_k} \int_{b_{k-1}}^{b_k} x f(x) dx\]
会让重建值位于其相关分类区间的质心（条件期望值）。

，最初于1957提出，并可以直接推广到用于[向量数据](https://zh.wikipedia.org/wiki/向量量化 "wikilink")。这个推广会得到或[K-平均分类器最优化方法](../Page/K-平均算法.md "wikilink")。此外，此方法还可以进一步推广到对向量数据包含一个熵约束。\[4\]

## 量化与数据压缩

量化在[有损数据压缩中起着相当重要的作用](../Page/有损数据压缩.md "wikilink")。很多情况下，量化可以被当作将有损数据压缩同[无损数据压缩相区别的标志之一](../Page/无损数据压缩.md "wikilink")。量化的目的通常是为了减少数据量。一些压缩算法，例如[MP3和](../Page/MP3.md "wikilink")[Vorbis](https://zh.wikipedia.org/wiki/Vorbis "wikilink")，以有选择地丢弃部分数据作为压缩的一种方法，这种手段可以被认为是量化的过程也可以被看作是一种有损压缩的形式。

[JPEG是一种利用了量化的图像有损压缩](../Page/JPEG.md "wikilink")。JPEG的编码过程对原始的图像数据作[离散余弦变换](../Page/离散余弦变换.md "wikilink")，然后对变换结果进行量化并作[熵编码](https://zh.wikipedia.org/wiki/熵编码 "wikilink")。通过量化可以降低变换值的精度，从而减少图像的数据量。当然，精度的损失意味着图像质量的下降。然而图像的质量可以通过量化位数的选择加以控制。例如，JPEG在每像素3[比特的精度下得到的图像质量还让人可以接受的](../Page/位元.md "wikilink")，相对于[PCM抽样得到的每个像素](../Page/脈衝編碼調變.md "wikilink")24比特的原始图像来说，数据量大大下降了。

现代压缩技术通常以量化输出的[信息熵](https://zh.wikipedia.org/wiki/信息熵 "wikilink")，而不是输出值集合的大小度量信息量的多少。

## 自然界中的量子化

从最基本的意义上来说，所有的[物理量都是量子化的](../Page/物理量.md "wikilink")，这是[量子力学的结论](../Page/量子力学.md "wikilink")。为了数学上的明晰性，在宏观的尺度上可以将量子的性质忽略，因此信号可以表示为连续的形式。

在实际应用中，这种内在的量子或量化的性质并不需要考虑。首先，量子效应会被信号的噪声淹没，因为任何观察对象在实际系统中总会伴随有其他物理现象。其次，测量仪器不可能绝对精确，被测的信号必然会被测量噪声污染。

## 量化误差

量化误差是指在量化过程引起的误差，表现为量化结果和被量化模拟量之间存在差值。这种差值在输出端体现为引入了[量化噪声](https://zh.wikipedia.org/wiki/量化噪声 "wikilink")。

## 相關條目

  - [模-数转换器](https://zh.wikipedia.org/wiki/模-数转换器 "wikilink")，[数-模转换器](https://zh.wikipedia.org/wiki/数-模转换器 "wikilink")
  - [量化误差](https://zh.wikipedia.org/wiki/量化误差 "wikilink"),
    [量化噪声](https://zh.wikipedia.org/wiki/量化噪声 "wikilink")
  - [离散信号](https://zh.wikipedia.org/wiki/离散信号 "wikilink")，[数字信号](https://zh.wikipedia.org/wiki/数字信号 "wikilink")
  - [抖动](../Page/抖动.md "wikilink")
  - [信息论](../Page/信息论.md "wikilink")
  - [率失真](https://zh.wikipedia.org/wiki/率失真 "wikilink")
  - [矢量量化](https://zh.wikipedia.org/wiki/矢量量化 "wikilink")

## 参考文献

## 外部链接

  - [Paper on mathematical theory and analysis of
    quantization](http://www.math.ucdavis.edu/~saito/courses/ACHA/44it06-gray.pdf)
  - [Quantization threads in
    Comp.DSP](http://www.dsprelated.com/comp.dsp/keyword/Quantization.php)

[Category:信号处理](https://zh.wikipedia.org/wiki/Category:信号处理 "wikilink")

1.
2.  Stuart P. Lloyd, "Least Squares Quantization in PCM", **, Vol.
    IT-28, pp. 129–137, No. 2, March 1982  (work documented in a
    manuscript circulated for comments at [Bell
    Laboratories](../Page/贝尔实验室.md "wikilink") with a department
    log date of 31 July 1957 and also presented at the 1957 meeting of
    the [Institute of Mathematical
    Statistics](https://zh.wikipedia.org/wiki/Institute_of_Mathematical_Statistics "wikilink"),
    although not formally published until 1982).

3.  Joel Max, "Quantizing for Minimum Distortion", **, Vol. IT-6, pp.
    7–12, March 1960.

4.  Philip A. Chou, Tom Lookabaugh, and , "Entropy-Constrained Vector
    Quantization", *IEEE Transactions on Acoustics, Speech, and Signal
    Processing*, Vol. ASSP-37, No. 1, Jan. 1989.
在[机器学习和](../Page/机器学习.md "wikilink")[统计学领域](../Page/统计学.md "wikilink")，**降维**是指在某些限定条件下，降低随机变量个数，得到一组“不相关”主变量的过程\[1\]。
降维可进一步细分为[变量选择和](../Page/特征选择.md "wikilink")[特征提取两大方法](../Page/特征提取.md "wikilink")。

## 变量选择

[变量选择假定数据中包含大量冗余或无关变量](../Page/特征选择.md "wikilink")（或称特征、属性、指标等），旨在从原有变量中找出主要变量。现代统计学中对变量选择的研究文献，大多集中于，其中最具代表性的方法包括：

  - (提出)

  - [Elastic net](../Page/Elastic_net.md "wikilink") (和提出)

  - [SCAD](../Page/SCAD.md "wikilink")
    ([范剑青和](../Page/范剑青.md "wikilink")提出)

  - [SURE screening](../Page/SURE_screening.md "wikilink")
    ([范剑青和](../Page/范剑青.md "wikilink")[吕金翅提出](../Page/吕金翅.md "wikilink"))

  - [PLUS](../Page/PLUS.md "wikilink")
    ([张存惠提出](../Page/张存惠.md "wikilink"))

## 特征提取

[特征提取可以看作](../Page/特征提取.md "wikilink")[变量选择方法的一般化](../Page/特征选择.md "wikilink")：[变量选择假设在原始数据中](../Page/特征选择.md "wikilink")，变量数目浩繁，但只有少数几个真正起作用；而[特征提取则认为在所有变量可能的函数](../Page/特征提取.md "wikilink")(比如这些变量各种可能的线性组合)中，只有少数几个真正起作用。有代表性的方法包括：

  - [主成分分析(PCA)](../Page/主成分分析.md "wikilink")

  -
  - (教科书中称为“Kernel method”或“Kernel
    trick”，常与其他方法如[PCA组合使用](../Page/主成分分析.md "wikilink"))

  - 基于距离的方法，例如：

      - [多维尺度分析](../Page/多维尺度.md "wikilink")

      -
      - (理论依据是[约翰逊-林登斯特劳斯定理](../Page/约翰逊-林登斯特劳斯定理.md "wikilink"))

## 参见

  - [变量选择](../Page/特征选择.md "wikilink")
  - [特征提取](../Page/特征提取.md "wikilink")
  - [约翰逊-林登斯特劳斯定理](../Page/约翰逊-林登斯特劳斯定理.md "wikilink")

## 参考文献

[Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink")

1.
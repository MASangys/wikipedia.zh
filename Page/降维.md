> 本文内容由[降维](https://zh.wikipedia.org/wiki/降维)转换而来。


在[机器学习](../Page/机器学习.md "wikilink")和[统计学](../Page/统计学.md "wikilink")领域，**降维**是指在某些限定条件下，降低随机变量个数，得到一组“不相关”主变量的过程\[1\]。 降维可进一步细分为[变量选择和](../Page/特征选择.md "wikilink")[特征提取两大方法](https://zh.wikipedia.org/wiki/特征提取 "wikilink")。

## 变量选择

[变量选择假定数据中包含大量冗余或无关变量](../Page/特征选择.md "wikilink")（或称特征、属性、指标等），旨在从原有变量中找出主要变量。现代统计学中对变量选择的研究文献，大多集中于，其中最具代表性的方法包括：

  - (提出)

  - [Elastic net](https://zh.wikipedia.org/wiki/Elastic_net "wikilink") (和提出)

  - [SCAD](https://zh.wikipedia.org/wiki/SCAD "wikilink") ([范剑青](../Page/范剑青.md "wikilink")和提出)

  - [SURE screening](https://zh.wikipedia.org/wiki/SURE_screening "wikilink") ([范剑青](../Page/范剑青.md "wikilink")和[吕金翅提出](https://zh.wikipedia.org/wiki/吕金翅 "wikilink"))

  - [PLUS](https://zh.wikipedia.org/wiki/PLUS "wikilink") ([张存惠提出](https://zh.wikipedia.org/wiki/张存惠 "wikilink"))

## 特征提取

[特征提取可以看作](https://zh.wikipedia.org/wiki/特征提取 "wikilink")[变量选择方法的一般化](../Page/特征选择.md "wikilink")：[变量选择假设在原始数据中](../Page/特征选择.md "wikilink")，变量数目浩繁，但只有少数几个真正起作用；而[特征提取则认为在所有变量可能的函数](https://zh.wikipedia.org/wiki/特征提取 "wikilink")(比如这些变量各种可能的线性组合)中，只有少数几个真正起作用。有代表性的方法包括：

  - [主成分分析](../Page/主成分分析.md "wikilink")(PCA)

  -
  - (教科书中称为“Kernel method”或“Kernel trick”，常与其他方法如[PCA组合使用](../Page/主成分分析.md "wikilink"))

  - 基于距离的方法，例如：

      - [多维尺度分析](https://zh.wikipedia.org/wiki/多维尺度 "wikilink")

      -
      - (理论依据是[约翰逊-林登斯特劳斯定理](../Page/约翰逊-林登斯特劳斯定理.md "wikilink"))

## 参见

  - [变量选择](../Page/特征选择.md "wikilink")
  - [特征提取](https://zh.wikipedia.org/wiki/特征提取 "wikilink")
  - [约翰逊-林登斯特劳斯定理](../Page/约翰逊-林登斯特劳斯定理.md "wikilink")

## 参考文献

[Category:统计学](https://zh.wikipedia.org/wiki/Category:统计学 "wikilink")

1.
> 本文内容由[隨機訊號](https://zh.wikipedia.org/wiki/隨機訊號)转换而来。


隨機訊號（）不能以一個確切的[數學公式來描述](https://zh.wikipedia.org/wiki/數學 "wikilink")，也不能準確地預測。因此對於隨機訊號一般只能在[統計的意義上來研究](https://zh.wikipedia.org/wiki/統計 "wikilink")。不論是工程上或是日常生活當中隨機訊號的例子有很多，例如[無線通訊](../Page/無線通訊.md "wikilink")系統中的[噪音](../Page/噪音.md "wikilink")與干擾、生物醫學訊號以及[語音](../Page/語音.md "wikilink")訊號都是隨機的，以下將討論隨機訊號的基本概念與描述方法。

## 基本概念

從[機率論可知我們可用一個](https://zh.wikipedia.org/wiki/機率論 "wikilink")[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")\(X\)來描述自然界中的[隨機事件](https://zh.wikipedia.org/wiki/隨機事件 "wikilink")，若\(X\)的取值為連續，則\(X\)為連續型隨機變量；若\(X\)的取值為離散，則\(X\)為離散型隨機變量。對於隨機變量\(X\)，我們一般用它的[分布函數及](https://zh.wikipedia.org/wiki/分布函數 "wikilink")[機率密度來描述](https://zh.wikipedia.org/wiki/機率密度 "wikilink")。

### 分布函數

對於[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")\(X\)，我們可用機率[分布函數來表示](https://zh.wikipedia.org/wiki/分布函數 "wikilink")，其數學描述為:

\[P(x) = Probability(X \leqslant x) = Probability(X \in (-\infty,x])\]

\[P(x)\]有以下最基本的性質:

1.  \(0 \leqslant P(x) \leqslant 1;\)
2.  \(P(-\infty) = 0;\)
3.  \(P(\infty) = 1;\)
4.  若 \(x \leqslant y\)，則 \(P(x) \leqslant P(y).\)

若\(X\)為連續[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")，可定義[機率密度函數](https://zh.wikipedia.org/wiki/機率密度 "wikilink"):

\[p(x) = \frac{\mathrm{d}P(x)}{\mathrm{d}x}\]

明顯[分布函數與](https://zh.wikipedia.org/wiki/分布函數 "wikilink")[密度函數的關係為](https://zh.wikipedia.org/wiki/密度函數 "wikilink"):

\[P(x) = \int_{-\infty}^{x} p(v)\mathrm{d}v\]

[密度函數有以下基本的性質](https://zh.wikipedia.org/wiki/密度函數 "wikilink"):

1.  \(p(x) \geqslant 0;\)
2.  \(\int_{-\infty}^{\infty} p(x)\mathrm{d}x = 1;\)
3.  \(P(b) - P(a) = \int_{a}^{b} p(x)\mathrm{d}x.\)

### 平均值與標準差

定義隨機變量\(X\)的[平均值](https://zh.wikipedia.org/wiki/平均值 "wikilink"):

\[\mu_X = E(X) = \int_{-\infty}^{\infty} xp(x)\mathrm{d}x\]

定義隨機變量\(X\)的[標準差](../Page/標準差.md "wikilink")的平方:

\[\sigma_X^2 = E(|X - \mu_X|^2) = \int_{-\infty}^{\infty} |x-\mu_X|^2p(x)\mathrm{d}x\]

定義隨機變量\(X\)的[平方平均数](../Page/平方平均数.md "wikilink"):

\[D_X^2 = E(|X|^2) = \int_{-\infty}^{\infty} |x|^2p(x)\mathrm{d}x\]

若\(X\)為離散隨機變數則以上運算變為求和。

### 矩

定義隨機變數\(X\)的m階原點[矩](https://zh.wikipedia.org/wiki/矩 "wikilink"):

\[\eta_X^m = E(|X|^m) = \int_{-\infty}^{\infty} |x|^mp(x)\mathrm{d}x\]

再定義隨機變數\(X\)的m階[中心矩](../Page/中心矩.md "wikilink"):

\[\gamma_X^m = E(|X - \mu_X|^m) = \int_{-\infty}^{\infty} |x-\mu_X|^mp(x)\mathrm{d}x\]

[平均值](https://zh.wikipedia.org/wiki/平均值 "wikilink")、[標準差](../Page/標準差.md "wikilink")及[矩都是](https://zh.wikipedia.org/wiki/矩 "wikilink")[隨機變量的數字特徵](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")，可利用它們來描述[隨機變數](https://zh.wikipedia.org/wiki/隨機變數 "wikilink")，例如[平均值可代表](https://zh.wikipedia.org/wiki/平均值 "wikilink")\(X\)取值的中心位置，[標準差](../Page/標準差.md "wikilink")表示了\(X\)的取值相對[平均值的分散程度](https://zh.wikipedia.org/wiki/平均值 "wikilink")。

### 隨機向量

N個[隨機變量組成的](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")[向量](../Page/向量.md "wikilink")\(X = [X_1,X_2,...,X_N]^T\)稱為隨機向量，它是研究多個隨機變量的聯合分布以及進一步將隨機變量理論推廣到隨機訊號的重要工具。隨機向量的[平均值為各分量的](https://zh.wikipedia.org/wiki/平均值 "wikilink")[平均值所組成的](https://zh.wikipedia.org/wiki/平均值 "wikilink")[平均值向量](https://zh.wikipedia.org/wiki/平均值 "wikilink"):

\[\mu_X = [\mu_{X1},\mu_{X2},...,\mu_{XN}]^T,\mu_{Xi} = E(X_i)\]

而[標準差](../Page/標準差.md "wikilink")的平方會形成[矩陣](https://zh.wikipedia.org/wiki/矩陣 "wikilink"):

\[E((X-\mu_X)(X-\mu_X)^T)=
\begin{bmatrix}
\sigma_1^2 & cov(X_1,X_2) & \cdots & cov(X_1,X_N) \\
cov(X_2,X_1) & \sigma_2^2 & \cdots & cov(X_2,X_N) \\
\vdots & \vdots & \ddots & \vdots \\
cov(X_N,X_1) & cov(X_N,X_2) &\cdots & \sigma_N^2
\end{bmatrix}\]

式中\(cov(X_i,X_j) = E((X_i-\mu_{Xi})^*(X_j-\mu_{Xj}))\)稱為分量\(X_i\)與\(X_j\)之間的[共變異數](https://zh.wikipedia.org/wiki/共變異數 "wikilink")。

## 隨機訊號的描述

為了了解接下來的說明因此我們需要舉一個例子。現在想像一個直流[放大器](../Page/放大器.md "wikilink")的輸出，當輸入[接地](../Page/接地.md "wikilink")時輸出應該為零，然而現實中[放大器](../Page/放大器.md "wikilink")會產生[雜訊](../Page/雜訊.md "wikilink")使得輸出不為零，該[雜訊](../Page/雜訊.md "wikilink")就是一個隨機訊號，因此當我們在相同的條件下獨立地進行多次觀察時，各次觀測到的結果應該互不相同。為了全面地了解輸出[雜訊](../Page/雜訊.md "wikilink")的特性，我們應該要在相同的條件下，獨立地盡可能做多次的觀測，這相當於在同一時刻對盡可能多的相同[放大器](../Page/放大器.md "wikilink")各做一次觀察一樣。這樣我們每一次的觀察都能得到一個記錄\(x_i(t)\)，其中\(i = 1,2,...,N;N\rightarrow\infty\)。如果我們把對雜訊[電壓](../Page/電壓.md "wikilink")的觀測看做為一個[隨機試驗](https://zh.wikipedia.org/wiki/隨機試驗 "wikilink")，那麼每一次的記錄都是該[隨機試驗的一次實現](https://zh.wikipedia.org/wiki/隨機試驗 "wikilink")，其結果\(x_i(t)\)就是一個樣本函數。所有樣本函數的[集合](https://zh.wikipedia.org/wiki/集合 "wikilink")\(i = 1,2,...,N;N\rightarrow\infty\)就構成了雜訊[電壓](../Page/電壓.md "wikilink")可能經歷的整個過程，該集合就是一個隨機訊號\(X(t)\)。

對一個特定的時刻，例如\(t=t_1\)顯然\(x_1(t_1),x_2(t_1),...,x_N(t_1)\)是一個[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")，它相當於在某一固定時刻同時測量無限多個相同[放大器](../Page/放大器.md "wikilink")的輸出[電壓](../Page/電壓.md "wikilink")，對於任一固定的時刻，輸出[電壓](../Page/電壓.md "wikilink")也是一個[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")。因此一個隨機訊號\(X(t)\)是與時間相關的[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")，接下來我們可用[隨機變量來描述隨機訊號](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")。當t在時間軸上取值\(t_1,t_2,...,t_m\)時，我們可得到m個[隨機變量](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")\(X(t_1),X(t_2),...,X(t_m)\)，顯然要描述這m個[隨機變量最全面的方法是利用m維機率](https://zh.wikipedia.org/wiki/隨機變量 "wikilink")[分布函數或](https://zh.wikipedia.org/wiki/分布函數 "wikilink")[機率密度](https://zh.wikipedia.org/wiki/機率密度 "wikilink"):

\[P_X(x_1,x_2,...,x_m;t_1,t_2,...,t_m) = P(X(t_1) \leqslant x_1,X(t_2) \leqslant x_2,...,X(t_m) \leqslant x_m)\]

當m趨近於無限大時上式能完整地描述了隨機訊號\(X(t)\)。但是在工程上要得到隨機訊號的高維[分布函數或](https://zh.wikipedia.org/wiki/分布函數 "wikilink")[機率密度是相當繁瑣的](https://zh.wikipedia.org/wiki/機率密度 "wikilink")，因此在實際工程問題中對於隨機訊號的描述除了採用低維的[分布函數或](https://zh.wikipedia.org/wiki/分布函數 "wikilink")[機率密度之外還使用了](https://zh.wikipedia.org/wiki/機率密度 "wikilink")[平均值](https://zh.wikipedia.org/wiki/平均值 "wikilink")、[標準差](../Page/標準差.md "wikilink")或[矩等數字特徵](https://zh.wikipedia.org/wiki/矩 "wikilink")。對上述例子中的隨機訊號\(X(t)\)離散化，我們得到離散隨機訊號\(X(nT_s)\)(以下簡記為\(X(n)\))，對\(X(nT_s)\)的每一次實現，記為\(x(n,i),n = -\infty \thicksim \infty\)代表時間，\(i = 1,2,...,N(N\rightarrow\infty)\)代表實現的序號，即樣本數。對於\(x(n,i)\)可有如下四種不同的解釋:

1.  若n固定，則\(x(n,i)\)相對純量i的集合為n時刻的隨機變量
2.  若i固定，則\(x(n,i)\)相對純量n的集合構成一個一維的離散時間序列，即\(x(n)\)
3.  若n固定，i也固定，則\(x(n,i)\)是一個具體的數值
4.  若n為變量，i也為變量，則\(x(n,i)\)是一個隨機訊號

### 統計描述

顯然\(X(n)\)的[平均值](https://zh.wikipedia.org/wiki/平均值 "wikilink")、[標準差](../Page/標準差.md "wikilink")等數字特徵均是時間n的函數，[平均值可表示為](https://zh.wikipedia.org/wiki/平均值 "wikilink")

\[\mu_X(n) = E(X(n)) =  \lim_{N \to \infty}\frac{1}{N}\sum_{i=1}^N x(n,i)\]

[標準差](../Page/標準差.md "wikilink")的平方為

\[\sigma_X^2(n) = E(|X(n) - \mu_X(n)|^2) = \lim_{N \to \infty}\frac{1}{N}\sum_{i=1}^N |x(n,i)-\mu_X(n)|^2\]

[平方平均数](../Page/平方平均数.md "wikilink")為

\[D_X^2(n) = E(|X(n)|^2) = \lim_{N \to \infty}\frac{1}{N}\sum_{i=1}^N |x(n,i)|^2\]

\(X(n)\)的[自相關函數定義為](https://zh.wikipedia.org/wiki/自相關函數 "wikilink")

\[r_X(n_1,n_2) = E(X^*(n_1)X(n_2)) = \lim_{N \to \infty}\frac{1}{N}\sum_{i=1}^N x^*(n_1,i)x(n_2,i)\]

共變異函數定義為

\[cov_X(n_1,n_2) = E([X(n_1)-\mu_X(n_1)]^*[X(n_2)-\mu_X(n_2)]) = \lim_{N \to \infty}\frac{1}{N}\sum_{i=1}^N [x(n_1,i)-\mu_X(n_1)]^*[x(n_2,i)-\mu_X(n_2)]\]

上面五式的求均值運算體現了隨機訊號的集總平均，該集總平均是由\(X(n)\)的無限多[樣本](https://zh.wikipedia.org/wiki/樣本 "wikilink")\(x(n,i),i = 1,...,\infty\)在相應時刻對應相加(或相乘後再相加)來實現的。其中[自相關函數](https://zh.wikipedia.org/wiki/自相關函數 "wikilink")\(r_X(n_1,n_2)\)描述了訊號\(X(n)\)在這\(n_1,n_2\)兩個時刻的相互關係，是一個重要的統計量。若\(n_1=n_2=n,\)則:

\[r_X(n_1,n_2) = E(|X(n)|^2) = D_X^2(n)\]

\[cov_X(n_1,n_2) = E(|X(n)-\mu_X(n)|^2) =\sigma_X^2(n)\]

對兩個隨機訊號\(X(n),Y(n),\)其相關函數和共變異函數函數分別定義為:

\[r_{XY}(n_1,n_2) = E(X^*(n_1)Y(n_2))\]

\[cov_{XY}(n_1,n_2) = E(|X(n_1)-\mu_X(n_1)|^*|Y(n_2)-\mu_Y(n_2)|)\]

接著介紹幾個在訊號處理中常用的一些概念。由於隨機訊號\(X(n)\)可以看成是無限維度的隨機向量，因此如果\(p_X(x_1,...,x_N;n_1,...,n_N) = p_X(x_1;n_1)p_X(x_2;n_2)\cdots p_X(x_N;n_X)\)則稱\(X(n)\)是獨立同分布(independent and identically distributed,I.I.D.)的隨機訊號。如果\(X(n)\)在任何不同時刻的[共變異數都為零](https://zh.wikipedia.org/wiki/共變異數 "wikilink")，即:

\[cov_X(n_1,n_2) = 0, \forall n_1 \neq n_2\]

將兩者的聯合機率密度和其各自機率密度有如下關係:

\[p_XY(x,y;n_1,n_2) = p_X(x;n_1)p_Y(y;n_2),\forall n_1,n_2\]

則稱\(X(n)\)和\(Y(n)\)是統計獨立的。進一步若\(p_X(x;n_1)\)和\(p_Y(y;n_2)\)是相同的函數，則稱\(X(n)\)和\(Y(n)\)是I.I.D.的隨機訊號。如果\(cov_{XY}(n_1,n_2) = 0,\forall n_1 \neq n_2,\)我們稱訊號\(X(n)\)和\(Y(n)\)是不相關的。由於:

\[cov(n_1,n_2) = E(X^*(n_1)Y(n_2)) - E(X^*(n_1))\mu_Y(n_2) - \mu_X^*(n_1)E(Y(n_2)) + \mu^*_X(n_1)\mu_Y(n_2) = E(X^*(n_1)Y(n_2)) - \mu^*_X(n_1)\mu_Y(n_2)\]

所以若\(X(n)\)和\(Y(n)\)是不相關的，必有\(E(X^*(n_1)Y(n_2)) = \mu^*_X(n_1)\mu_Y(n_2),\)即\(r_{XY}(n_1,n_2) = \mu^*_X(n_1)\mu_Y(n_2),\)如果:

\[r_{XY}(n_1,n_2) = 0,\forall n_1 \neq n_2\]

我們稱訊號\(X(n)\)和\(Y(n)\)是互相[正交](../Page/正交.md "wikilink")的。

## 參考文獻

  -
**黑塞矩陣**（德語：Hesse-Matrix；英語： 或
），又譯作**海森矩陣**、**海塞矩陣**或**海瑟矩陣**等，是一個由多變量[實值函數的所有二階](https://zh.wikipedia.org/wiki/實函數 "wikilink")[偏導數組成的](https://zh.wikipedia.org/wiki/偏導數 "wikilink")[方塊矩陣](https://zh.wikipedia.org/wiki/方塊矩陣 "wikilink")，由德國數學家[奧托·黑塞引入並以其命名](https://zh.wikipedia.org/wiki/奧托·黑塞 "wikilink")。

## 定義

假設有一實值函數\(f(x_1, x_2, \dots, x_n)\,\)，如果
\(f\,\)的所有二階偏導數都存在並在定義域內連續，那麼函數\(f\,\)的黑塞矩陣為

  -
    <math display="block">\\mathrm H=\\begin{bmatrix}\\frac {\\partial^2
    f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_n} \\\\ \\\\

\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2
f}{\\partial x_2\\,\\partial x_n} \\\\ \\\\ \\vdots & \\vdots &
\\ddots & \\vdots \\\\ \\\\ \\frac{\\partial^2 f}{\\partial
x_n\\,\\partial x_1} & \\frac{\\partial^2 f}{\\partial
x_n\\,\\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial
x_n^2} \\end{bmatrix}\\,</math>

或使用下標記號表示為

  -
    \(\mathrm H_{ij}=\frac{\partial^2f}{\partial x_i \partial y_j}\)

顯然黑塞矩陣
\(\mathrm H\,\)是一個\(n\times n\,\)方陣。黑塞矩陣的[行列式](../Page/行列式.md "wikilink")被稱爲黑塞式（英語：），而英語環境下使用Hessian一詞時可能指上述矩陣也可能指上述矩陣的行列式\[1\]。

## 性質

由[高等數學知識可知](https://zh.wikipedia.org/wiki/高等數學 "wikilink")，若一元[函數](https://zh.wikipedia.org/wiki/函數 "wikilink")\(f(x)\,\)在\(x=x_0\,\)點的某個[鄰域內具有任意階](https://zh.wikipedia.org/wiki/鄰域 "wikilink")[導數](https://zh.wikipedia.org/wiki/導數 "wikilink")，則函數\(f(x)\,\)在\(x=x_0\,\)點處的[泰勒展開式為](https://zh.wikipedia.org/wiki/泰勒展開 "wikilink")

  -
    \(f(x)=f(x_0)+f'(x)\Delta x+\frac {f''(x)}{2!}\Delta x^2+\cdots\,\)

其中，\(\Delta x=x-x_0\,\)。

同理，二元函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處的泰勒展開式為

  -
    \(f(x_1,x_2)=f(x_{10},x_{20})+f_{x_1}(x_{10},x_{20})\Delta x_1+f_{x_2}(x_{10},x_{20})\Delta x_2+\frac {1}{2}[f_{x_1 x_1}(x_{10},x_{20})\Delta x_1^2+2f_{x_1 x_2}(x_{10},x_{20})\Delta x_1\Delta x_2+f_{x_2 x_2}(x_{10},x_{20})\Delta x_2^2]+\cdots\,\)

其中，\(\Delta x_1=x_1-x_{10}\,\)，\(\Delta x_2=x_2-x_{20}\,\)，\(f_{x_1}=\frac{\partial f}{\partial x_1}\,\)，\(f_{x_2}=\frac{\partial f}{\partial x_2}\,\)，\(f_{x_1x_1}=\frac{\partial^2 f}{\partial x_1^2}\,\)，\(f_{x_2x_2}=\frac{\partial^2 f}{\partial x_2^2}\,\)，\(f_{x_1x_2}=\frac{\partial^2 f}{\partial x_1 \partial x_2}=\frac{\partial^2 f}{\partial x_2 \partial x_1}\,\)。

將上述展開式寫成矩陣形式，則有

  -
    \(f(x)=f(x_0)+\nabla f(x_0)^{\mathrm T}\Delta x+\frac{1}{2}\Delta x^{\mathrm T}G(x_0)\Delta x+\cdots\)

其中，\(\Delta x=\begin{bmatrix}\Delta x_1 & \Delta x_2\end{bmatrix}\,\)，\(\Delta x^{\mathrm T}=\begin{bmatrix}\Delta x_1 \\  \\ \Delta x_2\end{bmatrix}\,\)是\(\Delta x\)的[轉置](https://zh.wikipedia.org/wiki/轉置 "wikilink")，\(\nabla f(x_0)=\begin{bmatrix}\frac{\partial f}{\partial x_1}\\  \\
\frac{\partial f}{\partial x_2}\end{bmatrix}\,\)是函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)的[梯度](../Page/梯度.md "wikilink")，矩陣

  -
    <math display="block">G(x_0)=\\begin{bmatrix}\\frac{\\partial^2
    f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_2} \\\\ \\\\

\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_2^2} \\end{bmatrix}_{x_0}\\,</math>

即函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處的\(2\times2\,\)黑塞矩阵。它是由函数\(f(x_1,x_2)\)在\(x_0(x_{10},x_{20})\)点处的所有二階偏導數所組成的方陣。

由函數的二次連續性，有

  -
    \(\frac{\partial^2 f}{\partial x_1 \partial x_2}=\frac{\partial^2 f}{\partial x_2 \partial x_1}\)

所以，黑塞矩陣\(G(x_0)\,\)为[對稱矩陣](../Page/對稱矩陣.md "wikilink")。

將二元函數的泰勒展開式推廣到[多元函數](https://zh.wikipedia.org/wiki/多元函數 "wikilink")，函數\(f(x_1,x_2,\cdots,x_n)\,\)在\(x_0(x_1,x_2,\cdots,x_n)\,\)點處的泰勒展開式為

  -
    \(f(x)=f(x_0)+\nabla f(x_0)^{\mathrm T}\Delta x+\frac {1}{2}\Delta x^{\mathrm T}G(x_0)\Delta x+\cdots\,\)

其中，\(\nabla f(x_0)=\begin{bmatrix}\frac {\partial f}{\partial x_1} & \frac {\partial f}{\partial x_2} & \cdots & \frac {\partial f}{\partial x_n}\end{bmatrix}_{x_0}^T\,\)
為函數\(f(x)\)在\(x_0(x_1,x_2,\cdots,x_n)\,\)點的梯度，

  -
    <math display="block">G(x_0)= \\begin{bmatrix}

\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_2} & \\cdots & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_n} \\\\ \\\\ \\frac{\\partial^2
f}{\\partial x_2\\,\\partial x_1} & \\frac{\\partial^2 f}{\\partial
x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2\\,\\partial
x_n} \\\\ \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\\\
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_2} & \\cdots &
\\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}_{x_0}\\,</math>

為函數\(f(x)\,\)在\(x_0(x_1,x_2,\cdots,x_n)\,\)點的\(n\times n\,\)黑塞矩陣。若函數有\(n\,\)次連續性，則函數的\(n\times n\,\)黑塞矩陣是對稱矩陣。

說明：在[優化設計領域中](https://zh.wikipedia.org/wiki/優化設計 "wikilink")，黑塞矩陣常用\(G\,\)表示，且梯度有時用\(g\,\)表示。\[2\]

函數\(f\,\)的黑塞矩陣和[雅可比矩陣有如下關係](https://zh.wikipedia.org/wiki/雅可比矩陣 "wikilink")：

  -
    \(\mathrm H(f)=\mathrm J(\nabla f^{\mathrm T})\,\)

即函數\(f\,\)的黑塞矩陣等於其梯度的雅可比矩陣。

與梯度類似，借助[Nabla算子](../Page/Nabla算子.md "wikilink")可以將函數\(f\,\)的黑塞矩陣表示為
\(\mathrm H=\nabla^2 f\,\)

## 應用

### 函數的極值條件

對於一元函数\(f(x)\,\)，在給定區間內某\(x=x_0\,\)點處可導，並在\(x=x_0\,\)點處取得[極值](https://zh.wikipedia.org/wiki/極值 "wikilink")，其[必要條件是](https://zh.wikipedia.org/wiki/必要條件 "wikilink")

  -
    \(f'(x_0)=0\,\)

即函數\(f(x)\,\)的極值必定在[駐點處取得](https://zh.wikipedia.org/wiki/駐點 "wikilink")，或者說可導函數\(f(x)\,\)的極值點必定是駐點；但反過來，函數的駐點不一定是極值點。檢驗駐點是否為極值點，可以採用二階導數的正負號來判斷。根據函數\(f(x)\,\)在\(x=x_0\,\)點處的[泰勒展開式](https://zh.wikipedia.org/wiki/泰勒展開 "wikilink")，考慮到上述極值必要條件，有

  -
    \(f(x)=f(x_0)+\frac {f''(x_0)}{2!}\Delta x^2+\cdots\,\)

若\(f(x)\,\)在\(x=x_0\,\)點處取得極小值，則要求在\(x=x_0\,\)某一[鄰域內一切點](https://zh.wikipedia.org/wiki/鄰域 "wikilink")\(x\,\)都必須滿足

  -
    \(f(x)-f(x_0)>0\,\)

即要求

  -
    \(\frac {f''(x_0)}{2!}\Delta x^2>0\,\)

亦即要求

  -
    \(f''(x_0)>0\,\)

\(f(x)\,\)在\(x=x_0\,\)點處取得極大值的討論與之類似。於是有極值[充分條件](https://zh.wikipedia.org/wiki/充分條件 "wikilink")：

設一元函数\(f(x)\,\)在\(x=x_0\,\)點處具有二階導數，且\(f'(x_0)=0\,\)，\(f''(x_0)\ne 0\,\)，則

1.  當\(f''(x_0)>0\,\)時，函數\(f(x)\,\)在\(x=x_0\,\)處取得極小值；
2.  當\(f''(x_0)<0\,\)時，函數\(f(x)\,\)在\(x=x_0\,\)處取得極大值。

而當\(f''(x_0)=0\,\)時，無法直接判斷，還需要逐次檢驗其更高階導數的正負號。由此有一个規律：若其開始不為零的導數階數為偶數，則駐點是極值點；若為奇數，則為拐點，而不是極值點。

對於二元函数\(f(x_1,x_2)\,\)，在給定區域內某\(x_0(x_{10}, x_{20})\,\)點處可導，並在\(x_0(x_{10}, x_{20})\,\)點處取得[極值](https://zh.wikipedia.org/wiki/極值 "wikilink")，其[必要條件是](https://zh.wikipedia.org/wiki/必要條件 "wikilink")

  -
    \(f_{x_1}(x_0)=f_{x_2}(x_0)=0\,\)

即

  -
    \(\nabla f(x_0)=0\,\)

同樣，這只是必要條件，要進一步判斷\(x_0(x_{10}, x_{20})\,\)是否為極值點需要找到取得極值的充分條件。根據函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處的泰勒展開式，考慮到上述極值必要條件，有

  -
    \(f(x_1,x_2)=f(x_{10},x_{20})+\frac {1}{2}[f_{x_1 x_1}(x_0)\Delta x_1^2+2f_{x_1 x_2}(x_0)\Delta x_1\Delta x_2+f_{x_2 x_2}(x_0)\Delta x_2^2]+\cdots\,\)

設\(A=f_{x_1 x_1}(x_0)\,\)，\(B=f_{x_1 x_2}(x_0)\,\)，\(C=f_{x_2 x_2}(x_0)\,\)，則

  -
    \(f(x_1,x_2)=f(x_{10},x_{20})+\frac {1}{2}[A\Delta x_1^2+2B\Delta x_1\Delta x_2+C\Delta x_2^2]+\cdots\,\)

或

  -
    \(f(x_1,x_2)=f(x_{10},x_{20})+\frac {1}{2A}[(A\Delta x_1 + B\Delta x_2)^2+(AC-B^2)\Delta x_2^2]+\cdots\,\)

若\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處取得極小值，則要求在\(x_0(x_{10},x_{20})\,\)某一[鄰域內一切點](https://zh.wikipedia.org/wiki/鄰域 "wikilink")\(x\,\)都必須滿足

  -
    \(f(x_1,x_2)-f(x_{10},x_{20})>0\,\)

即要求

  -
    \(\frac {1}{2A}[(A\Delta x_1 + B\Delta x_2)^2+(AC-B^2)\Delta x_2^2]>0\,\)

亦即要求\(A>0\,\)，\(AC-B^2>0\,\)

即
\(\left.\frac{\partial^2 f}{\partial x_1^2}\right|_{x_0}>0\,\)

\(\begin{bmatrix}\frac{\partial^2 f}{\partial x_1^2}\frac{\partial^2 f}{\partial x_2^2}-(\frac{\partial^2 f}{\partial x_1\partial x_2})^2\end{bmatrix}_{x_0}>0\,\)
此條件反映了\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處的黑塞矩陣\(G(x_0)\,\)的各階主子式都大於零，即對於

  -
    <math display="block">G(x_0)=\\begin{bmatrix}\\frac{\\partial^2
    f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_2} \\\\ \\\\

\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_2^2} \\end{bmatrix}_{x_0}\\,</math>

要求
\(\left.\frac{\partial^2 f}{\partial x_1^2}\right|_{x_0}>0\,\)

\(| G(x_0) |=\begin{vmatrix}\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} \end{vmatrix}_{x_0}>0\,\)
\(f((x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處取得極大值的討論與之類似。於是有極值充分條件：

設二元函数\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點的鄰域內連續且具有一階和二階連續偏導數，又有\(f_{x_1}(x_0)=f_{x_2}(x_0)=0\,\)，同時令\(A=f_{x_1 x_1}(x_0)\,\)，\(B=f_{x_1 x_2}(x_0)\,\)，\(C=f_{x_2 x_2}(x_0)\,\)，則

1.  當\(A>0\,\)，\(AC-B^2>0\,\)時，函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)處取得極小值；
2.  當\(A<0\,\)，\(AC-B^2>0\,\)時，函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)處取得極大值。

此外可以判斷，當\(AC-B^2<0\,\)時，函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處沒有極值，此點稱爲[鞍點](../Page/鞍點.md "wikilink")。而當\(AC-B^2=0\,\)時，無法直接判斷，對此，補充一個規律：當\(AC-B^2=0\,\)時，如果有\(A\equiv 0\,\)，那麼函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)有極值，且當\(C>0\,\)有極小值，當\(C<0\,\)有極大值。

由線性代數的知識可知，若矩陣\(G(x_0)\,\)滿足
\(\left.\frac{\partial^2 f}{\partial x_1^2}\right|_{x_0}>0\,\)

  -
    <math display="block">\\begin{vmatrix}\\frac{\\partial^2
    f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_2} \\\\ \\\\

\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_2^2}
\\end{vmatrix}_{x_0}\>0\\,</math>

則矩陣\(G(x_0)\,\)是[正定矩陣](https://zh.wikipedia.org/wiki/正定矩陣 "wikilink")，或者說矩陣\(G(x_0)\,\)正定。

若矩陣\(G(x_0)\,\)滿足
\(\left.\frac{\partial^2 f}{\partial x_1^2}\right|_{x_0}<0\,\)

  -
    <math display="block">\\begin{vmatrix}\\frac{\\partial^2
    f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial
    x_1\\,\\partial x_2} \\\\ \\\\

\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_2^2}
\\end{vmatrix}_{x_0}\>0\\,</math>

則矩陣\(G(x_0)\,\)是[負定矩陣](https://zh.wikipedia.org/wiki/負定矩陣 "wikilink")，或者說矩陣\(G(x_0)\,\)負定。\[3\]

於是，二元函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處取得極值的條件表述為：二元函數\(f(x_1,x_2)\,\)在\(x_0(x_{10},x_{20})\,\)點處的黑塞矩陣正定，則取得極小值；在\(x_0(x_{10},x_{20})\,\)點處的黑塞矩陣負定，則取得極大值。

對於多元函數\(f(x_1,x_2,\cdots,x_n)\,\)，若在\(x_0(x_1,x_2,\cdots,x_n)\,\)點處取得極值，則極值存在的必要條件為

\(\nabla f(x_0)=\begin{bmatrix}\frac {\partial f}{\partial x_1} & \frac {\partial f}{\partial x_2} & \cdots & \frac {\partial f}{\partial x_n}\end{bmatrix}_{x_0}^T=0\,\)

取得極小值的充分條件為

  -
    <math display="block">G(x_0)= \\begin{bmatrix}

\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_2} & \\cdots & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_n} \\\\ \\\\ \\frac{\\partial^2
f}{\\partial x_2\\,\\partial x_1} & \\frac{\\partial^2 f}{\\partial
x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2\\,\\partial
x_n} \\\\ \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\\\
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_2} & \\cdots &
\\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}_{x_0}\\,</math>

正定，即要求\(G(x_0)\,\)的各階主子式都大於零，即
\(\left.\frac{\partial^2 f}{\partial x_1^2}\right|_{x_0}>0\,\)

\(\begin{vmatrix}\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} \end{vmatrix}_{x_0}>0\,\)

\(\vdots\)

\(| G(x_0) |>0\,\)
取得極大值的充分條件為

  -
    <math display="block">G(x_0)= \\begin{bmatrix}

\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_2} & \\cdots & \\frac{\\partial^2
f}{\\partial x_1\\,\\partial x_n} \\\\ \\\\ \\frac{\\partial^2
f}{\\partial x_2\\,\\partial x_1} & \\frac{\\partial^2 f}{\\partial
x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2\\,\\partial
x_n} \\\\ \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\\\
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_1} &
\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_2} & \\cdots &
\\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}_{x_0}\\,</math>

負定。\[4\]\[5\]\[6\]

## 拓展閱讀

  - [雅可比矩陣](https://zh.wikipedia.org/wiki/雅可比矩陣 "wikilink")
  - [梯度](../Page/梯度.md "wikilink")

## 參考文獻

[Category:矩陣](https://zh.wikipedia.org/wiki/Category:矩陣 "wikilink")
[Category:多变量微积分](https://zh.wikipedia.org/wiki/Category:多变量微积分 "wikilink")

1.
2.
3.
4.
5.
6.